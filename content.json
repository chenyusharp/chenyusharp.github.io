{"meta":{"title":"技术、生活、思考","subtitle":"","description":"","author":"chenyusharp","url":"http://example.com","root":"/"},"pages":[{"title":"tags","date":"2022-01-22T06:26:09.000Z","updated":"2022-01-22T10:22:48.535Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2022-01-22T06:20:31.000Z","updated":"2022-01-22T10:22:21.821Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"利用JVM命令行工具排查线上问题","slug":"typora文件集合/技术/常见的面试技术问题/利用JVM命令行工具排查线上问题","date":"2022-03-20T05:19:39.297Z","updated":"2022-03-20T06:17:33.697Z","comments":true,"path":"2022/03/20/typora文件集合/技术/常见的面试技术问题/利用JVM命令行工具排查线上问题/","link":"","permalink":"http://example.com/2022/03/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9D%A2%E8%AF%95%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/%E5%88%A9%E7%94%A8JVM%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E6%8E%92%E6%9F%A5%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/","excerpt":"","text":"名称 主要作用 jps 查看正在运行的java进程 jstack 打印线程快照 jmap 导出堆内存映射文件 jstat 查看jvm统计信息 jinfo 实时查看和修改jvm配置参数 jhat 用于分析heapdump文件 jps：查看正在运行的java进程 选项 作用 -q 只输出进程id -m 输出传递给主类main函数的参数 -l 输出主类全类名，如果进程执行的是jar包，输出jar包的名字。 -v 程序启动时制定的jvm参数 ex： jstack :打印线程快照查看某个java进程中所有线程的状态。一般用来定位线程出现长时间停顿的原因，如发生死循环、死锁、请求外部资源长时间等待等。 执行jstack的效果： jmap：导出堆内存映射文件jmap主要用来导出堆内存映射文件，看是否发生内存泄漏等； 1jmap -dump:file=文件名.dump 进程id jstat:查看jvm统计信息jstat可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 Loaded 解释 Loaded 加载类的个数 Bytes 加载类的字节数 Unloaded 卸载类的个数 Bytes 卸载类的字节数 Time 花费的时间 jinfo：实时查看和修改jvm参数 ex：","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"工作安排","slug":"工作安排","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92/"}]},{"title":"如何实现一个RPC框架","slug":"typora文件集合/技术/常见的面试技术问题/如何实现一个RPC框架","date":"2022-03-19T18:29:15.439Z","updated":"2022-03-20T05:20:22.016Z","comments":true,"path":"2022/03/20/typora文件集合/技术/常见的面试技术问题/如何实现一个RPC框架/","link":"","permalink":"http://example.com/2022/03/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9D%A2%E8%AF%95%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AARPC%E6%A1%86%E6%9E%B6/","excerpt":"","text":"一个RPC调用的过程如下 调用方发送请求后由代理类将调用的方法，参数组装成能进行网络传输的消息体 调用方将消息体发送到提供方 提供方将消息进行解码，得到调用的参数 提供方反射执行相应的方法，并将结果返回 生成代理类fb的Thrift和Google的gRPC都是定义一个schema文件，然后执行程序，帮你生成客户端代理类以及接口。调用方直接用生成的代理类来请求，提供方继承生成的接口即可。 优点：支持多语言通信。 在Java中生成代理类的方式： 1.JDK动态代理； 2.字节码操作类库（cglib，Javassist）。 协议为什么需要协议？ 数据在网络中是以二进制的形式在网络中传播的，RPC的请求数据不是以一个整体发送到提供方的，而是可能被拆分成多个数据包发送出去。定义协议，可以有效的保证通信的双方进行交流。 都有哪些种类的协议呢？ 定长协议：协议内容固定； 特殊结束符：定义一个消息结束的分割符，如读\\n，表示一个数据读取完毕了，没有就一直读； 变长协议（协议头+协议体）：用一个定长表示消息体的长度，剩下的内容表示消息体。？ 我们以dubbo的协议来进行说明，dubbo采用的协议被称为dubbo协议。协议的头格式如下： 解释： 为什么要自定义协议？ 关键字：高性能 Http协议的请求包比较大，有很多无用的内容，自定义协议可以精简很多的内容； Http协议是无状态的，每次都要重新建立链接，响应完毕以后链接关闭。 序列化常用的序列化方式： JDK原生序列化； JSON； Protobuf； Kryo； Hessian2； MessagePack； 选择序列化时，需要考虑的因素： 效率； 空间开销； 通用性和兼容性； 安全性。 通讯这个主要指的是IO模型； BIO NIO IO多路复用；（Netty） 异步IO 注册中心我们可以使用ZK、Redis、Nacos等多种方式实现； 其他路由策略、异常重试、监控、异步调用","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"工作安排","slug":"工作安排","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92/"}]},{"title":"常用的linux命令","slug":"typora文件集合/技术/技术笔记/服务器/常用的linux命令","date":"2022-03-19T18:23:26.102Z","updated":"2022-03-19T18:27:30.427Z","comments":true,"path":"2022/03/20/typora文件集合/技术/技术笔记/服务器/常用的linux命令/","link":"","permalink":"http://example.com/2022/03/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E5%B8%B8%E7%94%A8%E7%9A%84linux%E5%91%BD%E4%BB%A4/","excerpt":"","text":"编号 命令 释义 1 ps aux | grep redis-server 查看某个服务是否启动 2 3","categories":[{"name":"linux","slug":"linux","permalink":"http://example.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"redis源码环境搭建","slug":"typora文件集合/技术/redis/redis源码环境搭建","date":"2022-03-19T16:29:16.300Z","updated":"2022-03-19T18:19:49.413Z","comments":true,"path":"2022/03/20/typora文件集合/技术/redis/redis源码环境搭建/","link":"","permalink":"http://example.com/2022/03/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/redis/redis%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"","text":"make和cmake 的区别 make，是一个自动化编译工具，使用一条命令实现完全编译。 makefile，是一个文件，里面定义了make需要使用到的规则，make依据makefile文件中的规则来进行编译。 cmakefile，用来自动生成makefile文件的工具。它能够输出各种各样的makefile或者是project文件。 参考博文：https://blog.csdn.net/weixin_42491857/article/details/80741060 进行编译： 配置execute： 参考博文：https://cxybb.com/article/u011225266/116017675","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}]},{"title":"","slug":"typora文件集合/技术/常见的面试技术问题/Spring AOP是怎么实现的","date":"2022-03-18T17:03:12.253Z","updated":"2022-03-18T17:03:23.832Z","comments":true,"path":"2022/03/19/typora文件集合/技术/常见的面试技术问题/Spring AOP是怎么实现的/","link":"","permalink":"http://example.com/2022/03/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9D%A2%E8%AF%95%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/Spring%20AOP%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"http报文的常见的错误码","slug":"typora文件集合/技术/常见的面试技术问题/http报文的常见的错误码","date":"2022-03-18T15:59:18.287Z","updated":"2022-03-19T18:53:28.785Z","comments":true,"path":"2022/03/18/typora文件集合/技术/常见的面试技术问题/http报文的常见的错误码/","link":"","permalink":"http://example.com/2022/03/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9D%A2%E8%AF%95%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/http%E6%8A%A5%E6%96%87%E7%9A%84%E5%B8%B8%E8%A7%81%E7%9A%84%E9%94%99%E8%AF%AF%E7%A0%81/","excerpt":"","text":"Http请求报文和响应报文的格式 常见的首部如下： 通用首部字段（请求报文与响应报文都会使用的首部字段） Date：创建报文时间 Connection：连接的管理 Cache-Control：缓存的控制 Transfer-Encoding：报文主体的传输编码方式 请求首部字段（请求报文会使用的首部字段） Host：请求资源所在服务器 Accept：可处理的媒体类型 Accept-Charset：可接收的字符集 Accept-Encoding：可接受的内容编码 Accept-Language：可接受的自然语言 响应首部字段（响应报文会使用的首部字段） Accept-Ranges：可接受的字节范围 Location：令客户端重新定向到的URI Server：HTTP服务器的安装信息 实体首部字段（请求报文与响应报文的的实体部分使用的首部字段） Allow：资源可支持的HTTP方法 Content-Type：实体主类的类型 Content-Encoding：实体主体适用的编码方式 Content-Language：实体主体的自然语言 Content-Length：实体主体的的字节数 Content-Range：实体主体的位置范围，一般用于发出部分请求时使用。 ==状态码的识别== 类别 原因短语 1xx 信息性状态码 收到的请求正在处理 2xx 成功状态码 请求正常处理完毕 3xx 重定向状态码 需要进行附加操作以完成请求 4xx 客户端错误状态码 服务器无法处理请求 5xx 服务端错误状态码 服务器处理请求出错 2xx成功： 状态码 英文 解释 200 OK 表示从客户端发来的请求在服务端被正确处理 204 No content 表示请求成功，但响应报文不含实体的主体部分 206 Partial Content 进行范围请求 3xx 重定向 状态码 英文 解释 301 moved permanently 永久性重定向，表示资源已被分配了新的URL 302 found 临时性重定向，表示资源临时被分配了新的URL 303 see other 表示资源存在着另一个URL，应使用GET方法定向获取资源 304 not modified 表示服务器允许访问资源，但发生请求未满足条件的情况 307 temporary redirect 临时重定向，和302含义相同 4xx客户端错误 状态码 英文 解释 400 bad request 请求报文存在语法错误 401 unauthorized 表示发送的请求需要有通过HTTP认证的信息 403 Forbidden 表示对请求资源的访问被服务器拒绝 404 not found 表示在服务器上没有找到请求的资源 5xx 服务器错误 状态码 英文 解释 500 internal server error 表示服务器在执行请求时发生了错误 503 service unavalibale 表示服务器暂时处于超负荷或正在停机维护，无法处理请求。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"工作安排","slug":"工作安排","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92/"}]},{"title":"如何排查CPU飙高的问题","slug":"typora文件集合/技术/常见的面试技术问题/如何排查CPU飙高的问题","date":"2022-03-18T15:20:20.450Z","updated":"2022-03-19T18:54:02.518Z","comments":true,"path":"2022/03/18/typora文件集合/技术/常见的面试技术问题/如何排查CPU飙高的问题/","link":"","permalink":"http://example.com/2022/03/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9D%A2%E8%AF%95%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5CPU%E9%A3%99%E9%AB%98%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"如何排查CPU飙高的问题？ 先执行top命令，找到CPU占用比较高的进程； jstak 进程id &gt; loop.txt（文件名可以自定义）； 找到进程中CPU占用比较高的线程，线程id转为16进制； 到show.txt文件中根据线程id查看线程的具体状态即可； Top 命令运行图： 参数介绍： 第一行：基本信息： 第二行：任务信息 第三行：CPU使用情况 第四行：物理内存使用情况 buffer/cache buffer 和 cache都是内存中存放的数据，不同的是，buffer存放的是准备写入磁盘的数据，而cache存放的是从磁盘中读取的数据。 在linux中，有一个守护进程（daemon）会定期把buffers中的数据写入磁盘，也可以使用sync命令手动把buffer中的数据写入磁盘。使用buffer可以把分散的I/O操作集中起来，减少了磁盘寻道的时间和磁盘碎片。 cache是linux把读取频率高的数据，放到内存中，减少I/O。linux中cache没有固定大小，根据使用情况自动增加或删除。 top中使用的参数： 参数选项名称 含义 p 通过指定进程ID（PID）来仅仅监控某个进程的状态。可以指定多个，-pN1 -pN2 … （-p N1 -p N2…也可）或者 -pN1,N2,N3 …（-p N1,N2…也可） H 显示所有线程的运行状态指标。如果没有该参数，会显示一个进程中所有线程的总和。在运行过程中，可以通过H命令进行交互控制 第一步：执行top命令。 第二步：看到pid为23757的进程CPU占用较高，执行如下命令： 1jstack 23757 &gt; loop.txt 第三步：查看线程的具体执行情况； 1top -p 23757 -H 可以看到PID为23772,23773和23774的线程占用CPU较高。这里注意，PID不是特指进程的ID，线程的ID也可以叫做PID； 第四步：将10进制23772转为16进制，因为jstack中PID使用的是16进制： 12printf &quot;%x&quot; 23772输出5cdc 第五步：打开loop.txt文件，搜5cdc。 即可以定位到有问题的代码。","categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"工作安排","slug":"工作安排","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92/"}]},{"title":"系统监控与告警","slug":"wholee/系统监控与告警","date":"2022-03-17T09:29:56.686Z","updated":"2022-03-19T13:58:29.564Z","comments":true,"path":"2022/03/17/wholee/系统监控与告警/","link":"","permalink":"http://example.com/2022/03/17/wholee/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%91%8A%E8%AD%A6/","excerpt":"","text":"Grafana监控大盘地址：https://monitor.huoli101.com/?orgId=1应用机器监控： 例如：product-center的线上机器监控： 中间件Redis的监控，在Redis Overview中： 中间件MySQL的监控，地址：https://monitor.huoli101.com/d/MQWgroiiz/mysql-overview?orgId=1&amp;var-dataSource=%E7%BE%8E%E8%A5%BF&amp;var-interval=$__auto_interval_interval&amp;var-nodeName=product-odoo-new-mysql&amp;var-resource=product-odoo-new&amp;var-service=product-center&amp;var-jumpNode=%E5%95%86%E5%93%81%E4%B8%AD%E5%BF%83&amp;var-dataCenter=&amp;from=now-7d&amp;to=now。 PS：MySQL监控中需要关注的指标： 内存使用率； QPS： 满查询sql： 客户端连接进程数； CPU使用率：","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"dubbo接口调用","slug":"wholee/dubbo接口调用","date":"2022-03-17T08:54:48.561Z","updated":"2022-03-19T13:53:29.949Z","comments":true,"path":"2022/03/17/wholee/dubbo接口调用/","link":"","permalink":"http://example.com/2022/03/17/wholee/dubbo%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/","excerpt":"","text":"第一步：通过跳板机登录到test或者是预发、线上的机器上； 第二步：telnet+IP地址 +20988端口，访问dubbo服务，例如： 然后通过ls命令可以查看有那些已经注册的服务，如下图所示： 第三步：通过invoke 命令调用dubbo服务 例如： invoke com.clubfactory.product.center.client.service.product.readonly.IProductReadOnlyAPI.getByIds([20440305])， 会得到如下的结果： 最下面会有一个耗时的统计。 PS: 可用的开源工具：https://www.cxybb.com/article/qq_31091589/98056271；","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"宝塔相关知识","slug":"typora文件集合/技术/技术笔记/服务器/宝塔相关知识","date":"2022-03-12T14:38:16.285Z","updated":"2022-03-19T18:24:54.279Z","comments":true,"path":"2022/03/12/typora文件集合/技术/技术笔记/服务器/宝塔相关知识/","link":"","permalink":"http://example.com/2022/03/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E5%AE%9D%E5%A1%94%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/","excerpt":"","text":"1.查看面板入口：/etc/init.d/bt default 2.关闭安全入口：rm -f /www/server/panel/data/admin_path.pl 输入命令后，会得到对应的登录信息：","categories":[{"name":"linux","slug":"linux","permalink":"http://example.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"","slug":"typora文件集合/思维/如何提高记忆力","date":"2022-03-12T08:24:12.484Z","updated":"2022-03-18T17:07:13.843Z","comments":true,"path":"2022/03/12/typora文件集合/思维/如何提高记忆力/","link":"","permalink":"http://example.com/2022/03/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%80%9D%E7%BB%B4/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E8%AE%B0%E5%BF%86%E5%8A%9B/","excerpt":"","text":"保持充足的睡眠。思维按摩：用拇指和食指从上到下轻轻地按摩整个耳朵，用两只手的手指触摸位于发际和眉毛之间的两个穴位。促进血液流动，消除记忆障碍和增强记忆力。 经常咀嚼。 合理饮食： 多吃大豆和豆制品。 多吃鱼； 多吃桔子和香蕉； 多吃猪脑和鸡； 多吃蔬菜、胡萝卜、菠菜。","categories":[],"tags":[]},{"title":"日志查看规范","slug":"wholee/日志查看规范","date":"2022-03-11T02:09:44.082Z","updated":"2022-03-19T13:54:58.184Z","comments":true,"path":"2022/03/11/wholee/日志查看规范/","link":"","permalink":"http://example.com/2022/03/11/wholee/%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B%E8%A7%84%E8%8C%83/","excerpt":"","text":"product-message-consumer： 日志目录：/root/logs/product-message-consumer; 发送的消息日志在kafka_producer.log中，消费的消息日志在kafka_consumer.log中； 日志的查找： 日志上报： 1Cat.logEvent(MESSAGE_COUNT_FOR_GROUP, chatId, Message.SUCCESS, msg);","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"","slug":"typora文件集合/拉钩/中间件/Redis/作业","date":"2022-02-27T14:15:54.619Z","updated":"2022-03-12T16:38:05.759Z","comments":true,"path":"2022/02/27/typora文件集合/拉钩/中间件/Redis/作业/","link":"","permalink":"http://example.com/2022/02/27/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/%E4%BD%9C%E4%B8%9A/","excerpt":"","text":"编号 编码常量 对应的底层数据结构 1 REDIS_ENCODING_INT long类型的整数 2 REDIS_ENCODING_EMBSTR embstr编码的简单动态字符串 3 REDIS_ENCODING_RAW 简单动态字符串 4 REDIS_ENCODING_HT 字典 5 REDIS_ENCODING_LINKEDLIST 双端链表 6 REDIS_ENCODING_ZIPLIST 压缩链表 7 REDIS_ENCODING_INTSET 整数集合 8 REDIS_ENCODING_SKIPLIST 跳跃表和字典 不同类型、编码的对象 类型 编码 对象 REDIS_STRING REDIS_ENCODING_INT 使用整数值实现的字符串对象 REDIS_STRING REDIS_ENCODING_EMBSTR 使用embstr编码的简单动态字符串实现的字符串对象 REDIS_STRING REDIS_ENCODING_RAW 使用简单动态字符串实现的字符串对象 REDIS_LIST REDIS_ENCODING_ZIPLIST 使用压缩列表实现的列表对象 REDIS_LIST REDIS_ENCODING_LINKEDLIST 使用双端链表是想的列表对象 REDIS_HASH REDIS_ENCODING_ZIPLIST 使用压缩列表实现的哈希对象 REDIS_HASH REDIS_ENCODING_HT 使用字典实现的哈希对象 REDIS_SET REDIS_ENCODING_INTSET 使用整数集合实现的集合对象 REDIS_SET REDIS_ENCODING_HT 使用字典实现的集合对象 REDIS_ZSET REDIS_ENCODING_ZIPLIST 使用压缩列表实现的有序集合对象 REDIS_ZSET REDIS_ENCODING_SKIPLIST 使用跳跃表和字典实现的有序集合对象","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/Redis/使用Clion导入、调试Redis","date":"2022-02-26T16:57:42.873Z","updated":"2022-02-26T16:57:57.782Z","comments":true,"path":"2022/02/27/typora文件集合/拉钩/中间件/Redis/使用Clion导入、调试Redis/","link":"","permalink":"http://example.com/2022/02/27/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/%E4%BD%BF%E7%94%A8Clion%E5%AF%BC%E5%85%A5%E3%80%81%E8%B0%83%E8%AF%95Redis/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/C语言学习笔记","date":"2022-02-26T15:42:46.691Z","updated":"2022-02-26T16:53:18.600Z","comments":true,"path":"2022/02/26/typora文件集合/技术/技术笔记/C语言学习笔记/","link":"","permalink":"http://example.com/2022/02/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/C%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"C函数：在C语言中，有的语句使用时不能带括号，有的语句必须带括号。带括号的称为函数（Function）。 C语言自带的函数称为库函数（Library Function）。库（Library）是编程中的一个基本概念，可以简单地认为它是一些列函数的集合，在磁盘上往往是一个文件夹。C语言自带的库称为标准库（Standard Library），其他公司或个人开发的库称为第三方库（Third-Party Library）。 C语言规定，一个程序必须有且只有一个 main 函数。main 被称为主函数，是程序的入口函数，程序运行时从 main 函数开始，直到 main 函数结束（遇到 return 或者执行到函数末尾时，函数才结束） 头文件C语言开发者们编写了很多常用函数，并分门别类的放在了不同的文件，这些文件就称为头文件（header file）。每个头文件中都包含了若干个功能类似的函数，调用某个函数时，要引入对应的头文件，否则编译器找不到函数。 较早的C语言标准库包含了15个头文件，stdio.h 和 stdlib.h 是最常用的两个： stdio 是 standard input output 的缩写，stdio.h 被称为“标准输入输出文件”，包含的函数大都和输入输出有关，puts() 就是其中之一。 stdlib 是 standard library 的缩写，stdlib.h 被称为“标准库文件”，包含的函数比较杂乱，多是一些通用工具型函数，system() 就是其中之一。 空白符空格、制表符、换行符等统称为空白符（space character），它们只用来占位，并没有实际的内容，也显示不出具体的字符。 数据类型：常用的数据类型 说 明 字符型 短整型 整型 长整型 单精度浮点型 双精度浮点型 无类型 数据类型 char short int long float double void 数据类型对应的长度（字节）： 说 明 字符型 短整型 整型 长整型 单精度浮点型 双精度浮点型 数据类型 char short int long float double 长 度 1 2 4 4 4 8 sizeof 用来获取某个数据类型或变量所占用的字节数，如果后面跟的是变量名称，那么可以省略( )，如果跟的是数据类型，就必须带上( )。 %d称为格式控制符。 %d 输出一个数字。 %c：输出一个字符。c 是 character 的简写。 %s：输出一个字符串。s 是 string 的简写。 %f：输出一个小数。f 是 float 的简写。 %hd用来输出 short int 类型，hd 是 short decimal 的简写； %d用来输出 int 类型，d 是 decimal 的简写； %ld用来输出 long int 类型，ld 是 long decimal 的简写。 在数据前面加上unsigned关键字，表示数字是无符号数，所有位上都可以表示数字。 无符号数的输出： short int long unsigned short unsigned int unsigned long 八进制 – – – %ho %o %lo 十进制 %hd %d %ld %hu %u %lu 十六进制 – – – %hx 或者 %hX %x 或者 %X %lx 或者 %lX 小数C语言中常用的小数有两种类型，分别是 float 或 double；float 称为单精度浮点型，double 称为双精度浮点型。 输出： %f 以十进制形式输出 float 类型； %lf 以十进制形式输出 double 类型； %e 以指数形式输出 float 类型，输出结果中的 e 小写； %E 以指数形式输出 float 类型，输出结果中的 E 大写； %le 以指数形式输出 double 类型，输出结果中的 e 小写； %lE 以指数形式输出 double 类型，输出结果中的 E 大写。 转义字符转义字符以\\或者\\x开头，以\\开头表示后跟八进制形式的编码值，以\\x开头表示后跟十六进制形式的编码值。对于转义字符来说，只能使用八进制或者十六进制。 转义字符的初衷是用于 ASCII 编码，所以它的取值范围有限： 八进制形式的转义字符最多后跟三个数字，也即\\ddd，最大取值是\\177； 十六进制形式的转义字符最多后跟两个数字，也即\\xdd，最大取值是\\x7f。 完整列表： 转义字符 意义 ASCII码值（十进制） \\a 响铃(BEL) 007 \\b 退格(BS) ，将当前位置移到前一列 008 \\f 换页(FF)，将当前位置移到下页开头 012 \\n 换行(LF) ，将当前位置移到下一行开头 010 \\r 回车(CR) ，将当前位置移到本行开头 013 \\t 水平制表(HT) 009 \\v 垂直制表(VT) 011 &#39; 单引号 039 &quot; 双引号 034 \\\\ 反斜杠 092 关键字","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/lombok","date":"2022-02-25T01:30:37.202Z","updated":"2022-02-25T02:32:59.969Z","comments":true,"path":"2022/02/25/typora文件集合/技术/技术笔记/源码/lombok/","link":"","permalink":"http://example.com/2022/02/25/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/lombok/","excerpt":"","text":"lombok简介：https://projectlombok.org/ 有关使用lombok以后对象转换失效的问题Lombok使用@Builder注解以后，使用BeanUtils.copyProperties对象转换失效的问题。 这个其实就要追根溯源的去看lombok背后的机制，我们拿一个使用了@Data+@Builder组合注解的例子来看， 1.0 1.1 1.2 1.3 1.4 1.5 上面的图1.1是图1.0的Java Bean添加了@Data注解之后，对生成的class文件反编译得到的类文件，可以看出，反编译得到的ShippingRuleDTO对象是有一个无参的构造函数的；图1.2是添加了@Data+@Builder组合注解以后，反编译得到的类文件，这个时候发现重新生成的ShippingRuleDTO对象已经没有了无参的构造函数了，取而代之的是一个带有参数的构造函数，这个其实是和@Builder这个注解有关系的，@Builder注解是采用了建造者设计模式，原始对象的构建是通过Builder对象的build方法创建的，而Buider对象的build方法内部其实是调用了原始对象的带有参数的构造函数,如图1.3所示。 当采用图1.4这种经过封装的对象copy方法的时候，会发现dest对象的构建需要调用对应的类的instance方法。这个方法采用无参构造器进行创建对象的实例，如图1.5所示。 解决方法，在类上添加@NoArgsConstructor、@AllArgsConstructor两个注解，注意，这两个注解必须同时添加。 延伸阅读：为什么不能单独添加@Builder+@NoArgsConstructor注解？ \u0010","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/多线程/多线程","date":"2022-02-24T01:55:47.803Z","updated":"2022-02-24T01:55:47.803Z","comments":true,"path":"2022/02/24/typora文件集合/拉钩/多线程/多线程/","link":"","permalink":"http://example.com/2022/02/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"[TOC] 多线程和锁多线程的目的：充分利用多核CPU的并行处理的能力，加快程序的处理速度； 锁的存在的意义：控制资源的并发访问，使操作串行话； JUC相关的（AQS）AQS是一个用来构建锁合同步器的框架。 原理：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占有，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列实现的，即将暂时获取不到锁的线程加入到队列中。 CLH队列：是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点来实现锁的分配。 两种资源共享方式： Exclusive：公平锁和非公平锁。 Share： 锁相关 锁（Synchronized、ReentrantLock的区别）、MarkWord Synchronized、ReentrantLock的区别 两者都是可重入锁，什么是可重入锁？已获得锁的对象，可以再次获取锁； Synchronized是JVM实现的，使用起来简单；ReentrantLock是一个Java提供的API，比较灵活； Synchronized是非公平锁，ReentrantLock可以提供非公平锁和公平锁两种，利用fair参数可以控制； 都提供了等待、通知机制； Synchronized是利用了Obejct对象的notify和wait方法； ReentrantLock需要借助于condition、newCondition方法 ReentrantLock提供了中断等待机制；lock.lockInterruptibly() Java对象头的结构： MarkWord ：存储对象的hashcode、分代年龄、gc标记、同步状态、锁标志位等 kClassPointer：对象的类型指针，指向类元数据（类class文件信息，metaspace空间的方法区） Synchronized的优化&amp;Mark word 的结构 2.1 无锁（01），所有线程均可以修改某一个资源的值，但同时只能由一个线程修改成功，其他会循环尝试；2.2 偏向锁（01）：在对象头MarkWord中存放有对应的线程的id，如果发现请求线程是同一个的话，再次请求的时候，直接获取锁；偏向锁的一个撤销 ：全局安全点（没有字节码在执行），暂停拥有偏向锁的线程，并判断对象是否处于被锁定的状态，如果没有的话，则把对象置为无锁状态，并撤销偏向锁，恢复到无锁或者轻量级锁状态；2.3 轻量级锁（00）：如果在偏向锁的过程中，有其他的线程进行请求的话，就会转化为轻量级锁，或者是关闭偏向锁功能的时候（即2.2种描述的）。线程的栈帧中有一个Lock record的区域，拷贝一份Mark word到这个区域。线程会通过CAS操作，尝试讲Mark word 更新为这个栈帧中锁记录的指针，同时，LockRecord 中的owner指针也会指向Mark word。更新成功，线程就拥有对象的锁。如果CAS失败，判断Mark word是否指向当前线程的指针，是的话，就直接进入同步代码块继续执行。 另一个线程会自旋，当自旋超过一定次数之后，会膨胀为重量级锁。（自适应自旋）；另一个升级为重量级锁的原因是这个时候有另外的线程来争抢对象的锁；2.4 重量级锁（10）：每一个对象都有一个ObjectMonitor锁对象。重量级锁的时候，mark word中存储的是这个monitor锁的指针，另外monitor中，有一个owner指针，指向拥有锁的线程。ObjectMonitor对象内部结构：entryList： 在进入或者重新进入时被阻塞的线程；waitSet：在改Monitor上等待的线程；owner： monitor的所有者（线程）；这个monitor里面表示count（计数器），用于CAS操作。一次CAS操作成功，owner就会置换为指向对应最线程的指针；利用Mutex Lock这个系统提供的来实现，来进行加锁，缺点：需要从内核态切换到用户态，比较消耗性能； 同时，每一个线程都有一个monitor record列表。 2.5 GC标记（11） 如何避免线程死锁？ 线程死锁的四个条件： 互斥条件： 改资源任一时刻只能由一个线程占有； 请求与保持条件： 一个线程因请求资源而阻塞时，对已获得资源保持不放； 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕之后才能释放资源； 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系； 破坏死锁的话，需要从2至4三个点来进行考虑。 一次申请所有资源； 占用部分资源的线程进一步申请其他资源失败时，可以主动释放掉自己占有的资源； 按照某一个顺序申请资源，释放的时候，反序释放； 线程池：常用的线程池；优缺点；常用参数 常用线程池： 12345678910111213//创建一个固定大小（核心线程数、最大线程数）的线程池，队列是LinkedBlockingQueue。缺点：容易造成OOM；ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);//核心线程数是0，最大线程数是Integer.MAX_VALUE，队列是SynchronousQueue的线程池。SynchronousQueue不进行线程的保存，直接进行转发。容易造成OOM；ExecutorService cachedThreadPool = Executors.newCachedThreadPool();//核心线程是是1个、最大线程是1个，队列是LinkedBlockingQueue（无限大）的线程池，容易造成OOM；ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor();//核心线程数固定大小的延迟执行的一个线程池，最大线程池大小是Integer.MAX_VALUE,队列是延迟队列：DelayedWorkQueue。缺点：容易造成OOM；Executors.newScheduledThreadPool(5);//自定义线程池,IO密集型和CPU密集型的区别int coreThreads = 10;int maxThreads = 100;ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(coreThreads, maxThreads,0L, TimeUnit.MILLISECONDS,new ArrayBlockingQueue(500)); 建议的方法：自定义一个线程池: 线程池的执行流程 其他什么事OOM？如何理解？怎么排查OOM？内存泄漏和OOM的区别？见JVM。 队列&amp;常用多线程工具 ForkJoin 队列 上下文切换，Linux操作系统的上下文切换时间为什么很少？零拷贝。 零拷贝技术，sendfile！只需要2次切换、2次拷贝 mmap技术： 4次切换、3次拷贝 ThreadLocal ThreadLocalMap是ThreadLocal的静态内部类 内存泄漏： ThreadLocalMap中key为ThreadLocal的弱引用，而value是强引用。所以，如果ThreadLocal没有被引用的话，在gc时，key会被清理掉，而value不会。 那么这个时候，就会出现key为null的entry，发生内存泄漏。解决方法：手动调用remove方法，看源码可以发现，在执行set、get方法之后，顺便把路上无效的entry用线性清扫清除掉，也可以起到一定的解决内存泄漏的问题。但是get、set方法发起无效key的清理都是有触发条件的，一般都是发现key匹配不到， set方法： 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&#x27;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; get 方法： 12345678910111213141516171819202122232425262728293031323334private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;/** * Version of getEntry method for use when key is not found in * its direct hash slot. * * @param key the thread local object * @param i the table index for key&#x27;s hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; get、set方法是否确定可以解决内存泄漏问题？，这个看了，感觉因该是可以的，只不过是在特定的条件下。 JMM 内存模型JMM与happen-beforeL1、L2、L3和主内存之间是同步的，有缓存一致性MESI协议的保证，但是Store Buffer、Load Buffer和L1之间却是异步的。内存中写入一个变量，这个变量会保存在Store Buffer中，稍后才异步的写入L1中，同时同步写入主内存中。 重排序与内存可见性的关系：Store Buffer的延迟写入是重排序的一种，我们称之为内存重排序（Memory Ordering）。除此之外，还有编译器和CPU指令的重排序。 重排序类型： 编译器重排序：对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序； CPU指令重排序：在指令级别，让没有依赖关系的多条执行并行； CPU内存重排序：CPU有自己的缓存，指令的执行顺序和写入主内存的顺序不完全一致。 PS：第三种重排序是造成内存可见性问题的主因； 内存屏障：为了禁止编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令，也就是内存屏障（Memory Barrier）。这也正是JMM和happen-before规则的底层实现原理。 四种CPU内存屏障： LoadLoad：禁止读和读的重排序； StoreStore：禁止写和写的重排序； LoadStore：禁止读和写的重排序； StoreLoad：禁止写和读的重排序； As-if-serial语义： 只要操作之间没有数据的依赖性，编译器和CPU都可以任意重排序，因为执行结果不会改变，代码看起来像是完全串行地一行一行从头执行到尾，这也就是as-if-serial语义。 编译器和CPU只能保证每一个线程的as-if-serial语义。线程之间的数据依赖和影响，需要编译器和CPU的上层来确定。 happen-before定义：描述了两个操作之间的内存可见性。 如果A happen before B，意味着A的执行结果必须对B可见，也就是保证跨线程的内存可见性。 A happen before B不代表A一定能在B之前执行，只确保如果A在B之前执行，则A的执行结果必须对B可见。JMM对开发者作出的一系列的承诺： 单线程中的每个操作，happen-before 对应线程中任意后续的操作（as-if-serial语义保证）； 对volatile变量的写入，happen-before对应后续对这个变量的读取； 对synchronized的解锁，happen-before对应后续对这个锁的加锁； 对final变量的写，happen-before于final域对象的读，happen-before于后续对final变量的读； volatilevolatile的三重功效：64位写入的原子性保障、内存可见性、禁止重排序； 实现原理：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/分布式","date":"2022-02-24T01:55:09.588Z","updated":"2022-02-24T01:55:09.588Z","comments":true,"path":"2022/02/24/typora文件集合/拉钩/中间件/分布式/","link":"","permalink":"http://example.com/2022/02/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E5%88%86%E5%B8%83%E5%BC%8F/","excerpt":"","text":"[TOC] 分布式特性： 分布性，机器分布在不同的机房、城市、国家； 对等性：没有主从之分，所有节点都是对等的； 并发性：不同的节点可能会并发的访问相同的资源，如数据库； 缺乏全局时钟：很难定义两件事情的发生的先后顺序； 故障总会发生； 单点故障：如果一个服务只有一台机器提供服务，在这台机器上发上的故障就叫做单点故障； 面临的问题： 通信问题：不可避免的会发生通信故障； 数据一致性：备份数据和主数据不同步； 网络分区：也是由于网络不通导致的； 节点故障： 三态：成功、失败、超时； 重发：出现失败和超时，就需要重新发送； 幂等：多次请求，结果保持一致； CAP 一致性所有节点访问都是同一份最新的数据副本；一致性分类：1. 强一致性； 2. 弱一致性； 3. 最终一致性（弱一致性的一种）。 ![分布式系统一致性分类](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/分布式系统一致性分类.png) 可用性每次请求都能获取到不错的响应，但是不能保证获取的数据为最新的数据； 分区容错性分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障； CAP三者不能同时满足的论证AP满足的情况下，两个节点之间因为网路等原因断开了链接，就会导致不同的节点数据是不一致的。 BASE 基本可用假设系统出现了不可预知的故障，但是还可以使用。 软状态允许系统中的数据存在中间状态，并认为该状态不会影响系统的整体可用性。即允许系统在多个不同节点的数据副本存在数据延时； 最终一致性系统不可能是一直是软状态的，必须有个时间限制。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。 这个期限取决于网络延时、系统负载、数据复制方案设计等因素； 6种常见的分布式解决方案TCC补偿事务；-业务层面的分布式事务 Try- Confirm - Cancel Try： 预留，即资源的预留和锁定，注意的是预留； Confirm： 确认操作，这一步就是真正的执行了； Cancel： 撤销操作，可以理解为把预留阶段的动作撤销了； TCC有个事务管理者的角色，用来记录TCC全局事务状态并提交或者回滚事务； 缺点： 对于业务上的每个操作，都需要定义三个动作，分别对应Try-Confirm-Cancel。 对于业务的侵入较大和业务紧耦合，需要根据特定的场景和业务逻辑来设计相应的操作； 另外，撤销和确认操作的执行可能需要重试，因此需要保证幂等； 优点：可以跨数据库、跨不同的业务系统来实现事务； 本地消息表（异步确保）利用了各系统本地事务来实现分布式事务。将业务的执行和将消息放入消息表中的操作放在同一个事务中，这样就能保证消息放入本地消息表中的时候业务肯定是执行成功的。然后调用下一个操作，如果成功了，消息表的状态可以直接改为已成功；失败的话，定时任务定时读取本地消息表，筛选出还未成功的消息再调用对应的服务，服务更新成功了再变更消息的状态；（需要保证幂等）； 最终一致性 MQ事务第一步：发送给Broker事务消息即半消息，半消息不是说一半的消息，而是指这个消息对消费者来说不可见； 第二步：发送成功以后，执行本地的事务； 第三步：根据本地事务的执行结果向Broker发送Commit和RollBack命令； 同时：MQ的发送方需要提供一个反查事务状态的接口，如果一段时间内半消息没有收到任何操作请求，那么Broker会通过这个反查接口得知发送方事务是否执行成功，然后执行Commit或者RollBack命令；Commit命令：订阅方就能收到这个消息，然后执行对应的本地事务，然后ACK这个消息；RollBack：订阅方收不到这个消息，等于事务没有执行过； 最终一致性 最大努力通知最大努力通知其实只是表明了一种柔性事务的思想：我已经尽自己最大的努力想达成事务的最终一致性了。本地消息表和事务消息都是最大努力通知的一种。适用于对时间不敏感的业务，例如短信通知； 2PC 两阶段提交协议两阶段提交的问题： 同步阻塞参与者在提交过程中，一直处于阻塞状态，占用着系统资源，其他节点请求的时候就会阻塞； 单点问题过于依赖于事务协调者，如果事务协调者发生宕机或者超时。事务就没有办法继续执行下去。如果问题出现在阶段二，各个事务参与者将会一直处于锁定事务资源的过程中，从而无法继续完成事务。 数据不一致如果在事务协调者发送commit请求的过程中出现了宕机，就会导致一部分事务参与者执行了commit请求、一部分没有执行，就会导致数据在各个执行者是不一样的。 过于保守由于协调者是在接受到所有执行者的commit询问通知反馈之后，才发起的执行提交通知。当任意一个执行者失败或者等待超时之后。协调者就只能依靠自身的中断机制进行事务的中断。这样的策略过于保守，即没有完善的容错机制，任意节点的失败都会导致整个事务的失败。 3PC三阶段提交协议 三阶段提交协议的升级点（基于二阶段） 三阶段提交协议引入了超时机制；对于协调者和参与者都设置了超时机制（2PC中，只有协调者拥有超时机制），主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题。因为参与者自身拥有超时机制，会在超时之后，自动进行本地的commit从而释放资源。这种机制也侧面降低了整个事务的阻塞时间和范围。 在第一阶段和第二阶段，引入了一个缓冲阶段（PreCommit）。保证了在最后提交阶段之前各参与节点的状态是一致的。 PS：3PC协议并没有完全解决数据一致性问题。 XA(强一致性)X/Open组织提出的分布式事务规范，是基于两阶段提交协议。XA规范主要定义了全局事务管理器（TM）和局部资源管理器（RM）之间的接口。是目前主流的关系型数据库的实现方式。为什么需要TM？在分布式系统中，从理论上讲两台机器无法达到一致的状态，需要引入一个单点进行协调。由全局事务管理器管理和协调事务，可以跨越多个资源和进程。事务管理器用来保证所有的事务参与者都完成了准备工作（第一阶段)。如果事务管理器收到所有参与者都准备好的消息，会通知所有的事务都可以提交了（第二阶段)。 Sega模式NWR协议是一种在分布式存储系统中用于控制一致性级别的一种策略。 N： 在分布式存储中，有多少备份数据； W： 代表一次成功的更新操作要求至少有w份数据写入成功； R：代表一次成功的读数据操作要至少有R份数据成功读取； 当W+R&gt;N的时候，整个系统对于客户端来讲能保证强一致性； 当R+W&lt;=N时，无法保证数据的强一致性； 服务治理服务协调分布式锁： 基于缓存（Redis）实现分布式锁，扩展是使用Redisson； Zookeeper实现分布式锁；原理：全局临时顺序节点； 流量销峰方案： 消息队列削峰； 流量削峰漏斗：层层削峰，如下图 服务降级整个架构整体的负载超过了预设的上限阀值或即将到来的流量预计将会超过预设的阀值时，为了保证重要或基本的服务能正常运行，我们可以将一些不重要或不紧急的服务或任务进行延迟或暂停使用；策略： 页面降级； 延迟服务（MQ）； 写降级（限流）； 读降级（限流）； 缓存降级 后端代码： 抛异常； 返回NULL； 调用Mock数据； 调用Fallback处理逻辑； 服务限流限流的目的是通过对并发访问请求进行限速或者一个时间窗口内的请求数量进行限速来保护系统，一旦达到了限制速率则可以拒绝服务、排队或等待； 备注：tomcat的处理请求的参数设置：tomcat的并发数有以下两个参数控制：maxThreads：tomcat启动的最大线程数，即同时处理的任务个数，默认值是200；acceptCount：当tomcat启动的线程数达到最大时，接受排队的请求个数，默认值为100；另外还有支持的最大链接数：maxConnections：tomcat在任意时刻接受和处理的最大连接数。当接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomacat接收的连接数小于maxConnections。默认的最大连接数为10000。 参考博文：https://www.cnblogs.com/sunfie/p/12295945.html 限流算法 固定窗口计数器计数器限制每一分钟或者每一秒内请求不能超过一定的次数，在下一秒钟（下一分钟）计数器清零重新计算。 问题：容易形成流量突刺 滑动窗口计数器滑动窗口其实是细分后的计数器，它将每个时间窗口又细分成若干个时间片段，每过一个时间片段，整个时间窗口就会往右移动一格。 漏桶通过一个固定大小的FIFO队列+定时取队列元素的方式实现，请求进入队列后会被匀速的取出处理，当队列被占满后，后来的请求会被直接拒绝。优点：可以销峰填谷，不论请求多快多大，都只会匀速的发给后端，不会出现突刺现象，保证下游服务正常运行，缺点：队列中的请求会被排队，影响时间被拉长。 令牌桶算法令牌痛算法是以一个固定速率往桶中放置令牌（如果桶中的令牌满了就丢弃），每进来一个请求就去桶中找令牌，有的话就拿走令牌继续处理，没有的就拒绝请求。 优点：可以应对突发流量，当桶中有令牌时可以快速的响应，也不会产生漏桶算法中的等待时间；缺点：相比较漏桶算法，一定程度上减少了对下游服务的保护； 基于Guava的令牌桶算法的设计参考博文：https://juejin.cn/post/6961815018488725541 怎么实现一个限流器？基于Redis限流 基于Redis做限流操作，使用lua脚本保证命令原子性，比如qps设置为10，如果key不存在，就设置key过期时间1s，value=1；如果value小于10，则自增value；value达到10触发流控。示例lua代码如下： 123456789101112131415161718//获取令牌Token， 参数规则Id，获取令牌数，优先级 TokenResult requestToken(Long ruleId, int acquireCount, boolean prioritized); local key = &quot;rate.limit:&quot; .. KEYS[1]local limit = tonumber(ARGV[1])local expire_time = ARGV[2]local is_exists = redis.call(&quot;EXISTS&quot;, key)if is_exists == 1 then if redis.call(&quot;INCR&quot;, key) &gt; limit then return 0 else return 1 endelse redis.call(&quot;SET&quot;, key, 1) redis.call(&quot;EXPIRE&quot;, key, expire_time) return 1end 服务熔断当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护系统的整体可用性，可以暂时切断对下游服务的调用，这种牺牲局部，保全整体的措施叫做熔断。熔断机制： 开启熔断：在固定的时间窗口内，接口调用超时比率达到一个阀值，会开启熔断；进入熔断后，后续对该服务接口的调用不再经过网络，直接执行本地的默认方法，达到服务降级的效果。 熔断恢复：熔断不可能是永久的。当经过了规定时间以后，服务将从熔断状态恢复过来，再次调用下游服务。 实现： spring cloud hystrix 三种状态： 熔断关闭状态（Closed） 熔断开启状态（Open） 10秒中50%的出错比率 半熔断状态（Half-Open）","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/RPC/RPC","date":"2022-02-24T01:54:52.536Z","updated":"2022-02-24T01:54:52.536Z","comments":true,"path":"2022/02/24/typora文件集合/拉钩/中间件/RPC/RPC/","link":"","permalink":"http://example.com/2022/02/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/RPC/RPC/","excerpt":"","text":"[TOC] 了解rpc吗？RPC远程过程调用，借助RPC可以做到像本地调用一样调用远程服务，是一种进程间的通讯方式。 RPC的架构（组成部分）： 客户端（client），服务的调用方； 客户端存根（stub），存放服务端地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程调用发送给服务方； 服务端（server）：真正的服务提供者； 服务端存根（server stub）：解析客户端发送过来的数据包，调用本地方法；有哪些常见的rpc框架？ 如何自己设计一个rpc框架？ 服务注册与发现：注册中心只需要能存储服务信息即可，并且一定要保证高可用性；不要服务中心挂掉了，所有的服务都用不了了。常用的软件： zookeeper Etcd Consul Nacos（阿里的Nacos可以实现动态服务配置、服务发现、服务元数据以及流量管理等） 服务入口在Java中，远程调用，我们不可能把每个服务接口都暴露在外面，而是一个入口接受参数，再由这个入口分发到系统内部的某个服务，调用后返回结果。 序列化 grpc hession java自带的序列化 json/xml 负载均衡算法 轮训 随机 权重 最少连接 ip_hash Dubbo了解吗？Dubbo 提供了哪些负载均衡策略？ 基于hash一致性的ConsistentHashLoadBalance； 基于权重随机算法的RandomLoadBalance； 基于最少活跃调用算法的LeastActiveLoadBalance; 基于加权轮询算法的RoundRobinLoadBalance； 基于最短响应时间的ShortestResponseLoadBalance; 如何设计一个网关核心设计： 请求路由 服务注册 负责均衡 弹力设计： 增加异步、重试、幂等、流控、降级、熔断、监视等功能； 安全方面：权限控制、数据校验、SSL加密及证书管理 灰度发布：测试版本在某些服务器上进行发布； API聚合/API编排 重点： 高性能：使用异步非阻塞的通信框架Netty； 高可用：集群化设计，并且不同的节点之间需要同步数据； 服务化：提供一个Admin API来在运行时修改自己的配置； 高扩展性：网关或多或少会有一些业务逻辑，而业务是多变的，因此网关需要有扩展性； 运维方面： 业务送耦合、协议紧耦合； 应用监控，提供分析数据；分布式链路追踪 DevOps； 架构： 不要在网关中内置聚合后端服务的功能，采用plugin的方式； 网关应该靠近后端服务，并合后端服务使用同一个内网，这样可以保证通信的低延迟； 要支持容量扩展，所以需要成为一个集群来分担前端带来的流量； 服务发现可以有缓存； 校验用户请求：用户是否已经登陆，token验证； 监控，比如说检测异常访问； 谈谈对微服务的认识？网络http/http2","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/Redis/Redis","date":"2022-02-24T01:54:19.369Z","updated":"2022-02-24T01:54:19.369Z","comments":true,"path":"2022/02/24/typora文件集合/拉钩/中间件/Redis/Redis/","link":"","permalink":"http://example.com/2022/02/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/Redis/","excerpt":"","text":"[TOC] Redis的基本数据结构 Hash、Set 、Sorted Set、List、Geo、String等数据类型 数据库由redis.h中的RedisDb定义，初始化的时候，会预先分配16个数据库；所有的数据库保存到结构RedisServer的一个成员RedisServer.db 数组中。redisClient中存在一个名叫db的指针指向当前使用的数据库。 RedisObject结构：value是一个对象，包含字符串、列表、哈希对象、集合对象和有序集合对象； 字符串：Redis使用SDS（Simple Dynamic String）用于存储字符串和整型数据； 优势： SDS在C语言字符串的基础上加入了free和len字段，获取字符串长度的时间复杂度是O(1)，C是O(n); SDS由于记录了长度，在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区的溢出； 可以存取二进制数据，以字符串长度len来作为结束标识； 使用场景：存储字符串和整型数据、存储key、AOF缓冲区和用户输入缓冲； 有序集合跳表 ： 将有序链表中的部分节点分层，每一层都是一个有序链表； 查找过程：在查找时优先从最高层开始向后查找，当达到某个节点时，如果next节点值大于要查找的值或next指针指向null，则从==当前节点==下降一层继续向后查找。 插入：通过抛硬币（概率1/2）的方式来决定新插入结点跨越的层数；正面：插入上层；背面：不插入 删除：找到指定元素并删除每层的该元素即可； 特点： 每层都是一个有序链表； 查找的次数近似等于层数（1/2）； 底层包含所有元素； 空间复杂度O(n)扩充了一倍； 实现：利用zskiplist实现； 优势： 可以快速查找需要的节点O(logn); 可以在O(1)的时间复杂度下，快速获得跳跃表的头节点、尾节点、长度和高度；（zskiplist存储了这些信息）； 字典（hash散列表）hash冲突：采用单链表在相同的下标位置存储原始的key和value； 实现：包括：字典（dict）、Hash表（dictht）、Hash表节点（dictEntry）； 用途：出了可以存储K-V数据以外，还可以用于：散列表对象、哨兵模式中的主从节点管理； 扩容：存储上限：阀值0.75，需要rehash（扩容） 说明： 初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍； rehashidx，rehash标识。=0表示要进行rehash操作； 新增加的数据在新的hash表h[1]； 修改、删除、查询都在老的hash表h[0]、新hash表h[1]中（reshash中）； 将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为rehash。 渐进式hash：服务器忙的时候，则只对一个节点进rehash，服务器闲，可批量rehash（100节点）； 压缩列表（ziplist）压缩列表(ziplist)是由一系列特殊编码的连续内存块组成的顺序型数据结构 快速列表快速列表（quicklist）是Redis底层重要的数据结构，是列表的底层实现；快速列表是一个双向链表，链表中的每个节点是一个ziplist结构。quicklist中的每个节点ziplist都能够存储多个数据元素；双向链表的优势: 双向:链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。 普通链表(单链表):节点类保留下一节点的引用。链表类只保留头节点的引用，只能从头节点插 入删除； 无环:表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结 束。环状:头的前一个节点指向尾节点 带链表长度计数器:通过 len 属性获取链表长度的时间复杂度为 O(1)。 多态:链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。 10中encodingencoding 表示对象的内部编码，占 4 位。Redis通过 encoding 属性为对象设置不同的编码。 String的有三个：int（int类型的整数）、embstr（编码的简单动态字符串，长度小于44字节）、raw（简单动态字符串，长度大于44字节）； list的是quicklist（快速列表）； hash的是字典和压缩列表；dict（字典，散列表元素个数比较多或元素不是小整数或短字符串时），ziplist（当散列表的元素个数比较少，且元素都是小整型或短字符串时） set的是整型集合（intSet 都是整数并且在64位有符号整数范围内）和字典（非整数或在64位有符号整数范围以外）； zset的是：压缩列表和跳表+字典； 和memcache的区别： Redis的淘汰策略LRU：最近最少使用方式； LFU：最不经常使用方式； LEU:当内存满的时候，直接丢弃新的key值的写入； Redis的过期策略：主动过期+惰性过期两种；主动过期：redis默认每隔100ms就随机抽取一些设置了过期的key，检查是否过期，如果过期了就删除。惰性过期：过期的key，没有及时删除，那么在查询的时候，redis才会删除。 Redis的高可用性为什么是高性能的？redis内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以redis是单线程模型。它采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器进行处理。文件事件处理器包含4个部分： 多个socket； IO多路复用程序； 文件事件派发器； 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个socket会产生不同的操作，每个操作对应不同的文件事件。但是IO多路复用程序会监听多个socket，并将这些事件放到一个队列中去。文件事件派发器会从队列中取出一个事件，派发给对应的事件处理器进行处理。 持久化方式RDB复制和AOF复制 RDB复制全量复制。 AOF复制增量同步复制。原理：AOF文件中存储的是redis的命令，同步命令到 AOF 文件的整个过程可以分为三个阶段: 命令传播:Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。 缓存追加:AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加 到服务器的 AOF 缓存中。* 文件写入和保存:AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。 AOF的3种刷盘机制： Appendfsync always:每次写入磁盘都刷盘，对性能影响最大，占用IO比较高，数据安全型最高； appendfsync everysec：1秒刷一次盘，对性能影响最小，数据安全性低，节点宕机时最多丢失1秒数据； appendfsync no：按照操作系统机制刷盘，对性能影响最小，但是数据安全性低； 主从同步性能指标Redis的常用问题DB和缓存数据的不一致性不一致一方面有可能是更新db和redis的时候失败了，导致不一致，还有一种情况就是两者更新的中间某一时刻，其他线程进行请求，这个时候就会请求到老的数据，造成数据的不一致。 优先采用：先更新数据库、再删除缓存的策略。 怎么解决不一致问题？延迟删除？答：强一致性很难，追求最终一致性（需要时间）； 利用Redis的缓存淘汰策略被动更新 LRU 、LFU； 利用TTL被动更新； 在更新数据库时主动更新 (先更数据库再删缓存—-延时双删)； 异步更新 定时任务 数据不保证时时一致 不穿DB； 缓存穿透、击穿、雪崩 缓存穿透：客户端发起了大量的不存在的key的请求，这个时候缓存查询不到，就去请求数据库。相当于直接穿透缓存打到DB。怎么解决： 布隆过滤器； 缓存无效的key，并设置过期时间。key值的设计 表明名:列名:主键值 缓存击穿 户端同一个key短时间内有大量的请求，然后恰好这个时候，这个key的缓存失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。 怎么解决： 对于热点key可以不用设置过期时间； 使用互斥锁。如果缓存失效，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库被打死。 缓存雪崩： redis大量的key失效，造成缓存功能失效，请求直接打到db，造成数据库压力增大。怎么解决： 事前：尽量保证整个redis集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略； 事中： 本地ehcache缓存+hystrix限流&amp;降级，避免MySQL崩掉； 事后：利用redis持久化机制保存的数据库尽恢复缓存。 怎么处理热点缓存提前预热：把热点数据提前加载到缓存中。 MySQL⾥有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据? 保留热点数据。淘汰策略使用allkeys-lru. 保证Redis中只存20W的数据。 分布式锁的使用情况、和Redission的区别redis分布式锁：setNx命令；Redission框架：参考地址 ​ 加锁：如果客户端面临的是一个redis cluster 集群，首先会根据hash节点选择一台机器； 发送lua脚本到redis服务器上； 使用exists myLock 命令判断一下，如果key不存在的话，就进行加锁，使用hset myLock命令，需要注意的是value是客户端的Id（UUID）+线程id,并设置过期时间； 如果了另一个客户端请求，会发现key已经存在，然后判断hash数据结构中是否包含客户端2的id，没有的话，返回key的剩余生存时间；这个时候，客户端2会继续尝试获取； 一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每个10s检查下，如果客户端1还持有锁，就会不断延长key的生存时间； 重入：如果客户端1再次加锁，就会将hash数据结构中的值加一； 解锁：每次对myLock数据结构中的那个加锁次数减1。如果发现是0了，说明这个客户端已经不再持有锁了，那么这个时候就可以删除这个key了，同时会发布一个redis解锁的消息给其他的客户端；如果不是0，就会继续延长这个锁的超时时间； 利用redis还可以实现哪些常用的功能？怎么解决库存超卖问题？答：见高并发下库存扣减； 大key问题 string类型的big key，不要放到redis中； 单个简单的key存储的value很大，可以尝试将对象拆分成几个key-value，使用mget的方式获取值，这样的话，分拆单次操作的压力，将整个压力平摊到多次操作中，降低对redis的IO影响。 hash、","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/ES/ES","date":"2022-02-24T01:53:58.069Z","updated":"2022-02-24T01:53:58.069Z","comments":true,"path":"2022/02/24/typora文件集合/拉钩/中间件/ES/ES/","link":"","permalink":"http://example.com/2022/02/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/ES/ES/","excerpt":"","text":"[TOC] 正排索引与倒排索引ES的分片基本概念基本的存储单元是shard，一个index可能分为多个shard，每个shard可以分布在不同的机器上。然后一个shad是有多个Segment组成，每个Segment是一些倒排索引的集合。然后每次创建一个新的Document或更新一个Document，都会归属于一个新的Segment（同样会被记录到commit point里面），而不是去修改原来的Segment。每次文档的删除操作，会仅仅标记Segment中该文档为删除状态，而不是真正的立马删除。 几个重要的概念：Memory Buffer与Translog、commit point（记录着所有的segemnt信息，es在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片） 原因：每次commit操作意味着将Segment合并，并写入磁盘。但是这样做是很重的IO操作，所以为了提升机器性能和近实时搜索，新文档会被首先写入到内存Buffer和translog文件中，每个shard对应一个translog文件。translog的作用： 保证文件缓存中的文档不丢失； 系统重启时，从translog中年恢复； 新的segment收录到commit point中； ![ES Shard的组成部分](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES Shard的组成部分.png) *** write/refresh/flush过程*** ![ES write:refresh:flush总体流程图](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES write:refresh:flush总体流程图.png) write过程当写请求发送到es后，es将数据暂存写入memory buffer中，同时会写入到translog文件中；如下图：![ES write操作](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES write操作.png) refresh过程 将内存缓冲区的文档写入到新的Segment中，同时这个段被打开，使其可以被搜索到。这个时候Segment是存储在文件缓存系统中的。 内存缓冲区被清空，但translog没有被清空，是为了后面的flush操作； ![ES refresh操作](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES refresh操作.png) flush过程触发机制：translog变得越来越大、索引被刷新； 所有内存缓冲区的文档都会被写入一个新的段中； 缓冲区被清空； 一个提交点被写入硬盘（记录被flush到磁盘的段）； 文件系统缓存通过fsync被刷新到磁盘（flush）； 老的translog被删除； ![ES flush过程](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES flush过程.png) PS：当es重新启动的时候或索引重新打开的时候，他会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放translog中所有在最后一次提交后发生的变更操作。 merger过程 合并进程选择一小部分大小相似的段，并且在后台将他们合并到更大的段中。这并不会中断索引和搜索； 新的段被打开用来搜索； 老的段被删除； ![image-20211018065648999](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211018065648999.png) 常见问题排查高CPU场景 查看节点hot thread 12GET _nodes/hot_threadsGET _nodes/&lt;node_name&gt;/hot_threads 查看线程池 12GET _cat/thread_poolGET _cat/thread_pool/force_merge?v&amp;s=name 查看线程池使用的情况可快速定位当前集群线程池使用情况； 可查看具体节点的某个线程池的使用情况； 查看当前任务 123GET _cat/tasks?detailedGET _tasks?actions=*bulk&amp;detailedGET _tasks?actions=*search&amp;detailed 取消任务 1POST _tasks/&lt;taskId&gt;/_cancel 根据上一步拿到的任务id进行取消操作 查看索引的迁移进度 1GET _cat/recovery/&lt;index_name&gt;?v 高内存场景Es的高JVM内存压力可能是以下原因造成的： 集群的请求数量激增； 聚合、通配符以及在查询中选择了较宽的时间范围； 各节点间的分区分配不均衡或者一个集群中的分区太多； 字段数据或索引映射激增； 无法处理传入负载的实例类型； 查看缓存 123GET /_stats/query_cacheGET /_stats/fielddata_cacheGET /_stats/request_cache 清理缓存 1234POST /&lt;index_name&gt;/_cache/clearPOST /&lt;index_name&gt;/_cache/clear?fileddata=truePOST /&lt;index_name&gt;/_cache/clear?query=truePOST /&lt;index_name&gt;/_cache/clear?request=true 慢查询定位分页 分页方式 性能 优点 缺点 场景 from+size 低 灵活性好，实现简单 存在深度分页问题 数据量比较小，能容内深度分页的问题 Scroll 中 解决了深度分页问题 无法反映数据的实时性（快照版本），维护成本高，需要维护一个scroll_id 海量数据的导出 Search_after 高 性能最好，不存在深度分页问题，能够反映数据的实时性 实现比较复杂，每一次查询都需要上次查询的结果 海量数据的分页 集群规划 怎么规划？需要从以下两个方面考虑： 当前的数据量有多大？数据增长情况如何？ 机器规格，cpu、多大内存、多大硬盘容量？ es的JVM heap最大可以设置==32G==。如果机器的内存很大，可以考虑在一台机器上运行多个es节点实例。集群规划满足当前数据规模+适量增长规模即可，后续可按需扩展； 场景分析：A 对于业务搜索功能模块，且多是垂直领域的搜索。数据量级几千万到数十亿级别，一般是2-4台机器的规模。 B 大规模的OLAP，需要几十到几百的节点的规模。 节点角色ES节点有Master、DataNode（默认是数据节点）、Coordinate node三种。Coordinate Node: 协调节点，一个节点只接收请求、转发请求到其他节点、汇总各个节点返回数据等功能的节点。一个节点可以充当一个或者多个角色，默认三个都有。对于中大规模的集群，应当考虑角色分开。这样不会因为协调节点负载过高而影响数据节点的能力。 脑裂问题 6.x和之前版本： discovery.zen.minimum_master_nodes: (有master资格节点数/2) + 1 这个参数控制的是，选举主节点时需要看到最少多少个具有master资格的活节点，才能进行选举。官方 的推荐值是(N/2)+1，其中N是具有master资格的节点的数量。 7.x以后：集群自己控制，启动的一个新的集群的时候需要有cluster.inital_master_nodes初始化集群列表。 常用做法（中大规模集群）：： 12345671)Master 和 dataNode 角色分开，配置奇数个master，如3 2)单播发现机制，配置master资格节点(5.0之前): discovery.zen.ping.multicast.enabled: false —— 关闭多播发现机制，默认是关闭的 3)延长ping master的等待时长discovery.zen.ping_timeout: 30(默认值是3秒)——其他节点ping主节点多久时间没有响应就认为主节点不可用了。es7中换成了 discovery.request_peers_timeout 分片设置： ElasticSearch推荐的最大JVM堆空间是3032G, 所以把你的分片最大容量限制为30GB, 然后再对分片数量做合理估算. 例如, 你认为你的数据能达到200GB, 推荐你最多分配7到8个分片。在开始阶段, 一个好的方案是根据你的节点数量按照1.53倍的原则来创建分片. 例如,如果你有3个节点, 则推荐你创建的分片数最多不超过9(3x3)个。当性能下降时，增加节点，ES会平衡分片的放置。副本：为保证高可用性，副本数设置2即可。要求集群至少有3个节点，来分开存放主分片、副本。并发量大时，查询性能会下降，可增加副本数，来提升并发查询能力。 集群调优写: 首次向集群中灌入数据，可以将副本数设置为0，写入完再调整回去，这样副本分片只需要拷贝，节省了索引的过程； 1234PUT /&lt;index_name&gt;/_settings &#123;&quot;number_of_replicas&quot;: 0 &#125; 自动生成doc ID如果写入doc时指定了id，es会尝试读取原来的doc版本号，以判断是否需要更新。这回设计一次读取磁盘的操作。 设置合理的mapping 将不需要建立索引的字段index属性设置为not_analyzed或no； 减少字段内容长度； 使用不同的分词器； 调整_source字段 对analyzed的字段禁用norms; 调整索引的刷新间隔，如果对实时性要求不高的话； 批处理； Document的路由处理（设置合理的分片） ES默认的路由是根据id，也可以在发送请求时手动指定一个routing value，例如： 1PUT /index/doc/id?routing=user_id 读: 数据分组对数据进行基于天来建立索引，一个例子，日志系统； ID字段类型定义为keyword一般情况下，id字段不会被用作range类型搜索。keyword会被优化，以便进行terms查询。性能大约会提升30%。 限制用户的输入的条件；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/分享/感想","date":"2022-02-24T01:42:30.492Z","updated":"2022-02-24T01:43:05.795Z","comments":true,"path":"2022/02/24/typora文件集合/拉钩/分享/感想/","link":"","permalink":"http://example.com/2022/02/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%88%86%E4%BA%AB/%E6%84%9F%E6%83%B3/","excerpt":"","text":"短期学习计划：SMART原则 1.目标必须是具体的（Specific）：阅读Java多线程编程核心技术，深入掌握多线程中AQS的底层原理、锁与相关API工具类的应用； 2.目标必须是可以衡量的（Measurable）：每周输出一个工具类的架构图，并练习相应的Demo； 3.目标必须是可以达到的（Attainable）：画出AQS中底层的ReentrantLock与CountDownLatch等API工具类的源码调用关系图，并输出笔记； 4.目标必须是要与其他目标具有一定的相关性(Relevant)： 配合完成第二阶段模块三学习：并发编程与环境优化； 5.目标必须具有明确的截止期限（Time-bound）：圣诞节前完成；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/答疑/1月23号答疑","date":"2022-02-23T11:17:03.574Z","updated":"2022-02-23T12:42:47.936Z","comments":true,"path":"2022/02/23/typora文件集合/拉钩/答疑/1月23号答疑/","link":"","permalink":"http://example.com/2022/02/23/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E7%AD%94%E7%96%91/1%E6%9C%8823%E5%8F%B7%E7%AD%94%E7%96%91/","excerpt":"","text":"问题： 一、腾讯（QQ社区基础平台建设岗位）：面试内容：主要有三个模块：（1）主要介绍项目，遇到的难题，解决方案，用到的技术等；（2）redis，场景设计：如果让你用redis设计全国高考的排行榜，你怎么设计，可以结合数据库，也可以不结合 中间引出的问题： a.你在做排行榜的时候用到了zset那么他的底层数据结构是什么 b.你知道跳表的一个时间复杂度和空间复杂度吗，比如说他最高几层，为什么设计成这样子，如果这个高度还是不够呢，要怎么办 c.你知道redis存储数据的时候如果超出了他的存储空间，他的一个淘汰机制是怎么样的吗（3）mysql这里我是自由发挥，然后中间问了一些索引的问题问题不大 二、腾讯（手机QQ小世界业务部门岗位）：面试内容：主要有四个模块：（1）算法题：反转链表（2）redis，让你用redis去设计一个权限管理，比如说你校长登录这个系统，用什么数据结构去存，怎么能判断到是校长登录了（这里真的是经验不足，没有准备到位，难受，redis没怎么用过，诶）（3）mysql，分表，采取的是按照字段去进行一个垂直分表的方式，我怎么去得到我想要的某一个指定的ID（4）主要介绍项目，遇到的难题，解决方案，用到的技术等； 三、富途（ToB业务后台开发岗位）：面试内容：主要有三个模块：（1）网络相关的一些只是： a.HTTP和HTTPS的区别 b.HTTPS中的这个SSL里面是怎么加密的，你后台是怎么得到这个秘钥的，这样一个加密过程，然后证书是什么，跟加密有什么关系 c.各个状态码，1xxx代表什么，2xxx代表什么，3xxx代表什么，4xxx代表什么，5xxx代表什么。 d.加密算法有哪些，了解散列算法吗 e.场景设计题：假如公司里面用户登录用的密码的加密算法是你写的，一开始你写了A算法，那么后面你觉得B算法不好，想要换成B算法，这个时候你要怎么换 （注：由于编译方式不同，所以A算法加密的密码，B算法肯定是不适用的）（2）数据库： a.分库分表：跟腾讯内容类似，但是问了水平拆分怎么去分（水平拆分也是没经验，准备不到位，不懂啊） b.场景设计题：如果说生产环境上的数据库忘了加一个索引，你怎么在不停机的情况下去把这个索引加上去 （注：我这里设想的是去加一张中间表，把需要的索引放在这个中间表上面，面试官说我答对了一半，还要去思考怎么去把这个表的数据转移过去）（3）笔试题： a.数据库： user表：username，uid， tie表(帖子表)：uid，content， （多余字段记不得了，不关键） 请写一条sql，查出发帖数量最多的前十位用户的名字和发帖数 b.算法题： leetcode1353,但是有所不同，他给的入参是double类型 跳表的最大高度？ 最高32层。 跳跃表的是时间复杂度是：O(logn)，空间复杂度是： 跳表中数据的删除，不影响层高的显示。 开始最高层 forward 指针开始，forward 指向 null，说明这一层遍历结束了。就降一层，继续forward。 附跳跃表的数据结构： 为什么MySQL 底层的数据结构是B+树，而Redis底层的数据结构是跳表？ 因为B+tree比跳跃表的检索效率更高，数据分部的更均匀。 跳跃表是通过二路分治的方式实现logN。B+Tree是通过多路分治的方式实现logN。 当数据表的数据足够多的时候，B+tree的根节点～任何一块叶子节点的路径是固定的。而skiplist的头节点～目标节点的路径是不固定的。所以检索的value越大，skiplist的路径就越深，磁盘的io次数就越多。 B+tree的所有叶子节点构成了一个双向循环链表，每一块叶子节点可以存储一条或者多条数据。这种结构不管是一条记录、还是多条记录查询都能节省磁盘IO。 skiplist的每一个节点只存储一条记录，对于一条记录的查询是比较节省磁盘io，对于多条记录的查询，skiplist的磁盘IO次数会比B+tree要多。 但是Redis是基于内存的，不存在磁盘的IO操作。","categories":[],"tags":[]},{"title":"禁运禁售重构","slug":"wholee/禁运禁售重构","date":"2022-02-23T02:02:56.803Z","updated":"2022-03-19T13:55:36.675Z","comments":true,"path":"2022/02/23/wholee/禁运禁售重构/","link":"","permalink":"http://example.com/2022/02/23/wholee/%E7%A6%81%E8%BF%90%E7%A6%81%E5%94%AE%E9%87%8D%E6%9E%84/","excerpt":"","text":"服务梳理product-manage中提供的服务 编号 服务全限定名 备注 1 com.clubfactory.center.product.api.tagsForKafka#buildFbAndTrInfoByTagIds 废弃 2 com.clubfactory.center.product.biz.spclogs.productTags.ProductTagLogBiz#sendTagLog 封装好的日志上报类，可供参考 3 com.clubfactory.center.product.dto.exception.ProductCenterException 系统运行时异常类 4 各个工程的pom版本号：product-center 1.6.00-SNAPSHOT； product-manage 2.2.00-SNAPSHOT 大数据回流任务： 每个回流任务调用的是manage的这个方法：com.clubfactory.center.product.api.impl.ProductAPIImpl#removeTagByProductIdList","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"","slug":"typora文件集合/技术/技术笔记/设计/数据库E-R关系图设计总结","date":"2022-02-22T02:10:30.196Z","updated":"2022-03-15T06:56:12.212Z","comments":true,"path":"2022/02/22/typora文件集合/技术/技术笔记/设计/数据库E-R关系图设计总结/","link":"","permalink":"http://example.com/2022/02/22/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E5%BA%93E-R%E5%85%B3%E7%B3%BB%E5%9B%BE%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93/","excerpt":"","text":"什么是E-R关系图？ Visio给出的定义：https://www.visual-paradigm.com/cn/guide/data-modeling/what-is-entity-relationship-diagram/ 利用Navicate画E-R图； 1、点击Model-》添加按钮： 2、出现如下的弹窗： 第一个是物理类型：是对物理数据库的建模，需要选择数据库的版本号； 第二个是逻辑类型：是建立表之间的逻辑关系模型，不需要选择数据的版本号； 第三个是conceptual(概念性)，还不确定具体的含义。 进入设计界面： 一个完工的E-R图大概是如下图所示： 常用的几个功能： 在空白区右键点击，出现弹窗： 解释： Entity代表实体； Note代表备注，上图中黄色的图形； Image是插入图片； Layer是图层的意思，可以实现类似PS中的图层的效果； Shape（图形）： 5.1 Line 简单的线条； 5.2 Arrow 箭头； 5.3 Rectangle 添加正方形； 5.4 Ellipse：添加椭圆； 5.5 User：添加人形； 5.6 Database ：添加数据库图形； 5.7 Cloud：添加云的图形； 5.8 Trigger：添加触发器： 5.9 Server：添加服务器图形； 5.10 Desktop：添加电脑桌面图案； 5.11 Mobile： 添加手机图形； Lable：添加普通的lable； 建立表之间的Relation： &lt;video id=”video” controls=””src=”/Users/xiazhenyu/Pictures/Photos Library.photoslibrary/originals/2/2A9681AA-A5A6-42AC-8324-CE92116090D2.mov” preload=”none”&gt; Relations的一些操作在右侧列表中。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/设计/时序图","date":"2022-02-22T01:38:10.858Z","updated":"2022-02-22T01:39:41.133Z","comments":true,"path":"2022/02/22/typora文件集合/技术/技术笔记/设计/时序图/","link":"","permalink":"http://example.com/2022/02/22/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1/%E6%97%B6%E5%BA%8F%E5%9B%BE/","excerpt":"","text":"什么是时序图？ 时序图的作用？ 参考博文：https://www.jianshu.com/p/c5209bde7287 官方介绍：https://www.uml-diagrams.org/sequence-diagrams.html","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/JVM总结","date":"2022-02-19T14:50:48.224Z","updated":"2022-02-20T09:46:38.234Z","comments":true,"path":"2022/02/19/typora文件集合/拉钩/JVM/JVM总结/","link":"","permalink":"http://example.com/2022/02/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/JVM%E6%80%BB%E7%BB%93/","excerpt":"","text":"第一部分： JVM的运行时内存划分第二部分：垃圾回收的基础理论垃圾收集： 当前的主流的商业虚拟机的垃圾收集器，大多数采用了“分代收集”的理论进行的设计。分代收集是一个理论，实质是一套符合大多数程序运行实际情况的经验法则，建立在两个分代假说之上： 弱分代假说：绝大多数对象都是朝生夕灭的。 强分代假说：熬过越多次垃圾回收过程的对象就越难以消亡。 基于上述的假说，多款垃圾收集器（Serial、CMS等）将Java堆划分为不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储。显而易见，如果一个区域中大多数对象都是朝生夕灭，难以熬过垃圾收集过程的话，那么把它们集中放在一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象（这个是可达性分析算法的意义所在），就能以较低代价回收到大量的空间；如果剩下的都是难以消亡的对象，那把它们集中放在一块，虚拟机便可以使用较低的频率来回收这个区域。这就做到了同时兼顾垃圾收集的时间开销和内存的空间有效利用。 常见的垃圾收集算法： 标记-清除算法： 缺点： 执行效率不稳定。标记和清除两个动作的执行效率会随着对象数量的增长而降低； 容易产生内存空间的碎片化问题； 标记-复制算法 注意这个策略的使用的背景是，绝大多数对象都是朝生夕灭的。所以在Serial、ParNew等新生代垃圾收集器均采用了这种策略来设计新生代的内存布局：把新生代划分为Eden区+两个比较小的Survivor空间。 比例为8:1:1。 这个会产生一个问题：我们没有办法保证一次Minor GC之后，总是会有不超过10%的对象存活。所以需要依赖其他区域（大多数是老年代）进行分配担保。 标记-整理算法 标记过程和“标记-清除”算法一样，但是不是直接对可回收的对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。这个可以提高系统的吞吐量。 基于这个思想，我们发现，老年代其实并不适合这个算法，因为在老年代中，每次回收都会有大量的对象存活，移动存活对象并更新所有引用这些对象的地方将会是一种极为繁重的操作。而且我们发现，这个操作是需要STW的。但是不移动的话，就会导致标记-清除算法中的内存碎片化问题，这个问题会影响应用程序的吞吐量。 总结：标记-清除算法和标记-整理算法各有各的优点。关注吞吐量的一般使用标记-整理算法，比如Parallel Scavenge收集器；关注延迟的使用标记-清除算法，比如CMS收集器。 需要依赖的技术：1. 根结点的枚举。PS：此阶段是必须STW的。 HotSpot虚拟机的解决方案：使用了OopMap的数据结构。一旦类加载动作完成的时候，HotSpot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置（安全点）记录下栈里和寄存器里哪些位置是引用。这样收集器扫描的时候就可以直接得知这些信息了，并不需要真正一个不漏的从方法区等GC Roots开始查找。 2. 安全点方法调用、循环跳转、异常跳转，这些功能的指令才会产生安全点。 另一个问题：如何让所有线程在垃圾收集器发生时都跑到最近的安全点，然后停顿下来。 有两个可选的方案：抢先式中断、主动式中断（现在被采用的）。 3. 安全区域安全区域就是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，这个区域中任意地方开始垃圾收集都是线程安全的。解决应用程序处于Sleep状态或者是Blocked状态等处于”不执行“的时候的垃圾回收问题。 4.记忆集与卡表记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。这个记忆集并不需要很高的精度，只需要收集器能够通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了。常见的一些记录精度： 字长精度：每个记录精确到一个机器字长，该字长包含跨代指针； 对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针； 卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针； ​ 目前常用的是使用第三种方式，具体的是一种被称为“卡表（Card Table）”的方式去实现记忆集。 5. 写屏障作用：用以解决卡表元素维护，何时变脏、怎么维护变脏？ 在HotSpot虚拟机中是通过写屏障技术维护卡表状态的。写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环形（Around）通知，供程序执行额外的动作。在赋值前的部分的写屏障叫作写前屏障，在赋值后的则叫作写后屏障。 如何解决伪共享问题？ 不采用无条件的写屏障，而是先检查卡表标记，只有当该卡表元素未被标记过时才将其标记为变脏。 6. 并发的可达性分析白色：表示对象尚未被垃圾收集器访问过。可达性分析结束以后，对象仍然是白色，即代表不可达（可以被回收）。 黑色：表示对象已经被垃圾回收器访问过，且这个对象的所有引用都已经扫描过。 灰色：表示对象已经被垃圾收集器访问过，但是这个对象上至少存在一个引用还没有被扫描过。 对象消失问题产生的条件： 赋值器插入了一条或多条从黑色对象到白色对象的新引用； 赋值器删除了部分或全部从灰色对象到白色对象的直接或间接引用。 增量更新： 破坏了第一个条件。当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再以这些记录过的引用关系中的黑色对象为根，重新扫描一次。即黑色对象一旦插入了指向白色对象的引用之后，它就变成灰色对象了。 原始快照： 破坏了第二个条件。当灰色对象要删除指向白色对象的引用关系时，就讲这个要删除的引用记录下来，在并发扫描结束之后，再以这些记录过的引用关系中的灰色对象为根，重新扫描一次。即无论引用关系删除与否，都会按照刚开始扫描那一刻的对象图快照来进行搜索。 CMS基于增量更新来做并发标记的，G1、Shenansoah使用原始快照来实现的。 第三部分：常见的垃圾回收器 第四部分：类文件结构与类加载 第五部分：虚拟机字节码执行引擎 第六部分：JVM并行原理","categories":[],"tags":[]},{"title":"现有系统中间件","slug":"wholee/现有系统中间件","date":"2022-02-18T07:58:56.304Z","updated":"2022-03-19T13:55:16.337Z","comments":true,"path":"2022/02/18/wholee/现有系统中间件/","link":"","permalink":"http://example.com/2022/02/18/wholee/%E7%8E%B0%E6%9C%89%E7%B3%BB%E7%BB%9F%E4%B8%AD%E9%97%B4%E4%BB%B6/","excerpt":"","text":"ELK 简介： Elasticsearch是实时全文搜索和分析引擎，提供搜集、分析、存储数据三大功能，是一套开放REST和JAVA API等结构提供高效搜索功能，可扩展的分布式系统。它构建于Apache Lucene搜索引擎库之上。具有分布式，零配置，自动发现，索引自动分片，索引副本机制，restful 风格接口，多数据源，自动搜索负载等特点 Logstash它支持几乎任何类型的日志，包括系统日志、错误日志和自定义应用程序日志。它可以从许多来源接收日志，这些来源包括 syslog、消息传递（例如 RabbitMQ）和JMX，它能够以多种方式输出数据，包括电子邮件、websockets和Elasticsearch。 Kibana是一个基于Web的图形界面，用于搜索、分析和可视化存储在 Elasticsearch指标中的日志数据。它利用Elasticsearch的REST接口来检索数据，不仅允许用户创建他们自己的数据的定制仪表板视图，还允许他们以特殊的方式查询和过滤数据，Kibana 可以为 Logstash 和 Elasticsearch 提供友好的日志分析 web 界面，可以帮助你汇总、分析和搜索重要数据日志。","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"页面入口","slug":"wholee/页面入口","date":"2022-02-17T07:58:31.249Z","updated":"2022-03-19T13:56:14.896Z","comments":true,"path":"2022/02/17/wholee/页面入口/","link":"","permalink":"http://example.com/2022/02/17/wholee/%E9%A1%B5%E9%9D%A2%E5%85%A5%E5%8F%A3/","excerpt":"","text":"页面入口1新货品中心 货品管理-编辑货品 修改类目–&gt;触发修改标签–&gt;触发修改禁运禁售（类目维度）（根据类目打标的标签是不是不能删除？？） 修改标签–&gt;触发修改禁运禁售（货品维度） 货品管理-货品标签新增标签–&gt;触发生成禁运禁售规则 2.旧货品中心 标签管理-标签批量操作批量打标/去表–&gt;触发修改 禁运禁售（货品维度）标签管理-类目打标管理配置类目自动打标规则按规则打标–&gt;触发修改禁运禁售（类目维度）按规则取消–&gt;触发修改禁运禁售（类目维度） 标签管理-销售规则管理编辑–&gt;触发打标–&gt;触发修改禁运禁售（标签维度）标 签管理-运输规则管理编辑–&gt;触发打标–&gt;触发修改禁运禁售（标签维度） 定时任务根据数仓计算结果打标：com.clubfactory.center.product.job.controller.JobControllercom.clubfactory.center.product.job.controller.JobController#autoAddAndRemoveTagcom.clubfactory.center.product.job.controller.JobController#addAndRemove91Tagcom.clubfactory.center.product.job.controller.JobController#removeAll91Tagcom.clubfactory.center.product.job.controller.JobController#addAndRemove107Tag触发类目自动打标规则：com.clubfactory.center.product.job.job.ShippingRuleJob接口product-center-web根据页面入口来梳理product-manage新接口：操作货品（新增/审核/修改）com.clubfactory.center.product.api.product.ProductAPI#createProductcom.clubfactory.center.product.api.product.ProductAPI#commitPasscom.clubfactory.center.product.api.product.ProductAPI#updateProduct操作标签（添加/移除）com.clubfactory.center.product.api.product.ProductAPI#addTagByProductIdListcom.clubfactory.center.product.api.product.ProductAPI#addTagByProductNoListcom.clubfactory.center.product.api.product.ProductAPI#removeTagByProductIdListcom.clubfactory.center.product.api.product.ProductAPI#removeTagByProductNoList老接口：根据页面入口、定时任务来梳理product-center","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"现有系统问题","slug":"wholee/现有系统的问题","date":"2022-02-15T09:11:49.180Z","updated":"2022-03-19T19:33:00.913Z","comments":true,"path":"2022/02/15/wholee/现有系统的问题/","link":"","permalink":"http://example.com/2022/02/15/wholee/%E7%8E%B0%E6%9C%89%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"日志打的太多，而且不够准确，存在复制，不能准确定位到具体的代码； 缓存中的key统一都是prod开头，写死的，这个不会导致预发和线上共享同一个key了吗？ 拦截校验能否统一？ 主图： product_template 中的image_url； 轮播图： product_images中的url； sku图片：product_product中的imageUrl中； 商品sku图片： pt表中的数据需要重新刷下，需要把record表中的数据重新写入到pt表中的。","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"","slug":"typora文件集合/技术/技术笔记/积累","date":"2022-02-14T01:48:55.453Z","updated":"2022-03-07T06:36:08.388Z","comments":true,"path":"2022/02/14/typora文件集合/技术/技术笔记/积累/","link":"","permalink":"http://example.com/2022/02/14/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%A7%AF%E7%B4%AF/","excerpt":"","text":"Holder的类，一个例子EasyExcel中的Holder接口。","categories":[],"tags":[]},{"title":"常用网站与配置","slug":"wholee/常用网站与配置","date":"2022-02-11T02:34:10.266Z","updated":"2022-03-19T13:54:26.353Z","comments":true,"path":"2022/02/11/wholee/常用网站与配置/","link":"","permalink":"http://example.com/2022/02/11/wholee/%E5%B8%B8%E7%94%A8%E7%BD%91%E7%AB%99%E4%B8%8E%E9%85%8D%E7%BD%AE/","excerpt":"","text":"研发效能：Redis 查询配置这么查看redis的数据？首先需要在应用平台中的Apollo数据源中添加对应的Apollo配置，如下图所示： ​ 然后在Redis控制台中，选择对应的应用、环境、机房、Redis的关键词（这个对应的是上图中的配置前缀）以及命令，点击执行就可以进行查看了。 Redis测试环境的查询地址：http://owl.huoli101.com/#/redis-manager/console 应用：选择对应的项目； 环境：test 机房：aws-ningxia Redis：club-boot.redis.product-center-redis 跳板机地址 物理机的跳板机地址： http://jump.huoli101.com/ Iterm 可以通过jump自定义命令进行登录，如下图所示： 容器的跳板机地址: ​ ssh -p 10049 &#x7a;&#x68;&#101;&#x6e;&#x79;&#117;&#x78;&#x69;&#x61;&#x40;&#116;&#x72;&#x61;&#101;&#x66;&#105;&#107;&#x31;&#x2e;&#x6e;&#x78;&#x2e;&#104;&#117;&#x6f;&#x6c;&#x69;&#49;&#48;&#49;&#46;&#x63;&#111;&#x6d; PS:这个跳板板地址是在大禹系统进行配置的，参考地址：http://wiki.huoli101.com/pages/viewpage.action?pageId=53830581 可以通过Iterm工具进行自动登录； 数据库SQL审核/查询平台 地址：http://db.huoli101.com/#/home 常用数据库链接配置： 这个查询oodo库的相关配置。 网关请求地址配置http://dayu.huoli101.com/#/app/project-application/service-route","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"","slug":"typora文件集合/技术/技术笔记/Restful和RPC的思考","date":"2022-02-10T01:39:18.055Z","updated":"2022-02-10T01:40:44.594Z","comments":true,"path":"2022/02/10/typora文件集合/技术/技术笔记/Restful和RPC的思考/","link":"","permalink":"http://example.com/2022/02/10/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Restful%E5%92%8CRPC%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"","text":"什么是Restful？什么是RPC？","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/设计模式思考","date":"2022-01-29T06:35:28.385Z","updated":"2022-02-11T07:02:51.846Z","comments":true,"path":"2022/01/29/typora文件集合/技术/技术笔记/设计模式思考/","link":"","permalink":"http://example.com/2022/01/29/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%9D%E8%80%83/","excerpt":"","text":"自己对设计模式的思考 Builder模式构建者模式的主要点就是在一个类里面有一个静态类Builder，这个类里面的成员变量和外层的类中的成变量是一样的，里面提供了对每一个成员变量的操作方法，然后还有一个build签名函数，用以初始化这个静态的类。build里面调用的是外层的对象的构造函数，入参就是这个静态类，里面会把这个静态类的成员变量的值依次复制给外层对象中对应的成员变量。 在Spring中的应用： 责任链模式责任链模式的特点是可以一直把参数传递到下一个处理的handler下去，直到handler没有下一个要处理的了为止。基本的思想就是，我们要去定义一个抽象的基类，比如叫做ProcessorHandler,然后这个抽象类中是有一个引用类型的成员变量的，类型也是ProcessorHandler ，我们暂且把这变量叫做next吧。然后我们还需要定义一个方法handler()，接收的参数我们假设是一个接口HandlerInterface，里面的处理逻辑核心的是当next不为空或者null的时候，调用next的同名的方法签名。最后我们怎么使用呢？可以按照下面的步骤去做： 第一步：定义一个类，继承ProcessorHandler; 第二步：重写抽象父类中的handler()方法，我们可以在这个里面做一些自己的业务逻辑； 第三步：在handler()重写的实现方法的最后，我们要手动去调用下抽象父类的handler方法，让父类帮我们把处理逻辑给传递下去； 在Spring中的应用： 适配器模式 适配器的思想可以这么考虑。我们Class A已经实现了接口Interface 1了，我们不想在让他再去实现另外的一个接口了，但是我们现在这个Class A的要实现的功能却在另外的一个接口或者类中，这个时候我们就可以通过适配器的模式去做。同样的原理：我们写一个Adapter去实现Interface 1，我们在对应的方法中再去调用我们真正需要调用的类或者服务。，比如Class B中的某个方法。适配器模式的作用：我们通过增加一个新的适配器来解决接口不兼容的问题，使得原本没有任何关系的类可以协同工作。适配器模式在Spring中的应用： 通过上图，我们看到，AdvisorAdapter架起了Advice与MethodInterceptor之间的桥梁，可以根据输入的advisor，得到对应的advice，然后进一步调用adapter中的方法匹配到对应的MethodInterceptor。 装饰者模式我理解就是一个接口的实现类A中，有一个成员变量B，也实现了相同的接口，然后在A的实现的接口interface1()中，可以调用B的相同的接口，同时可以做些其他的操作。 策略模式策略模式其实就是把if语句块中的代码抽离出来，变成一个一个的策略，然后需要有一个入口去切换策略。目的是对同一个操作，不同的策略的实现是不同的。 策略模式的三个角色： Context 封装角色：也称为上下文角色，起到了封装的作用，屏蔽了高层模块对策略的直接访问； 策略抽象对象角色：定义策略的接口； 策略实现类：策略实现接口，实现具体的策略算法或行为内容并向外界暴露。 在Spring中的应用： loadBeanDefinition： 分析；context封装角色：AbstractXmlApplicationContext； 抽象对象角色：BeanDefinitionReader； 策略实现类：XmlBeanDefinitionReader和PropertiesBeanDefinitionReader，这个可以通过BeanDefinitionReader的实现类可以得知， 分析：context封装角色：AnnotationConfigWebApplicationContext抽象对象角色：这个从源码看，AnnotatedBeanDefinitionReader并不是一个接口或是抽象类，但是AnnotatedBeanDefinitionReader中有一个成员变量BeanDefinitionRegistry，这个是一个接口，从AnnotatedBeanDefinitionReader的初始化可以看出，这个接口的实现类是DefaultListableBeanFactory。所以个人理解抽象角色是BeanDefinitionRegistry。策略实现类角色：根据上面的分析，个人理解策略实现类是DefaultListableBeanFactory。 ResourceLoader: ResourceLoader接口的实现大致分为两大类：一个是直接的实现类DefaultResourceLoader，另一个是ResourcePatternResolver和ApplicationContext。 角色分析：context角色： AbstractBeanDefinitionReader；抽象策略：ResourceLoader；实现类角色：DefaultResourceLoader和ResourcePatternResolver。ResourceLoader是一个非常基础的接口，Spring框架中大量的类是实现了这个接口的。 观察者模式定义：观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。当主题对象状态发生变化的时候，会通知所有观察者，使观察者自己可以更新自己。 作用：让耦合的双方都依赖于抽象，而不是依赖于具体。从而使各自的变化不会影响到另一边的变化。并建立了一套触发机制。 1.Spring中的容器事件： ContextStartedEvent：ApplicationContext启动事件； ContextRefreshedEvent：ApplicationContext更新事件； ContextStoppedEvent：ApplicationContext停止事件； ContextClosedEvent：ApplicationContext关闭事件； 2.事件监听者：有两种方式，一种是通过继承ApplicationListener接口，然后是在onApplicationEvent()方法中处理事件。另一种是采用注解的形式：@EventListener。注解的实现原理： EventListenerMethodProcessor中的初始化之后调用的方法afterSingletonsInstantiated中，这个里面会去遍历所有的bean， 然后调用processBean方法。 提取出EventListener注解修饰的方法并根据注解的参数创建ApplicationListener对象加入到ApplicationContext的监听列表中。 监听列表是在哪里呢？从源码可以看出，一个是存放到了AbstractApplicationContext的applicationListeners中去，一个是存放到了名为AbstractApplicationEventMulticaster的对象中去， 3. 发布事件事件发布的入口是在ApplicationEventPublish接口中的publishEvent方法，但是具体的实现是在ApplicationEventMulticater中。 此处调用了SimpleApplicationEventMulticaster中的multicastEvent方法进行事件的发布。 从上图可以看出，SimpleApplicationEventMulticaster进行事件的发布是支持线程池异步发布的–只要对应的Executor是不为null的。 然后我们看这里，从这里我们可以看到，发布和订阅之间的关系了。之所以发布的事件，订阅者能接受到，是因为在发布的时候，最终调用的是ApplicationListener的onApplicationEvent方法。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/1月26号答疑","date":"2022-01-26T11:38:04.915Z","updated":"2022-01-27T01:36:27.106Z","comments":true,"path":"2022/01/26/typora文件集合/拉钩/JVM/1月26号答疑/","link":"","permalink":"http://example.com/2022/01/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/1%E6%9C%8826%E5%8F%B7%E7%AD%94%E7%96%91/","excerpt":"","text":"我觉得，可以从编写一行代码，到这行代码最终被执行出来的过程说。写代码、编译成字节码、编译成指令、运行期间（运行时内存划分、线程模型划分）。 不用说1 2 3 4点这样的细节。比如你说gcRoots时候，为了解决gcRoots性能问题，引用了缓存，并且是在写屏障里去维护gcRoots缓存。 什么是SRE？ 日志采集： 一般是用kafka + ElasticSearch； 然后再你的服务器上埋一个agent，监听你的本地日志； 这个agent会把日志生产到kafka上； 然后kafka的消费端，把日志写到elasticSearch里； 你这样回溯找方法调用关系，其实还是面向过程。 其实就是说，要用面向对象的四维去拆解这个组件。 比如问你younggc时，如果有些引用是被老年代引用的，怎么解决的? Spring 先看架构图 –》每一个jar，看看package的划分 –》 细分学习，搞清楚利用了什么设计模式 –》 利用面向对象的思维去拆解组件。 然后我问springboot和spring的关系是什么？","categories":[],"tags":[]},{"title":"常用linux命令","slug":"wholee/常用linux命令","date":"2022-01-25T09:39:37.532Z","updated":"2022-03-19T13:54:05.621Z","comments":true,"path":"2022/01/25/wholee/常用linux命令/","link":"","permalink":"http://example.com/2022/01/25/wholee/%E5%B8%B8%E7%94%A8linux%E5%91%BD%E4%BB%A4/","excerpt":"","text":"1. 服务相关：2.日志文件相关：1、 查看日志： tail -f 2、删除整行的数据连击D键，注意这个需要在vim命令中，同时不能处于INSERT的状态。 3、退出命令Ctrl+C 4、显示行号 3、其他Hexo相关命令： 编号 命令 功能 1 hexo s 启动Server，当前进程。 2 hexo s &amp; 启动Server，以后台进行运行。 3 hexo g 生成静态文件 4 hexo d 将本地的文件部署到服务器上。 5 6 7 日志查看： bash-5.1# cat /tmp/a bash-5.1# cat /dev/null &gt; /tmp/a 解压缩日志：gunzip 或者是gzip -d ，这两个命令是等价的。","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"DDL","slug":"wholee/DDL","date":"2022-01-25T06:39:26.648Z","updated":"2022-03-19T13:52:20.813Z","comments":true,"path":"2022/01/25/wholee/DDL/","link":"","permalink":"http://example.com/2022/01/25/wholee/DDL/","excerpt":"","text":"商品相关表的DDL语句：Product_product:12345678910111213141516171819202122232425262728293031323334353637383940CREATE TABLE `product_product` ( `id` int(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `create_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `weight` decimal(10,2) DEFAULT NULL COMMENT &#x27;重量&#x27;, `confirm_weight` decimal(10,0) DEFAULT NULL COMMENT &#x27;确认后的重量&#x27;, `default_code` varchar(50) DEFAULT NULL, `name_template` varchar(500) DEFAULT NULL COMMENT &#x27;sku名称&#x27;, `create_uid` int(11) DEFAULT NULL, `message_last_post` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `product_tmpl_id` bigint(20) NOT NULL COMMENT &#x27;商品id&#x27;, `barcode` varchar(50) DEFAULT NULL COMMENT &#x27;条码&#x27;, `volume` double DEFAULT NULL COMMENT &#x27;体积&#x27;, `write_date` timestamp(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) COMMENT &#x27;修改时间&#x27;, `active` tinyint(1) DEFAULT NULL COMMENT &#x27;是否有效&#x27;, `write_uid` int(11) DEFAULT NULL, `sku_no` varchar(50) DEFAULT NULL, `purchase_sku` varchar(200) DEFAULT NULL, `purchase_sku_barcode` varchar(200) DEFAULT NULL, `offline_reason` int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;上下架信息&#x27;, `offline_reason_list` json DEFAULT NULL COMMENT &#x27;上下架信息List&#x27;, `image_url` varchar(1000) DEFAULT &#x27;&#x27; COMMENT &#x27;sku图片&#x27;, `marking_price` decimal(10,4) DEFAULT NULL COMMENT &#x27;划线价，包含多国价格&#x27;, `hs_table` text COMMENT &#x27;多国hs_code, 税率\\n&#123;\\n &quot;IN&quot;:&#123;\\n &quot;hsCode&quot;:100,\\n &quot;taxRate&quot;:10.02\\n &#125;\\n&#125;&#x27;, `price_origin` decimal(10,4) DEFAULT &#x27;0.0000&#x27; COMMENT &#x27;原价&#x27;, `feature` varchar(2048) DEFAULT NULL COMMENT &#x27;sku扩展属性&#x27;, `version` int(10) unsigned NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;版本号,只在更新feature字段时才有用&#x27;, `currency` char(3) DEFAULT &#x27;&#x27; COMMENT &#x27;币种&#x27;, `sku_marking_price` decimal(10,4) DEFAULT &#x27;0.0000&#x27; COMMENT &#x27;带币种划线价&#x27;, `attribute_value_ids` varchar(64) DEFAULT NULL COMMENT &#x27;sku销售属性值id\\nid用逗号分隔,起始逗号开头,结尾逗号收尾&#x27;, `stock` int(11) DEFAULT NULL COMMENT &#x27;初始上货库存\\n&#x27;, `size_measurement` varchar(1024) DEFAULT NULL COMMENT &#x27;商品厘米尺寸&#x27;, `sequence` int(11) DEFAULT NULL COMMENT &#x27;sku序号, 从大到小&#x27;, `length` decimal(10,2) DEFAULT NULL COMMENT &#x27;长度，单位是厘米&#x27;, `width` decimal(10,2) DEFAULT NULL COMMENT &#x27;宽度，单位是厘米&#x27;, `height` decimal(10,2) DEFAULT NULL COMMENT &#x27;高度，单位是厘米&#x27;, PRIMARY KEY (`id`), KEY `product_product_product_tmpl_id_index` (`product_tmpl_id`), KEY `product_product_sku_no_index` (`sku_no`), KEY `product_product_purchase_sku_barcode_index` (`purchase_sku_barcode`)) ENGINE=InnoDB AUTO_INCREMENT=61134527 DEFAULT CHARSET=utf8 COMMENT=&#x27;sku表&#x27; product_template12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758CREATE TABLE `product_template` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `list_price` decimal(10,2) DEFAULT NULL COMMENT &#x27;sku最高价&#x27;, `write_uid` int(11) DEFAULT NULL, `product_property` varchar(1024) CHARACTER SET utf8 DEFAULT NULL COMMENT &#x27;商品属性&#x27;, `create_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `audited_date` timestamp NULL DEFAULT NULL COMMENT &#x27;审核通过时间, 只有审核通过记录, 审核拒绝不记录该时间&#x27;, `description` text CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci COMMENT &#x27;图文详情&#x27;, `write_date` timestamp(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) COMMENT &#x27;修改时间&#x27;, `active` tinyint(1) DEFAULT NULL COMMENT &#x27;是否有效&#x27;, `sub_status` int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;商品子状态&#x27;, `short_name` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL COMMENT &#x27;名称（短）&#x27;, `name` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL COMMENT &#x27;名称&#x27;, `image_url` varchar(1024) CHARACTER SET utf8 DEFAULT NULL, `video_url` varchar(200) CHARACTER SET utf8 DEFAULT NULL COMMENT &#x27;视频url&#x27;, `video_cover` varchar(200) CHARACTER SET utf8 DEFAULT NULL COMMENT &#x27;视频头图&#x27;, `orders` int(11) DEFAULT &#x27;0&#x27;, `b_specifics` text CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci, `cluster_id` int(11) DEFAULT NULL, `search_keywords` varchar(500) CHARACTER SET utf8 DEFAULT NULL, `product_no` varchar(50) CHARACTER SET utf8 DEFAULT NULL COMMENT &#x27;商品编号&#x27;, `electric` tinyint(1) DEFAULT &#x27;0&#x27;, `pre_pro_tmpl_id` int(11) DEFAULT NULL, `daily_testing_flag` smallint(6) DEFAULT NULL COMMENT &#x27;0,默认值，1，测试中，2，满足测试标准&#x27;, `illegal_tags` text CHARACTER SET utf8 COMMENT &#x27;违禁标签列表&#x27;, `new_first_category_id` int(11) DEFAULT &#x27;0&#x27; COMMENT &#x27;新一级类目id&#x27;, `biz_model` tinyint(4) NOT NULL DEFAULT &#x27;1&#x27; COMMENT &#x27;支撑模式&#x27;, `source_id` int(11) DEFAULT NULL COMMENT &#x27;商品来源&#x27;, `version` int(10) unsigned NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;版本号&#x27;, `sub_source_type` varchar(200) CHARACTER SET utf8 DEFAULT &#x27;&#x27; COMMENT &#x27;上游来源子类型&#x27;, `reference_title` varchar(256) CHARACTER SET utf8 DEFAULT NULL COMMENT &#x27;商品中文标题&#x27;, `supplier_write_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;商家最后修改时间&#x27;, `min_price` decimal(10,2) DEFAULT &#x27;0.00&#x27; COMMENT &#x27;sku最低价&#x27;, `currency` char(3) DEFAULT &#x27;&#x27; COMMENT &#x27;币种&#x27;, `sku_max_price` decimal(10,4) DEFAULT &#x27;0.0000&#x27; COMMENT &#x27;sku最高价&#x27;, `sku_min_price` decimal(10,4) DEFAULT &#x27;0.0000&#x27; COMMENT &#x27;sku最低价&#x27;, `store_id` int(11) DEFAULT NULL COMMENT &#x27;店铺id&#x27;, `category_id` int(11) NOT NULL COMMENT &#x27;叶子类目id&#x27;, `supplier_product_no` varchar(128) DEFAULT NULL COMMENT &#x27;商家货号&#x27;, `seller_id` int(11) DEFAULT NULL COMMENT &#x27;卖家id&#x27;, `seller_name` varchar(64) DEFAULT NULL COMMENT &#x27;卖家名称&#x27;, `country` varchar(16) DEFAULT NULL COMMENT &#x27;卖家国家&#x27;, `feature` varchar(2048) DEFAULT NULL COMMENT &#x27;商品扩展属性&#x27;, `tag_tr_nations` varchar(1000) DEFAULT &#x27;&#123;&quot;pt&quot;:[],&quot;jy&quot;:[],&quot;ts&quot;:[]&#125;&#x27; COMMENT &#x27;禁运国家&#x27;, `tag_fb_nations` varchar(1000) NOT NULL DEFAULT &#x27;[]&#x27; COMMENT &#x27;禁售国家&#x27;, `name_zh` varchar(256) DEFAULT NULL COMMENT &#x27;多国家语言-中文名称&#x27;, `three_d_show_infos` json DEFAULT NULL COMMENT &#x27;3dShow图片信息&#x27;, `brand_id` int(11) DEFAULT NULL COMMENT &#x27;品牌id&#x27;, PRIMARY KEY (`id`), KEY `cluster_id_index` (`cluster_id`), KEY `product_template_name_index` (`name`), KEY `product_template_product_no_index` (`product_no`), KEY `product_template_pre_pro_tmpl_id_index` (`pre_pro_tmpl_id`), KEY `idx_source_id` (`source_id`), KEY `idx_create_date` (`create_date`) USING BTREE, KEY `idx_category_id` (`category_id`), KEY `product_template_seller_id_index` (`seller_id`,`supplier_product_no`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=20440255 DEFAULT CHARSET=utf8mb4 COMMENT=&#x27;spu表 商品主表create_date,write_date&#x27; product_template_ext123456789101112131415161718CREATE TABLE `product_template_ext` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `product_id` int(11) NOT NULL COMMENT &#x27;商品主表id&#x27;, `product_no` varchar(50) NOT NULL COMMENT &#x27;商品货号&#x27;, `seller_id` int(11) DEFAULT NULL COMMENT &#x27;卖家id&#x27;, `seller_name` varchar(64) DEFAULT NULL COMMENT &#x27;卖家名称&#x27;, `country` varchar(16) DEFAULT NULL COMMENT &#x27;卖家国家&#x27;, `feature` varchar(2048) DEFAULT NULL COMMENT &#x27;商品扩展属性&#x27;, `version` int(10) unsigned NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;版本号,只在更新feature字段时才有用&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `price_origin` decimal(10,2) DEFAULT &#x27;0.00&#x27; COMMENT &#x27;上货价格&#x27;, `hs_code` varchar(50) DEFAULT &#x27;&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `idx_product_id` (`product_id`), KEY `idx_seller_id` (`seller_id`), KEY `product_template` (`seller_id`)) ENGINE=InnoDB AUTO_INCREMENT=20452855 DEFAULT CHARSET=utf8 COMMENT=&#x27;商品扩展表&#x27; product_attribute1234567891011CREATE TABLE `product_attribute` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `create_uid` int(11) DEFAULT NULL, `create_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `name` varchar(50) NOT NULL COMMENT &#x27;sku属性名称&#x27;, `sequence` int(11) DEFAULT NULL, `write_uid` int(11) DEFAULT NULL, `write_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;修改时间&#x27;, `type` varchar(50) DEFAULT NULL COMMENT &#x27;品类&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=3461150 DEFAULT CHARSET=utf8 COMMENT=&#x27;Sku属性表&#x27; product_attribute_value12345678910111213141516CREATE TABLE `product_attribute_value` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `create_uid` int(11) DEFAULT NULL, `create_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `name` varchar(200) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL COMMENT &#x27;sku属性值名称&#x27;, `sequence` int(11) DEFAULT NULL COMMENT &#x27;排序&#x27;, `attribute_id` int(11) NOT NULL COMMENT &#x27;sku属性id&#x27;, `write_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;修改时间&#x27;, `write_uid` int(11) DEFAULT NULL, `color` varchar(50) CHARACTER SET utf8 COLLATE utf8_bin DEFAULT NULL COMMENT &#x27;color&#x27;, `content` varchar(50) CHARACTER SET utf8 COLLATE utf8_bin DEFAULT NULL COMMENT &#x27;内容&#x27;, `ext` text COMMENT &#x27;属性值扩展字段，对于size属性 存放尺码转换信息&#x27;, `nameZh` varchar(200) CHARACTER SET utf8 COLLATE utf8_bin DEFAULT &#x27;&#x27; COMMENT &#x27;属性值中文名&#x27;, PRIMARY KEY (`id`), KEY `product_attribute_value_attribute_id_name_index` (`attribute_id`,`name`)) ENGINE=InnoDB AUTO_INCREMENT=7373416 DEFAULT CHARSET=utf8 COMMENT=&#x27;sku属性值表&#x27; product_images:1234567891011121314CREATE TABLE `product_images` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `create_uid` int(11) DEFAULT NULL, `create_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `url` varchar(1000) DEFAULT NULL, `url_small` varchar(1000) DEFAULT NULL, `url_middle` varchar(1000) DEFAULT NULL, `product_template_id` int(11) NOT NULL COMMENT &#x27;商品id&#x27;, `write_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;修改时间&#x27;, `write_uid` int(11) DEFAULT NULL, `sequence` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `product_template_id_idx` (`product_template_id`)) ENGINE=InnoDB AUTO_INCREMENT=6062129 DEFAULT CHARSET=utf8 COMMENT=&#x27;图片表&#x27; category_new1234567891011121314151617181920CREATE TABLE `category_new` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;类目id&#x27;, `category_english_name` varchar(256) NOT NULL COMMENT &#x27;类目英文名称&#x27;, `category_chinese_name` varchar(256) NOT NULL COMMENT &#x27;类目中文名称&#x27;, `parent_id` int(11) DEFAULT NULL COMMENT &#x27;父类目id&#x27;, `category_level` smallint(6) NOT NULL COMMENT &#x27;类目层级，第一级父类目为1，子类目依次往后2、3 ...&#x27;, `id_path` varchar(256) NOT NULL COMMENT &#x27;id路径 以/隔开&#x27;, `english_name_path` varchar(512) NOT NULL COMMENT &#x27;类目英文名称 以/隔开&#x27;, `chinese_name_path` varchar(512) DEFAULT &#x27;-1&#x27; COMMENT &#x27;类目中文名称 以/隔开&#x27;, `is_leaf` tinyint(1) NOT NULL COMMENT &#x27;是否叶子节点&#x27;, `is_valid` tinyint(1) NOT NULL COMMENT &#x27;是否是有效类目&#x27;, `tags` varchar(256) DEFAULT NULL COMMENT &#x27;类目标签&#x27;, `extend_field` varchar(256) DEFAULT NULL COMMENT &#x27;扩展字段，可以填写创建更改人的名字以及其它附加信息&#x27;, `finance_category_id` int(10) DEFAULT NULL COMMENT &#x27;财务类目id&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `guide_image` text COMMENT &#x27;类目引导图片,JSON格式多图，长度不超过5张&#x27;, PRIMARY KEY (`id`), KEY `category_new_parent_id_index` (`parent_id`)) ENGINE=InnoDB AUTO_INCREMENT=67401004 DEFAULT CHARSET=utf8 COMMENT=&#x27;新类目&#x27; category_ext12345678910CREATE TABLE `category_ext` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;, `category_id` int(10) unsigned NOT NULL COMMENT &#x27;类目id&#x27;, `feature` varchar(2048) DEFAULT NULL COMMENT &#x27;类目扩展属性&#x27;, `version` int(10) unsigned NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;版本号,只在更新feature字段时才有用&#x27;, `update_time` datetime NOT NULL COMMENT &#x27;更新时间&#x27;, `create_time` datetime NOT NULL COMMENT &#x27;创建时间&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `category_ext_idx` (`category_id`)) ENGINE=InnoDB AUTO_INCREMENT=9670 DEFAULT CHARSET=utf8 COMMENT=&#x27;类目扩展属性表&#x27; property123456789101112131415161718192021CREATE TABLE `property` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;, `create_user` varchar(64) DEFAULT NULL COMMENT &#x27;创建记录的用户&#x27;, `update_user` varchar(64) DEFAULT NULL COMMENT &#x27;最后更新记录的用户&#x27;, `name` varchar(64) NOT NULL COMMENT &#x27;属性名英文，不为空，不可重复&#x27;, `cn_name` varchar(64) NOT NULL COMMENT &#x27;属性中文名&#x27;, `enumerable` tinyint(4) DEFAULT &#x27;0&#x27; COMMENT &#x27;是否是可枚举属性,默认为可枚举\\n 0是枚举\\n 1是枚举可输入\\n 2是可输入&#x27;, `multi_select` tinyint(4) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;是否多选，默认单选\\n 0是单选\\n 1是多选&#x27;, `searchable` tinyint(4) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;是否可搜索\\n 0 可搜索\\n 1 不可搜索&#x27;, `sort` int(11) NOT NULL COMMENT &#x27;排序字段&#x27;, `source` tinyint(4) DEFAULT NULL COMMENT &#x27;属性来源\\n0 大数据写入\\n1 人工写入&#x27;, `status` tinyint(4) DEFAULT &#x27;0&#x27; COMMENT &#x27;属性状态\\n0 正常状态\\n1 已归一&#x27;, `type` varchar(64) DEFAULT NULL COMMENT &#x27;属性类型&#x27;, `rule` varchar(256) DEFAULT NULL COMMENT &#x27;属性规则&#x27;, `feature` varchar(1024) DEFAULT NULL COMMENT &#x27;业务扩展&#x27;, `is_visible` tinyint(1) DEFAULT &#x27;0&#x27; COMMENT &#x27;是否用户可见0可见1不可见&#x27;, PRIMARY KEY (`id`) USING BTREE, UNIQUE KEY `property_name_uindex` (`name`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=394 DEFAULT CHARSET=utf8 COMMENT=&#x27;属性表&#x27; property_value1234567891011121314151617181920CREATE TABLE `property_value` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;主键id&#x27;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;修改时间&#x27;, `create_user` varchar(64) DEFAULT NULL COMMENT &#x27;创建用户&#x27;, `update_user` varchar(64) DEFAULT NULL COMMENT &#x27;修改用户&#x27;, `property_id` int(11) unsigned NOT NULL COMMENT &#x27;属性id&#x27;, `value_id` int(11) unsigned NOT NULL COMMENT &#x27;属性值id&#x27;, `name` varchar(64) NOT NULL COMMENT &#x27;属性值英文名&#x27;, `cn_name` varchar(64) DEFAULT NULL COMMENT &#x27;属性值中文名&#x27;, `sort` int(11) unsigned DEFAULT NULL COMMENT &#x27;排序字段&#x27;, `human_edit` tinyint(1) unsigned DEFAULT NULL COMMENT &#x27;是否被人工编辑过&#x27;, `source` tinyint(4) unsigned DEFAULT NULL COMMENT &#x27;属性值来源\\n 0 大数据算法写入\\n 1 人工写入&#x27;, `status` tinyint(4) unsigned NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;属性值状态\\n 0 正常\\n 1 已归一\\n 2 人工失效&#x27;, `merge_id` int(11) unsigned DEFAULT NULL COMMENT &#x27;归一到的ID&#x27;, `feature` varchar(1024) DEFAULT NULL COMMENT &#x27;业务扩展字段&#x27;, PRIMARY KEY (`id`) USING BTREE, UNIQUE KEY `property_value_property_id_value_id_uindex` (`property_id`,`value_id`) USING BTREE, UNIQUE KEY `property_value_property_id_name_uindex` (`property_id`,`name`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=5773 DEFAULT CHARSET=utf8 COMMENT=&#x27;商品属性值&#x27; tag1234567891011121314CREATE TABLE `tag` ( `id` int(11) NOT NULL AUTO_INCREMENT, `tag_id` int(11) NOT NULL COMMENT &#x27;展示序号&#x27;, `name` varchar(128) NOT NULL COMMENT &#x27;标签名称&#x27;, `example` varchar(128) DEFAULT NULL COMMENT &#x27;示例&#x27;, `active` tinyint(1) unsigned DEFAULT &#x27;1&#x27; COMMENT &#x27;tag 是否有效 1:有效 0:无效&#x27;, `is_delete` tinyint(1) unsigned NOT NULL DEFAULT &#x27;1&#x27; COMMENT &#x27;是否删除&#x27;, `create_time` datetime NOT NULL, `update_time` datetime NOT NULL, `en_name` varchar(128) DEFAULT NULL COMMENT &#x27;标签名称英文&#x27;, `tag_type` tinyint(4) DEFAULT NULL COMMENT &#x27;标签分类&#x27;, `operation_ext` json DEFAULT NULL COMMENT &#x27;操作记录&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=139 DEFAULT CHARSET=utf8 COMMENT=&#x27;商品标签表&#x27;","categories":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"}],"tags":[{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"}]},{"title":"","slug":"typora文件集合/拉钩/JVM/1月23号直播","date":"2022-01-23T13:57:05.220Z","updated":"2022-01-29T02:53:20.070Z","comments":true,"path":"2022/01/23/typora文件集合/拉钩/JVM/1月23号直播/","link":"","permalink":"http://example.com/2022/01/23/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/1%E6%9C%8823%E5%8F%B7%E7%9B%B4%E6%92%AD/","excerpt":"","text":"假期作业：从上层整体视角看JVM，做个总结；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/Java中的位运算符","date":"2022-01-22T14:05:47.832Z","updated":"2022-01-22T14:17:02.007Z","comments":true,"path":"2022/01/22/typora文件集合/技术/技术笔记/Java中的位运算符/","link":"","permalink":"http://example.com/2022/01/22/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Java%E4%B8%AD%E7%9A%84%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6/","excerpt":"","text":"常用的位运算符位运算的作用是什么？ 比较高级的求减法,没看明白是什么意思。 123456789private int subtraction(int a, int b) &#123; if (b == 0) &#123; return a; &#125; int c = a &amp; b; a ^= c; b ^= c; return subtraction(a | b, b &lt;&lt; 1);&#125;","categories":[],"tags":[]},{"title":"小技巧","slug":"小技巧","date":"2022-01-22T11:33:36.000Z","updated":"2022-03-12T16:07:52.582Z","comments":true,"path":"2022/01/22/小技巧/","link":"","permalink":"http://example.com/2022/01/22/%E5%B0%8F%E6%8A%80%E5%B7%A7/","excerpt":"","text":"快捷键Typora 添加代码块快捷键： ctrl + `； 软件：Hexo Hexo启动命令：hexo s,可以加上&amp;符号让其后台运行： hexo s &amp; hexo g：根据source中的内容，更新public； hexo d：提交文件到github上去。 hexo clean：清除public文件下的所有内容； 参考文章：https://blog.51cto.com/u_14114084/3651579","categories":[{"name":"技能","slug":"技能","permalink":"http://example.com/categories/%E6%8A%80%E8%83%BD/"},{"name":"工作","slug":"技能/工作","permalink":"http://example.com/categories/%E6%8A%80%E8%83%BD/%E5%B7%A5%E4%BD%9C/"}],"tags":[{"name":"技能","slug":"技能","permalink":"http://example.com/tags/%E6%8A%80%E8%83%BD/"}]},{"title":"DDD","slug":"DDD","date":"2022-01-22T07:00:26.000Z","updated":"2022-03-18T18:41:58.395Z","comments":true,"path":"2022/01/22/DDD/","link":"","permalink":"http://example.com/2022/01/22/DDD/","excerpt":"","text":"[TOC] DDD与微服务的关系各种域领域：限定业务边界和范围，然后在这个边界内解决业务问题； 子域：领域可以进一步划分为子领域，多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围； 核心域：决定产品和公司核心竞争力的子域是核心域； 通用域：没有太多个性化诉求，同时被多个子域使用的通用功能子域是通用域（权限、认证）； 支撑域：不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，就是支撑域； 商品的额核心域：基础资料、商家商品、营业部商品；通用域：权限、认证；支撑域：品牌、类目、属性、BOM关系； 领域模型与服务微服务与模型什么是领域服务？当领域中的某个操作过程不是实体或值对象的职责时，此时我们便应该将该操作放在一个单独的接口中，即领域服务，然后它是无状态的。以下场景可以放到领域服务中： 执行一个显著的业务操作过程； 对领域对象进行转换； 以多个领域对象作为输入进行计算，结果产生一个值对象； Q：微服务的粒度？微服务如何拆分和设计？微服务的边界在哪里？ A：需要确定业务或者是微服务的边界。 DDD的核心：通过领域驱动设计方法定义领域模型，从而确定业务和应用边界，保证业务模型和代码模型的一致性。 Q：为什么DDD适合微服务？A：DDD是一种处理高度复杂领域的设计思想。它可以分离技术实现的复杂性，并围绕业务概念构建领域模型来控制业务的复杂性，以解决软件难以理解、难以演进的问题。DDD是一种架构设计方法论，它通过边界划分将业务领域简单化，以利于设计出清晰的领域和应用边界，可以很容易地实现架构的演进。 Q：如何划定领域模型和微服务的边界？A：第一步：在事件风暴中梳理业务过程中的==用户操作==、==事件以及外部依赖关系==，根据这些要素梳理出领域实体等领域对象；第二步：根据业务的关联性，将==业务紧密相关==的实体进行组合形成聚合，确定聚合中的==聚合根==、==值对象==和==实体==。所以说：这些聚合是在==同一个微服务实例==中运行；第三步：将一个或者多个聚合划定在一个界限上下文内，形成==领域模型==，用以划分微服务的边界，是物理隔离的。不同的界限上下文是在不同的微服务实例中运行的。界限上下文可以用来划分具体的领域边界。 PS：事件风暴：建立领域模型的主要方法。包括用例分析、场景分析、用户旅程分析，梳理领域对象之间的关系。建立实体、命令、事件 Q：DDD与微服务的关系？ A：DDD是一种架构设计方法，微服务是一种架构风格，两者都是为了追求高响应力，从业务视角去分离应用系统建设复杂度的手段； DDD主要关注：从业务领域视角划分领域边界，通过业务抽象，建立领域模型，维持业务和代码的逻辑一致性； 微服务主要关注：运行时的进程间通信、容错和故障隔离，实现去中心化数据管理和去中心化服务治理，关注的是开发、测试、构建、部署； 什么是界限上下文？用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。在这个边界内定义了模型的适用范围，使团队所有成员能够明确知道什么应该在模型中实现，什么不应该在模型中实现（本领域的职责，就比如商品中的销售商品、货品、主档等的关系。销售商品的界限上下文就可以理解为商家销售商品的领域边界，当然也可以理解为地点销售商品的子领域边界。货品的界限上下文也可以这么理解。这个东西划定了领域服务的边界）。 相爱相杀（聚合根-实体-值对象）实体和值对象是组成领域模型的基础单元。 什么是实体？A：实体是领域模型中的一个重要对象。领域模型中的实体是多个属性、操作或行为的载体。业务依存度高和业务关联紧密的多个实体对象和值对象进行聚合，形成聚合根。（类比商品，商家商品就是有商家商品基础信息+sku信息+图文描述信息等多个实体聚合而成的。它们对应的业务对象都是商家商品业务，相互之间有很强的依存关系。） 代码处理逻辑：在DDD中，这些实体类通常采用充血模型，与这个实体类相关的所有业务逻辑都在这个实体类中实现，跨多个实体类的领域逻辑在==领域服务==中实现。Q：实体是怎么映射到数据库中的表的？都有哪些方式？A：领域模型映射到数据模型，大多数情况下是一对一的，但是也会存在一对多、多对一等场景。举例：一对一：商家商品基础信息、sku信息等；一对多：权限实体对应用户user、角色role两个持久化对象；多对一：客户和账户两个实体对象有可能对应同一个数据持久化对象； 什么是值对象？这个是一个更为抽象的东西。通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体。在DDD中用来描述领域的特定方面，并且是一个没有标识符的对象，叫做值对象。值对象本质上就是一个集。是若干个用于描述目的、具有整体概念和不可修改的属性。在领域建模的过程中，值对象可以保证属性归类的清晰和概念的完整性，避免属性零碎。（就是一些列具有特殊语义的属性的集合，这些属性各自分开有可能比较的零碎，组合起来可能具有更为完整的概念。）值对象与实体一样，同样是从事件风暴中构建出来的。与实体对象的区别：值对象只有==数据初始化操作和有限的不涉及修改数据的行为==，基本不包含业务逻辑。（从业务实际上看，实体中的每一个属性都可以理解为是一个单一的属性值对象。只有多个属性集值对象的集合，我们可以把它们单独出来作为一个class来创建。这个可以类比商品图文实体中的图文描述字段–description，我们就可以把Description作为一个值对象来看待。对于一个description值对象而言，它是有几个属性的集合组成的，而且这个值对象是不需要用唯一的Id进行标识的）。 数据持久化设计？在领域建模的时候，我们可以将对象设计为值对象，保留对象的业务涵义，同时又减少了实体的数量；在数据建模时，我们可以将值对象嵌入实体，减少实体表的数量，简化数据库设计。（\u0010说白了就是作为领域对象，实体要和值对象分来，但是值对象是要有一个属性保存在实体中的，在数据库中，值对象是序列化为一个字段保存在实体对应的一个表中的）。 实体和值对象之间的关系？实体和值值对象是微服务底层的最基础的对象。实现了最核心的领域逻辑。 （具体的关系，可以参考前面的描述，简而言之，就是实体是有业务操作行为与逻辑的，而值对象只是一系列属性的集合，操作而言也大多是数据初始化与展示，没有复杂的修改）。 聚合与聚合根？聚合领域模型内的实体和值对象都是一个个体，是很基础的领域对象，实现了个体对应的业务操作。而能让实体和值对象协同工作的组织就是聚合，它用来确保这些领域对象在实现共同的业务逻辑的同时，能保证数据的一致性。是数据修改和持久化的基本单元。（白话，聚合定义了数据库事务操作的基本单元，比如操作商家商品的修改，这个大的事务中应该包含哪些操作呢？比如包括商家商品础信息的修改、图文的修改、sku的修改等，这些内容的修改需要在一个统一的事务中，确保是一个原子化的操作）。 高内聚和低耦合聚合在DDD分层架构中属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑。聚合内实体以充血模型实现个体业务能力，实体之间通过在领域服务中实现业务逻辑的高内聚。跨多个实体的业务逻辑通过领域服务来实现，跨多个聚合的业务逻辑通过应用服务（业务服务）来实现。（从上面的描述可以看出，聚合是一个动作，是对实体和对值对象的一种==组织==。） 聚合根如果把聚合比做组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅仅是实体，还是聚合的管理者——负责协调实体和值对象按照固定的业务规则协同完成共同的业务逻辑。==聚合之间，需要通过聚合根的ID来进行交互。== 如何设计聚合根？ 在一致性边界内建模真正的不变条件。（意思就是这个边界内的各个实体和值对象是按照统一的业务规则来运行的）； 设计小聚合。（一个聚合内不宜包含过多的实体和值对象）； 通过唯一的标识（ID）来引用其他的聚合。这样可以最大限度的降低聚合之间的耦合度； 在边界之外适用最终一致性；在一次事务中，只能修改一个聚合的状态。如果一次业务操作涉及多个聚合状态的修改，应该采用==领域事件==的方式异步修改相关的聚合，实现聚合之间的解耦（异步线程？MQ？）。 通过应用层实现跨聚合的服务调用。（\u0010在业务服务中调用各个聚合服务，也即领域服务）； 领域事件什么是领域事件？是一种架构风格或者是编程范式。解决了不同的聚合根之间的耦合的问题。在集合根完成更新操作以后会产生一个新的事件并广播出去，由其他订阅该事件的订阅者完成其他的聚合根的对应的操作。这样就实现了不同的聚合根之间的解耦。 领域事件怎么实现？ 建模。领域事件是一个对象，同样需要建模，定义它的数据结构。领域事件的名称的格式一般为产生这个事件的聚合根的名字+产生事件的动词的过去式。比如说MerchantItemCreated。 内部的数据结构。一般与产生它的聚合根的很相似。除此之外，还会多两个属性：事件的发生日期、事件的唯一编号。 处理时需要注意的几点： 领域事件是领域逻辑的一部分，所以在领域层不应该依赖某些底层的框架或是中间件， 事件的发送应该是异步非阻塞的，不应该阻塞当前处理的线程； 设计上避免事件链的产生，即一个事件被处理后又产生了另一个事件； 考虑最终一致性的解决方案，记录好日志，以及事件丢失的处理与排查方案； 框架的选择：可以选择使用Sprint中的事件、订阅功能，或者是Guava中的EventBus；","categories":[{"name":"DDD","slug":"DDD","permalink":"http://example.com/categories/DDD/"}],"tags":[{"name":"DDD","slug":"DDD","permalink":"http://example.com/tags/DDD/"}]},{"title":"","slug":"typora文件集合/拉钩/复盘/简历复盘模板","date":"2022-01-19T16:45:36.965Z","updated":"2022-01-19T16:45:36.965Z","comments":true,"path":"2022/01/20/typora文件集合/拉钩/复盘/简历复盘模板/","link":"","permalink":"http://example.com/2022/01/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/%E7%AE%80%E5%8E%86%E5%A4%8D%E7%9B%98%E6%A8%A1%E6%9D%BF/","excerpt":"","text":"一、简历中的知识点1.1 知识点1（以Spring为例）1.1.1 底层原理1（以bean加载机制为例）1.1.1.2 工作中遇到的问题举例：Could not autowire. No beans of xxx 1.1.1.3 原理知识点1（bean加载顺序）举例：Spring是如何解决上面的问题的？ 1.2 知识点2同1.1 二、项目经历2.1 项目12.1.1 系统/功能背景描述做这个系统或功能的目的是什么？ 2.1.2 设计思路2.1.2.1 功能性2.1.2.1.1 模块划分描述为什么这样划分模块？ 2.1.2.1.2 模型抽象描述为什么抽象出这样的通用模块？ 2.1.2.1.3 方案实现描述如何使用各种技术实现该系统或功能？ 2.1.2.1 非功能性（以下维度有优化点就写，没有就不写）2.1.2.1.1 性能（延迟和吞吐量）2.1.2.1.2 数据一致性2.1.2.1.3 可观测性（监控预警）系统或功能是否实现了主动告警功能？如何实现？ 2.1.2.1.4 可用性服务挂了怎么办？ 2.1.2.1.5 扩展性2.1.2.1.5.1 功能扩展性 2.1.2.1.5.2 节点扩容 是否支持机器节点的快速/自动扩容？如何实现快速/自动扩容？ 2.1.2.1.6 可维护性系统或功能否方便维护？如何维护？如何实现可维护性？ 2.1.2.1.7 接入成本他人是否可以快速接入该系统/功能？如何接入？如何实现接入功能？ 2.1.2.1.8 安全性系统或功能是否提供权限管理或鉴权功能？如何实现的？ 2.2 项目2同2.1","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/复盘/4HR面试准备-分享版","date":"2022-01-19T16:45:36.828Z","updated":"2022-01-19T16:45:36.832Z","comments":true,"path":"2022/01/20/typora文件集合/拉钩/复盘/4HR面试准备-分享版/","link":"","permalink":"http://example.com/2022/01/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/4HR%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87-%E5%88%86%E4%BA%AB%E7%89%88/","excerpt":"","text":"1. HR问职业规划（1）业务能力 我希望的是半年内熟悉咱们公司的技术架构、业务架构。 先从一个模块开始打磨，希望经过我的打磨后成为一个稳定高效的模块。 当负责的模块稳定后，希望负责一个子流程，成为这个子流程的负责人。 经过几年的打磨，我希望成为熟悉整个流程，成为某一方面的专业人士。 因为还不知道具体在咱们公司做什么，就以现在的公司为例，我是先负责的边缘系统处理客诉等问题，后面在我的主动申请下，开始参加到 ** 这个核心系统中，再到后面成为该系统的负责人，并且在公司申请创新项目时作为该系统的专家进行资料整理和提交 （2）管理能力 也希望未来技术能力成熟了，项目管理能力提升了之后，也能够有机会带人，成为一个优秀的管理者。 （3）学习方面 如果公司项目需要我在某个技术点深入研究，我是非常乐意的，做技术的都希望提升自己的技术水平嘛，这样项目实践和技术可以相结合。 2. 薪资谈判关注点： 薪资构成。不能谈论包年，而是以月薪为单位展开谈判 涨薪周期及幅度，大概的晋级标准 （1）有其他家offer 注意点：这个时候谈薪资，首先你要证明自己的价值，从前面的面试中，你觉得自己有哪些方面是非常适合这个岗位的。你要认可你说的价值。 话术：XX那边给到你的offer是XXK，另一边XX给到你的offer是XXK，目前的期望是希望能够到XXK。但是你要表示对于这家企业这边意向更高。 （2）没有其他家offer 话术： 目前的期望是XXK。 一方面是基于之前和面试官的沟通，我觉得自己在技术能力方面是可以胜任这个岗位的，当然我也知道后面有很多需要提升和补足的地方，我会尽快通过学习提升自己。 另一方面，这次换工作我希望可以在一个平台长期发展，至少三年内我会想要在这个平台上稳定的学习和提升。 所以我这次跳槽非常的慎重，平台和项目都在综合考虑。我也知道公司内部的调薪幅度不会很大，所以我希望能够得到这样的一个涨幅。希望您可以帮忙争取一下，感谢。 3. 个人缺点是什么注意点：避重就轻 话术： 性子比较急，对待做事不提前准备的同事可能比较缺乏耐心。现在平时和别人聊天的时候会注意控制自己，慢慢锻炼自己的耐心。毕竟都是同事，肯定要互相协作把项目做好对的。 4. 对待加班的态度表达自己愿意牺牲一部分的个人时间去提升个人能力，同时也可以为公司创造更多的价值。但是要去了解公司是否经常加班，并表明自己的态度。 5. HR或者面试官问我还有什么要问他的注意点： 可以问问本岗位相关的问题，比如部门的人员配置，公司面临的最大挑战是什么，需要我提前准备和学习什么，不要纠结于薪资也不要说没问题，否则会让他误认为你对于岗位没有兴趣。 话术： 人员配置，小组多少人做这个项目 职级：资深开发 负责内容：证券理财社区 公司面临的最大挑战是什么 需要我提前准备和学习什么 6. 离职原因注意点： 以自己的职业规划为中心展开话术，让HR知道你是个很有目标和规划的人 话术： 我到公司还有一个月就满5年了，取得了长足的进步，部门经理很认可我加上自己主动争取，负责的项目从边缘转换到核心的系统，但无论是从职务和薪水上都没有得到公司应有的认可。我多方了解到公司近期也不会给我升职。毕竟待了5年，我很感谢前公司的培养让我成长，但公司给我的回报远低于我的市场价值，所以，我选择了离开，寻找能真正体现自己价值的地方。 7. 为什么我是这份工作的最佳人选咱们公司需要可以产出“效益”的人，而我的背景和经验可以证明我的能力。 咱们部门的效益，在我的理解上，就是最快速+最清晰地了解业务特点，并在脑子里形成一个概念模型，然后将概念模型实现。 讲述自己曾经负责的项目案例 所以我觉得，我有这个能力去为咱们公司，为咱们部门产生“效益”。 8. 如何拒绝offer感谢您给我的认可和面试中给我的指导，出于对项目的兴趣和未来规划的考虑。目前我这边已经入职了心仪的公司和岗位，期望未来有机会能和您公事，感谢～ 9. 很想去但薪资有点低您好，我想了解下咱们最终定薪情况是怎么样的呢，我目前手里有个XX的offer是30K*15，但是我对咱们的意向更高一些，项目和领域都是我想要发展的方向，因为我这次是希望在一个大平台长期发展的，所以希望您能帮我争取一下薪资这部分。 10. HR要了流水，等了好几天都没收到offer您好，想了解下咱们的offer我大概什么时间可以收到呢，还是很期待的。我这边有个offer催我X号入职，但我对咱们这边意向更高，项目和平台的发展前景，都是我非常看好的，所以想了解下offer的流程进度。 11. HR对薪资进行拉锯战时如果已经达到期望直接确定 如果未到期望当没有达到期望薪资时，则需要她帮我去争取 （1）站在HR的角度去阐述 （2）站在自己的角度去阐述 （3）夸面试官 话术： 我特别理解公司的现状，咱们HR招人也需要尽量地压缩成本，但是通过前面几轮的技术面试，我还是很自信的，我相信我有这个悟性和适应能力，也拥有一定的技术能力，去参与平台的系统设计与核心模块的研发工作。 在第三轮面试的时候，我跟咱们**领导聊的很好，我觉得他特别和善，我相信我能在他的领导下，我会与咱们公司的产品团队、业务运营团队紧密协同，高质量地完成业务需求。 我的个人职业规划中，就是为了进入咱们这个大家庭，在这个大平台长期发展。 所以我对咱们公司的意向更高一些，项目和领域都是我想要发展的方向，所以希望您能帮我争取一下薪资这部分。 如果面试官拒绝商谈从我个人的自我认知来判断，我觉得我是适合这个岗位的，我的期望薪资也不是很高。我也说过，我可以为心仪的平台和领域降低我的薪资期望，但是咱们也不能压的太低。所以就希望咱们部门再认证考虑下我的期望薪资，找到一个大家都满意的数值。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/复盘/3饿了么第三轮面试复盘-分享版","date":"2022-01-19T16:45:36.713Z","updated":"2022-01-19T16:45:36.717Z","comments":true,"path":"2022/01/20/typora文件集合/拉钩/复盘/3饿了么第三轮面试复盘-分享版/","link":"","permalink":"http://example.com/2022/01/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/3%E9%A5%BF%E4%BA%86%E4%B9%88%E7%AC%AC%E4%B8%89%E8%BD%AE%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98-%E5%88%86%E4%BA%AB%E7%89%88/","excerpt":"","text":"面试过程项目概述问题1. 从业务的角度谈谈项目面试官：经过前几轮的面试，我们已经了解了你的技术和架构能力，这轮我们主要从业务的角度谈谈你负责的项目 回答： （1）面试官很明确的提出了从项目角度谈，那么以业务为主，技术架构为辅 （2）谈了项目的业务在公司的定位 （3）谈了项目的业务场景和成长性 （4）细讲了项目中每个模块的业务场景和功能 问题2. 项目细节面试官：我在你刚才聊的过程中，记录了一些笔记，有几个感兴趣的点 回答：结合真实案例就面试官的提问进行讲解 问题3. 项目重构解决的问题面试官：看你简历上，提到你们的项目经历了两次重构，这两次重构分别解决了什么问题 回答： （1）功能性上优化细节 （2）可用性上优化细节 （3）性能上优化细节 （4）友好性上优化细节 项目中技术细节问题1. 秒杀系统面试官：你刚才聊到秒杀系统，你们是怎么做的 内心OS： 这个问题不是二面回答了吗，怎么又问了，果然是搞技术的都感兴趣的点 回答： 请参考《饿了么第二轮面试复盘-分享版》 问题2. 技术细节面试官：你说的秒杀系统中，redis使用集群，那怎么解决数据一致性问题 回答： （1）先统计出大概的延迟时间t，在t个单位时间内，查询主库；t个单位时间外，查询从库 （2）二次查询 面试官：还有其他方案吗 回答：暂时想不起来了 面试官：还有一个很多程序员不屑的堆机器 事后总结：当时忘了说分片了 面试复盘1. 需要将自己负责的项目梳理清楚1.1 负责的系统在公司中的定位，以及他的成长性公司的定位是一家客户忠诚度解决方案公司，具体的方案就是提供优惠权益服务、创新支付服务、数字化营销服务。具体来讲就是介于银行端和商户端中间，将客户在门店发生的交易信息流路由到各家银行。 其中交易就包含了积分兑换、权益兑换、刷卡收单、二维码支付、优惠券兑换核销。 而我负责的就是消费券系统，涉及到券的产生和发出、券的状态变更、券的兑换核销。 消费券的业务量的逐年增加，主要得益于两点： （1）消费习惯的改变。比如积分兑换，以前大家是拿着卡片到店刷卡交易，现在更多的是出示银行app的二维码。 （2）线下交易的萎缩和线上交易的增加。尤其是疫情开始后，更多人选择在线上消费。比如星巴克自建点餐小程序，在其中就可以将卡包中的优惠券进行使用。 1.2 负责的系统以什么拆分成多少个模块的我们是以业务场景按照单一职责原则进行划分的： 在我们的优惠券系统中，券码的生命周期包含了：发券、券变更、券核销使用。 发券：银行app、天猫商城或者商户自有平台，调用发券接口。 券变更：包含了作废、冻结等状态变更和有效期、资金渠道等明细变更。 券核销：门店收银机扫码发起的核销请求，根据上送的券码和商品详情，判断券码本身和使用规则上面是否满足。（使用规则包括了：满减、买赠、折扣、单品、代金） 基于上面的业务场景，我们将系统拆分成了这么几个模块： 发券模块：接收来此外部的发券请求、变更请求。因为他们都有一个共同的特性，请求均来自于银行app、天猫商城或者商户自有平台。 核销模块：接收来自线下门店收银机，线上点餐等平台的核销及其反交易请求。根据规则引擎，判断折抵金额和折抵商品。他们都有一个共同的特性，请求均来自于有固定营业时间的门店和线上平台。 查询模块：接收来自线上线下场景的查询请求，因为其请求量大，所以单独一个模块且单独连接一个从库。 后管模块：用于内部立项，创建基础数据，报表导出。 定时任务模块：用于执行跑批等定时任务。 2. 项目中面临的挑战2.1 业务方面的挑战 发券接口的复杂性。发券接口接收来自银行app、天猫商城、商户自有平台的请求。银行有自己的一套标准，比如有的银行还依然使用着比较老的8583格式的报文，有的银行虽然是json格式，但是参数与我们系统的参数不一致。天猫也有自己的标准报文，我们也必须做报文转换以及制码结果的回调。以上不同平台的不同报文，我们需要找到共性也要支持个性，提供一个专门的报文转换功能，转变成券系统的统一报文。 核销接口的复杂性。需要面对不同商家的收银机，需要提供标准接口给收银机厂商，也要完成品牌的自定义需求。 核销规则的复杂性。从分类上，我们就要分成：代金券、单品券、折扣券、满减券、买赠券。 涉及到多个规则，比如简单的日期时间规则，限定使用日期和时间段；比如限量规则，每天只能兑换1w杯咖啡，多次券每天券只能核销2次；比如买赠规则，最低消费门槛，折扣系数或金额，商品的黑白名单（其中还分：sku、品类、规格），买A+B赠A，买A+B赠C等不同规则的配置。规则使用上也是很复杂，上送不通类型券和商品的场景下，计算出折抵金额和折抵产品。还涉及到不同类型券之间是否可叠加使用。 2.2 技术方面的挑战秒杀场景 生产交易问题排查和解决 规则引擎 3. 项目中遗漏的点 缺少风控管理（因为经过前几轮的面试，我知道了我应聘的岗位负责的项目，所以对风控做了些许了解，将话题转移到面试官直接负责的项目中去，谈谈的看法） 4. 项目的升级过程，升级解决的问题V1升级到V2解决的问题 功能性的提升 可用性优化 性能优化 渠道对接友好性优化 5. 最重要的点，最重要的点，最重要的点！！！聊项目的时候，一定要举项目中真实案例做讲解，这样有助于面试官对你项目的理解，才能更好的交流。 6. 项目管理6.1 如果项目中需要其他部门协调工作，怎么处理如果跨项目组，就让我们技术部的领导与其他组的组长进行协调，以重要性和紧急性两个维度对两个组现在所负责的项目进行排序，如果我组系统更重要且紧急，则进行人员借调配合开发。 如果跨部门，就让技术部领导找更高层的领导，由他出面，也同样以重要性和紧急性两个维度对两个组现在所负责的项目进行排序。在实际工作中，我们也经常发生这样的事情，其中有成功的，也有失败的。 成功的案例中，由于我们借调，多多少少影响了兄弟部门的绩效，我们的方案就是将当年我们部门的绩效划拨了一部分给他们，算作他们的绩效。 失败的案例中，最终方案就是由我们技术部的领导从同部门其他组临时抽调人员，协助我们完成相关接口。 4.2 兄弟部门不配合的原因： 他们有自己的进度安排，也有紧急项目 他们觉得架构设计不合理，接口不应该是他们提供 4.3 如果是我的组员被抽调过去，那么我放人的原因是什么？当前团队负责的项目的优先级在全局角度来看是否紧急（事情划分成重要和紧急两部分），当前资源外调并不会造成公司生产经营上的损失或造成影响。 4.4 站在对方的角度考虑 我是借调方。对他们的进程可能造成什么样的影响，在他们的角度打消他们的顾虑。比如我们的成功后带来的效益，一定给他们带来一定的好处或者绩效 我是被借调方。站在全局的角度考虑，他们的系统能带来更大的收益，我们的系统在现阶段可以暂缓迭代步骤，对经营不会带来关键的损失。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/复盘/2饿了么第二轮面试复盘-分享版","date":"2022-01-19T16:45:36.597Z","updated":"2022-01-19T16:45:36.597Z","comments":true,"path":"2022/01/20/typora文件集合/拉钩/复盘/2饿了么第二轮面试复盘-分享版/","link":"","permalink":"http://example.com/2022/01/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/2%E9%A5%BF%E4%BA%86%E4%B9%88%E7%AC%AC%E4%BA%8C%E8%BD%AE%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98-%E5%88%86%E4%BA%AB%E7%89%88/","excerpt":"","text":"面试过程项目相关问题问题1：负责的项目面试官：讲讲你负责的项目 回答： （1）讲了下现在所负责的优惠券系统 （2）讲了下优惠券系统的基本场景 问题2：项目的业务场景和业务成长性面试官：讲下你负责的项目的业务场景及业务的成长性 回答： （1）讲了下优惠券系统的业务场景：发券到用户 -&gt; 中期状态或明细的变更 -&gt; 用户兑换核销 （2）讲了下优惠券在公司业务中比重逐年增加的过程 问题3：项目遇到的挑战面试官：你负责的项目在推进中遇到了哪些挑战 回答： （1）业务挑战 只简单讲了下业务过程，没有深入的将遇到的困难或者挑战 （2）技术挑战 根据实际生产过程中碰到的问题，讲了数据库高可用升级过程：单库 -&gt; 1主1从 -&gt; 1主2从 -&gt; 加入es 分析了每个过程中碰到的问题、解决方案及方案的优缺点。 讲了下秒杀系统的诞生过程 目的：讲面试官的注意力转移到秒杀系统中，希望借此展开问答 问题4：技术调研过程面试官：你前面说数据库的升级过程，那最终拍板是谁决定的 回答： （1）讲了下技术拍板由架构师决定 （2）提到自己在这个过程中，负责的是技术调研 面试官：你说到你负责技术调研，能说说你的调研过程吗 回答： （1）功能性 （2）非功能性 可用性：技术同事学过的，用过的 吞吐量：使用了分库分表的方案，100张表，每张表100万个code，就已经上亿的数据了，已经能够满足我们的需求。 性能：MySQL性能已经有了很大提升。OceanBase据说性能更好，但没研究过。 可运维性：为了减轻运维同事的开销，尽量选择公司现有的技术栈，比如数据库OceanBase（架构师用过其他人都没用过）和MySQL之间，选择了MySQL。且选择了阿里云的RDS服务。 可观测行（监控）：选择了RDS，能够提供比较友好的监控 接入友好性：MySQL社区更庞大 扩展性：我们选择了RDS服务，能够轻松升级成集群。 数据一致性 问题5：讲讲你做的秒杀功能面试官：刚才讲到秒杀功能，讲讲你们是怎么做的 回答： 设定场景：1000个产品，10万会员 前端： （1）恶意请求 （2）链接暴露：之前CoCo做活动就出现过这样的情况，链接暴露了。后续对时间做了判断但依然组织不了程序就是比人手点击快这个事实。 提问：银行app还是易百app上操作。举例：银行交行最红，coco情人节活动 后端： （1）超卖 （2）高并发 （3）数据库 设计思路： 前端： （1）资源静态化：虽然目前都是采用前后端分离，但是前段服务的压力也会很大，所以需要将活动产品的静态资源放入到CDN服务器。 （2）按钮控制：在活动开始前将按钮置为灰色，用户点击后也可以置为灰色，防止用户随意点击造成服务器压力过大。 （3）秒杀链接校验：URL动态化，使用MD5等加密算法对随机的字符串做加密，使其成为URL。前段获取到URL后端校验后才能通过。 后端： （1）服务单一职责：添加一个专门用来秒杀的微服务，有自己的秒杀数据库，不会影响到系统中其他的微服务。 （2）Nginx：负责负载均衡，将请求平均分配到若干台。还可以拦截恶意请求。 （3）限流： ​ 前端限流：类似于前面说的按钮再被点击后置为灰色。 ​ 后端限流：分为总流量的限制，和瞬时流量的限制 ​ 总流量的限制：当活动产品数量达到上限后，返回false给前端，前端显示活动结束页面。如果后续还有请求则拒绝处理。 ​ 瞬时流量的限制：可以自己用LongAdder实现一个简易的限流功能，也可以借助Sentiel等组件。 （4）Redis集群：单台Redis，大概能支撑3万～4万的QPS。使用主从同步，读写分离的方案。因为秒杀本身就是读多写少的场景，可以使用一主多从的方案。 （5）库存预热：一般的系统中需要查询库存量，然后减库存，这个过程对数据库性能是个挑战，我们可以使用Redis记录库存，定时任务或者人工将活动的库存量提前写入到Redis中。 ​ 但是，这个方案有个缺点，我们前面说过Redis使用的是主从模式，那么可能存在这样一个场景，实际库存还剩1件，但是多台从库同时收到查询库存的请求，都发现还有库存可以扣减，这样就会造成实际库存变成负数。 ​ 解决这个问题，可以在查询库存后再减库存，再校验实际库存是否大于0。但这个方案并没有根本上解决问题。解决问题的根本办法是使用Lua脚本，将查询库存和扣减库存变成一个事务。 （6）降级、熔断、隔离 服务不行了就降级；如果还不行就熔断不影响其他系统，虽然我们的秒杀系统本身就是单独的微服务，但是也可能会调用其他的微服务。 （7）削峰填谷： 使用MQ，将请求变成异步的，比如我的券系统就是使用了MQ，将批量制码变成异步的，处理成功后回调或者直接修改数据库状态。‘ 问题6: 大数据框架用过哪些问题：常见的大数据框架用过哪些 回答： 承认自己用过了一些，但属于会用阶段没有研究过 非项目相关问题问题1：离职原因面试官：讲讲你现在离开现有公司的原因 回答：此处省略 问题2：现在所在部门有多少人面试官：讲讲你现在部门有多少人 回答：此处省略 你有什么问题要问我的面试复盘1. 二面目的一般情况下，按照技术 -&gt; 业务设计 -&gt; 管理的步骤。第二轮面试考察的是求职者的业务设计水平。 （1）业务分析和拆解能力 （2）业务场景的设计能力 2. 二面中常见问题（1）工作中最满意的项目 （2）项目中待优化的地方 （3）项目中具体技术点的使用 （4）如何设计一个系统或者模块 （5）模糊场景设计问题 3. 常见问题的回答思路（1）针对该场景进行具像化 （2）模糊不清的问题可以互动讨论 （3）完成功能性问题 （4）安全性问题解决 （5）可用性提升优化 （6）性能提升优化 （7）用户友好性提升优化 4. 功能迭代中的演进思维定义：项目设计的是一个完整的方案，但是不可能一步到位实现这个最终方案，因此，需要我们既要保证业务的正常迭代，也要一步一步实现最终方案，这个过程就是系统的演进。 系统的演进会有两种场景： （1）如果现有系统设计还算合理，可以通过改动现有系统来演进。利用某一个业务需求迭代的机会，先重构系统中需求相关的某一个功能点，然后逐步利用其他需求，重构系统其他功能，最终实现系统的最终方案。 （2）如果现有系统设计不太合理，可以新建一个系统来演进。可以利用某一个业务需求迭代的机会，先实现新系统中业务需求的功能点，将新功能的请求都路由到新系统，其他请求还都路由到老系统。后面逐步利用需求迭代的机会，在新系统中完成最终方案。但需要上有系统逐步切换到新系统中。 5. 项目设计及实现思路前期设计 （1）项目说明 券系统的业务场景，现状等 （2）项目建模 （3）技术选型 技术方案调研： 哪些维度去调研各项技术 功能性 非功能性 可用性 吞吐量 性能 可运维性 可观测行（监控） 接入友好性 扩展性 数据一致性 文档输出 生成调研报告 （4）架构设计 从哪些角度思考架构设计 等同于技术方案调研的几个维度 文档输出（系统设计说明书） 时序图 流程图 架构设计图 整体架构 组件内部架构 （5）数据库设计 提供表结构和搜索引擎的索引的文档结构 （6）功能设计（接口设计） 文档说明 接口定义说明 工具 使用了YApi工具，能够编写接口文档，且提供类似postMan的http工具，用于测试接口 （7）项目管理 任务排期 任务分解 制定任务负责人 时间 工具 任务跟踪 CI持续集成 中期实现 测试工作 （1）代码质量 衡量维度 功能性 程序的功能是否都实现 非功能性 性能 安全性 其他架构设计里的维度 文档输出（质量报告） 功能性 单元测试覆盖率 非功能性 性能 接口响应延迟是多少，是否达标？ 接口支持的最大并发是多少，是否达标？ 安全性 有多少被安全工具扫描出来的漏洞 其他架构设计里的维度 后期验证 （1）制定发布的ToDoList （2）项目启动正常 （3）老功能兼容性演示 （4）新功能演示 6. 向面试官提问（1）部门或团队负责的系统 （2）部门或团队的技术栈","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/1月19号直播","date":"2022-01-19T13:45:32.171Z","updated":"2022-01-19T15:03:05.955Z","comments":true,"path":"2022/01/19/typora文件集合/拉钩/JVM/1月19号直播/","link":"","permalink":"http://example.com/2022/01/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/1%E6%9C%8819%E5%8F%B7%E7%9B%B4%E6%92%AD/","excerpt":"","text":"四则运算？涉及的技术点：操作数栈 局部变量与方法内部的引用操作？ 思考下java中的多态与方法调用的关系？ TLAB：一个区域，提前划分一块内存范围给一个线程，会随着线程的gc而终止，gc回收机制和整个Eden区是一样的。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/Tomcat源码学习","date":"2022-01-19T06:46:37.138Z","updated":"2022-01-19T06:55:26.935Z","comments":true,"path":"2022/01/19/typora文件集合/技术/技术笔记/源码/Tomcat源码学习/","link":"","permalink":"http://example.com/2022/01/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/Tomcat%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"Tomcat时间可以按照1_000_000这样的格式取设置。 SocketChannel 封装了对ByteBuffer的操作。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/复盘/1饿了么第一轮面试复盘-分享版","date":"2022-01-18T13:25:11.411Z","updated":"2022-01-19T16:50:43.260Z","comments":true,"path":"2022/01/18/typora文件集合/拉钩/复盘/1饿了么第一轮面试复盘-分享版/","link":"","permalink":"http://example.com/2022/01/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/1%E9%A5%BF%E4%BA%86%E4%B9%88%E7%AC%AC%E4%B8%80%E8%BD%AE%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98-%E5%88%86%E4%BA%AB%E7%89%88/","excerpt":"","text":"面试过程1. JAVA基础问题1：HashMap面试官：讲讲HashMap 回答： （1）使用场景 （2）源码大概（源码实现、扩容过程） ​ 扩展了解决Hash冲突的常见方法：重散列、重哈希、拉链法。HashMap、ConcurrentHashMap都使用的是拉链法，ThreadLocal使用的是重散列法。 （3）优点 ​ 不需要考虑线程安全的情况下，性能好，查询效率高，查询的时间复杂度是O(1)。 （4）缺点 线程不安全。 ​ 扩展了JDK为了解决线程安全，在JUC包中添加了HashTable、ConcurrentHashMap。 目的：成功的将面试官的注意点引入我们学过的并发编程模块。 问题2：ConcurrentHashMap面试官：既然提到ConcurrentHashMap，那么讲讲他是如何保证线程安全的，以及他的扩容过程。 回答： （1）ConcurrentHashMap使用了拉链法，以数组中每个元素为加锁维度，目的是细化锁的粒度，使其保证线程安全的同时保证并发性。 （2）与之形成鲜明对比的是HashTable，虽然二者都保证的线程安全，但HashTable以每个操作方法为维度，粒度较粗。 问题3：锁面试官：讲下java中常见的锁有哪些？ 回答：最常见到的就是Synchronized和AQS组件下的ReentrantLock 面试官：能讲一下他们两个直接的区别吗，以及我们该怎么选择？ 回答： （1）Synchronized的使用方法 （2）ReentrantLock的使用方法 （3）两者的共同点和不同点 （4）针对不同点，如果需要使用ReentrantLock的特性就选择ReentrantLock，如果不需要就推荐使用Synchornized，原因是隐式加锁，对程序员友好。 遗漏点：线程安全方面存在着较大的设计区别、并发处理能力上存在较大区别 面试官：他们两个直接的性能有差距吗？ 回答： （1）在JDK1.6之前，性能有所差距 （2）在JDK1.6之后，JVM将Synchronized分成了无锁、偏向锁、轻量级锁、重量级锁。 （3）询问面试官是否要将Synchronized的4个锁状态的升级过程细讲下，面试官说，针对这个知识点你已经讲的挺具体的了，不需要深入了。 2. MySQL问题1：表容量面试官：你们系统单表容量大概有多少？ 回答： （1）新系统的单表容量大概是100W左右 （2）之所以新系统的容量不是很高，因为我们重构系统一个很重要的缘由就是解决单表容量过大问题。 （3）介绍了下老系统的单表问题，曾经出现过自增主键不够的问题 （4）为了解决老系统的单表问题，我们采取了将两天前的交易通过定时任务移动到历史表中 （5）新系统为了解决这个问题，采用了分库分表的方案 目的：将面试官的注意力转移到自己很熟悉的新系统中 问题2：分库分表面试官：讲下你们怎么分库分表的？ 回答： （1）使用了Sharding-jdbc插件 （2）横向切分+纵向切分的方式，并具体举例code表 （3）优点：减轻单库单表的压力 （4）缺点：当需要按时间统计订单时，就会比较难 （5）缺点的解决方案：利用binLog，将数据同步到数据仓库中，然后es提供数据的搜索 面试官：es这个方案中，你们怎么保证es与数据库的数据一致性的？ 回答： （1）这个方案不是我做的，但我考虑过，我可以给下我的见解 （2）binLog是推动到MQ的，那就要保证MQ的数据安全，讲了如何防止MQ数据丢失 （3）需要再加一个补救措施，每天零点定时任务，检测当日新增数据量是否一致，如果不一致，则进行补录 面试官：你这个补救措施是针对insert的，那如果是update怎么办？ 当时没回答上来，面试官就进入下一个问题了，没有过多浪费时间。 问题3：ES面试官：前面既然提到了，能讲讲吗？ 回到：对不起，没有研究过，只知道日常的使用 问题4：MySQL的索引原理面试官：讲下MySQL的索引原理 回答： （1）讲了下B+树 （2）B树与B+树的区别 （3）当新建索引的时候，新增一个索引树 （4）扩展了自己熟悉的索引失效，以自己项目中曾经碰到的问题为切入点，讲了6种常见的索引失效场景。 目的：脱离干巴巴的理论知识，以项目中问题讲解实战中可能碰到的问题 3. JVM问题1：CPU、内存占用过高时的查找问题的方法面试官：你们项目中有没有碰到过内存占用过高的场景，你们怎么解决的？ 回答： （1）没有碰到过内存占用过高的场景，但是我们有过CPU过高的场景 （2）回答咱们之前上课时讲过的思路 目的： 内存占用过高还没实践过，所以想转移话题，结果失败 面试官：如果现在碰到内存占用过高的场景，你打算怎么排查？ 回答： （1）首先得先查下是不是境外内存占用过高 （2）境外内存占用过高，可以只用Google提供的一个工具进行排查，它能够看到对象的引用次数等等，承认自己还没有实践过 （3）堆内存占用过高，就讲了下咱们上课时的思路，也同样承认自己还没实践过 问题2：JVM参数调优面试官：你们项目中JVM参数是怎么样的 回答： （1）承认CTO规定这类参数只能由运维经理进行配置，不允许程序员自己配置 （2）但是自己知道大概有哪些参数需要配置，并讲了常见的几个参数，和不太可能有人配置的指定垃圾收集器 目的：主动提到垃圾收集器，是为了尽快问到自己更熟悉的内容 问题3：垃圾回收器面试官：既然提到垃圾收集器，讲一下你熟悉的垃圾回收器？ 回到： （1）因为项目中使用的是JDK1.8，所以对CMS稍微熟悉点 （2）CMS垃圾回收的过程，以及为什么要STW （3）扩展出垃圾回收中的可达性分析、二次标记、三色标记 （4）表达了自己虽然更加熟悉CMS，但是其他的垃圾收集器都逃不开三种垃圾回收算法 （5）讲了下标记-清除、标记-复制、标记-整理算法的思路 面试官：既然提到标记-清除，那么他就会产生垃圾碎片，能说出CMS是怎么解决垃圾碎片问题的吗 回答： （1）明确说出自己不记得两个参数的单词是什么，但清除他们的作用 （2）讲了下在Full GC时，开启内存碎片整理过程。由于碎片整理时需要移动存活对象的，需要停顿一段时间。（默认开启，JDK9开始废弃）（对应-XX:+UseCMS-CompactAtFullCollection ） （3）讲了下收集器在执行若干次不整理碎片的Full GC后，下一次进入Full GC就会进行碎片整理。（默认0，表示每次进入FUll GC都需要碎片整理。JDK9开始废弃）（对应-XX:CMSFullGCsBeforeCompaction） 面试官：除了CMS，G1垃圾收集器熟悉吗？ 回答： （1）承认暂时不熟悉，但表达如果项目使用的版本默认是G1，可以去学习下 4. 框架问题1：SpringIoc面试官：大概讲下SpringIoc？ 回答： （1）承认是两年前学的内容，现在组织语言有点难 （2）表示自己曾今尝试手写过Ioc容器，并讲了下当时的大概的实现方式 面试官：SpringAop呢？ 回答： （1）承认自己没有准备切面编程相关的知识点 问题2：动态代理面试官：讲下JDK动态代理，cglib动态代理的区别 回到： （1）讲了下两者在使用上的不同之处 5. 架构设计问题1：设计模式面试官：你熟悉哪些设计模式？ 回答： （1）说出自己最喜欢用的三种设计模式：适配器模式、拦截器模式、策略模式 （2）每个设计模式在项目中的使用及其优点 面试官：除了这些还有吗？ 回答： （1）常听说的观察者模式，装饰器模式，讲了下大概的作用 PS：单例模式、工厂模式没有讲，当时觉得听的太多了，千篇一律使用到这两个模式，不够亮点，所以选择几个个人喜欢且熟悉的。 问题2：架构师思维面试官：你简历中写道架构师思维，那你觉得架构师思维应该是怎么样的？ 回答： （1）说出自己认为的几个重要的原则，架构师应该遵循：单一职能原则，开闭原则 PS：设计模式的六大原则，当时只记得这两个原则了 （2）就上述的两个原则，分别举例，在日常项目中，我们是怎么做的 （3）说出架构师还需要有个技能，就是演化思维 PS：“演化思维”这个词当时没想出来，随便说了大概，忘了具体内容了 （4）根据自己的项目经验详细讲解了怎么从一个小功能到一个微服务的过程。 ​ 举的例子是券系统-哈根达斯文件上传商委。 ​ 第一步实现功能； ​ 第二步性能提升优化，怎么去满足大文件的处理； ​ 第三步可用性提升优化，怎么将功能抽象，满足卡系统、订单系统的使用； ​ 第四步用户友好性提升优化，除了定时任务，还添加了接口，让运营同事能上传指定日期的文件，并做好控制防止同一日起重复提交。 你有什么问题要问我的面试复盘1. 面试官目的一般情况下，按照技术 -&gt; 业务设计 -&gt; 管理的步骤。第一轮面试考察的是求职者的技术水平能力 2. 提问方式2.1 具体技术点及与其他技术点的区别解答思路： （1）需要讲解核心的区别点 （2）举出每个技术点的使用场景及优缺点 案例： 问：BIO、NIO、AIO三者直接的区别？ 答：同步异步、阻塞非阻塞的区别。各自的使用场景及优缺点 2.2 开放性的问某个技术点解答思路： （1）通过与面试官的交互，确定具体需要讲解的技术细节 案例： 问：讲讲JVM原理 思路：JVM主要有五大模块：类加载系统、运行时数据区、执行引擎、本地方法接口、垃圾回收模块。挑其中最有把握的，问面试官是否可以就其深入讲讲。 3. 向面试官提问3.1 面试的小组或部门负责的功能目的： 了解小组做的项目或者模块，在后面的面试的中可能有用 3.2 面试的小组或部门的人数目的： 了解人数，间接的了解求职部门的规模","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/Mybatis源码学习","date":"2022-01-16T15:10:47.084Z","updated":"2022-01-16T16:07:07.752Z","comments":true,"path":"2022/01/16/typora文件集合/技术/技术笔记/源码/Mybatis源码学习/","link":"","permalink":"http://example.com/2022/01/16/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/Mybatis%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"MyBatis学习第一个问题：Mybatis的执行查询的流程是什么样子的？常用API介绍：SqlSessionFactoryBuilder，用以构建一个SqlSessionFactory对象；SqlSessionFactory SqlSession的工厂对象：创建方法： 方法 解释 openSession() 默认会开启一个事务，但事务不会自动提交，也就意味着需要手动提交该事务，更新操作数据才会持久化到数据库。 openSession(boolean autoCommit) 参数为是否自动提交，如果设置为true，那么不需要手动提交事务。 Mybatis","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/算法/常用题目","date":"2022-01-15T17:14:55.357Z","updated":"2022-01-15T17:15:05.862Z","comments":true,"path":"2022/01/16/typora文件集合/技术/算法/常用题目/","link":"","permalink":"http://example.com/2022/01/16/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E7%AE%97%E6%B3%95/%E5%B8%B8%E7%94%A8%E9%A2%98%E7%9B%AE/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/算法/理论技术","date":"2022-01-15T17:14:43.363Z","updated":"2022-03-04T16:35:05.186Z","comments":true,"path":"2022/01/16/typora文件集合/技术/算法/理论技术/","link":"","permalink":"http://example.com/2022/01/16/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E7%AE%97%E6%B3%95/%E7%90%86%E8%AE%BA%E6%8A%80%E6%9C%AF/","excerpt":"","text":"回溯算法：https://leetcode-cn.com/problems/permutations/solution/hui-su-suan-fa-python-dai-ma-java-dai-ma-by-liweiw/ 这篇文章介绍的比较详细。 栈：栈是一个先入后出的结构，如果有这种左右对称匹配的情况，可以考虑栈的这个数据结构。 动态规划：重要！！！什么是动态规划？怎么写出动态规划转移方程。 反转链表链表的特点是什么？如何遍历链表？如何反转链表？反转链表的head以及各节点； 123456789ListNode prev=null;ListNode curr=head;while(curr!=null)&#123; ListNode next=curr.next; curr.next=prev; prev=curr; curr=next; &#125;return prev; 12345678910111213141516171819202122232425262728293031public ListNode reverseKGroup(ListNode head, int k) &#123; if (head == null || head.next == null) &#123; return head; &#125; ListNode tail = head; for (int i = 0; i &lt; k; i++) &#123; if (tail == null) &#123; return head; &#125; tail = tail.next; &#125; ListNode newHead = reverse(head, tail); head.next = reversezKGroup(tail, k); return newHead;&#125;private ListNode reverse(ListNode head, ListNode tail) &#123; ListNode prev = null; ListNode curr = head; while (curr != tail) &#123; ListNode next = curr.next; curr.next = prev; prev = curr; curr = next; &#125; return prev;&#125; KMP算法：KMP算法是一个快速查找匹配串的算法，它的时间复杂度是：O(m+n)。原因：其能在==非完全匹配的过程==中提取有效信息进行复用，以减少重复匹配的消耗。 排序算法常用的几种排序算法： leetcode中的第31题不是很懂题意。 n * n 的矩阵旋转。涉及到的数学知识。 对于矩阵中第i行的第j个元素，在旋转以后，它出现在倒数第i列的第j个位置。matrix[row][col]=matrixnew[col][n-row-1]。并且通过几次旋转以后，可以发现，有一个规律可循，如下图公示：$$\\left{\\begin{matrix}temp &amp;&amp;&amp;&amp;&amp;&amp; =matrix[row][col] \\matrix[row][col] &amp;&amp;&amp;&amp;&amp;&amp; =matrix[n-col-1][row] \\matrix[n-col-1][row] &amp;&amp;&amp;&amp;&amp;&amp; =matrix[n-row-1][n-col-1] \\matrix[n-row-1][n-col-1] &amp;&amp;&amp;&amp;&amp;&amp; =matrix[col][n-row-1] \\matrix[col][n-row-1] &amp;&amp;&amp;&amp;&amp;&amp;=temp\\end{matrix}\\right}$$ Typora中公式的编辑，可以参考这个文章：https://zhuanlan.zhihu.com/p/261750408 #### 幂 实现[pow(x, n)]的功能 理论数学知识： ​ 解题思路： hash表； DFS 贪心算法 递归 二分法 DP 分治思想 在二维的坐标系中，表示4个方向： int[][] directions = &#123;&#123;0, 1&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;-1, 0&#125;&#125;; 分别表示向上、向右、向下、向左四个方向。","categories":[],"tags":[]},{"title":"","slug":"每日提问面板","date":"2022-01-15T10:20:11.960Z","updated":"2022-01-20T14:37:48.911Z","comments":true,"path":"2022/01/15/每日提问面板/","link":"","permalink":"http://example.com/2022/01/15/%E6%AF%8F%E6%97%A5%E6%8F%90%E9%97%AE%E9%9D%A2%E6%9D%BF/","excerpt":"","text":"[TOC] 多线程和锁多线程的目的与意义是什么？ 多线程的目的：充分利用多核CPU的并行处理的能力，加快程序的处理速度； 锁的存在的意义：控制资源的并发访问，使操作串行话； JUC相关的（AQS）AQS是一个用来构建锁合同步器的框架。 请解释一下AQS的原理？ 原理：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占有，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列实现的，即将暂时获取不到锁的线程加入到队列中。 CLH队列：是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点来实现锁的分配。 两种资源共享方式： Exclusive：公平锁和非公平锁。 Share： 锁相关请解释下锁（Synchronized、ReentrantLock的区别）？Synchronized、ReentrantLock的区别 两者都是可重入锁，什么是可重入锁？已获得锁的对象，可以再次获取锁； Synchronized是JVM实现的，使用起来简单；ReentrantLock是一个Java提供的API，比较灵活； Synchronized是非公平锁，ReentrantLock可以提供非公平锁和公平锁两种，利用fair参数可以控制； 都提供了等待、通知机制； Synchronized是利用了Obejct对象的notify和wait方法； ReentrantLock需要借助于condition、newCondition方法 ReentrantLock提供了中断等待机制；lock.lockInterruptibly() 请说下java对象头的结构：？MarkWord ：存储对象的hashcode、分代年龄、gc标记、同步状态、锁标志位等 kClassPointer：对象的类型指针，指向类元数据（类class文件信息，metaspace空间的方法区） Synchronized的优化&amp;Mark word 的结构 2.1 无锁（01），所有线程均可以修改某一个资源的值，但同时只能由一个线程修改成功，其他会循环尝试；2.2 偏向锁（01）：在对象头MarkWord中存放有对应的线程的id，如果发现请求线程是同一个的话，再次请求的时候，直接获取锁；偏向锁的一个撤销 ：全局安全点（没有字节码在执行），暂停拥有偏向锁的线程，并判断对象是否处于被锁定的状态，如果没有的话，则把对象置为无锁状态，并撤销偏向锁，恢复到无锁或者轻量级锁状态；2.3 轻量级锁（00）：如果在偏向锁的过程中，有其他的线程进行请求的话，就会转化为轻量级锁，或者是关闭偏向锁功能的时候（即2.2种描述的）。线程的栈帧中有一个Lock record的区域，拷贝一份Mark word到这个区域。线程会通过CAS操作，尝试讲Mark word 更新为这个栈帧中锁记录的指针，同时，LockRecord 中的owner指针也会指向Mark word。更新成功，线程就拥有对象的锁。如果CAS失败，判断Mark word是否指向当前线程的指针，是的话，就直接进入同步代码块继续执行。 另一个线程会自旋，当自旋超过一定次数之后，会膨胀为重量级锁。（自适应自旋）；另一个升级为重量级锁的原因是这个时候有另外的线程来争抢对象的锁；2.4 重量级锁（10）：每一个对象都有一个ObjectMonitor锁对象。重量级锁的时候，mark word中存储的是这个monitor锁的指针，另外monitor中，有一个owner指针，指向拥有锁的线程。ObjectMonitor对象内部结构：entryList： 在进入或者重新进入时被阻塞的线程；waitSet：在改Monitor上等待的线程；owner： monitor的所有者（线程）；这个monitor里面表示count（计数器），用于CAS操作。一次CAS操作成功，owner就会置换为指向对应最线程的指针；利用Mutex Lock这个系统提供的来实现，来进行加锁，缺点：需要从内核态切换到用户态，比较消耗性能； 同时，每一个线程都有一个monitor record列表。 2.5 GC标记（11） 如何避免线程死锁？ 线程死锁的四个条件： 互斥条件： 改资源任一时刻只能由一个线程占有； 请求与保持条件： 一个线程因请求资源而阻塞时，对已获得资源保持不放； 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕之后才能释放资源； 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系； 破坏死锁的话，需要从2至4三个点来进行考虑。 一次申请所有资源； 占用部分资源的线程进一步申请其他资源失败时，可以主动释放掉自己占有的资源； 按照某一个顺序申请资源，释放的时候，反序释放； 说下线程池：常用的线程池；优缺点；常用参数 常用线程池： 12345678910111213//创建一个固定大小（核心线程数、最大线程数）的线程池，队列是LinkedBlockingQueue。缺点：容易造成OOM；ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);//核心线程数是0，最大线程数是Integer.MAX_VALUE，队列是SynchronousQueue的线程池。SynchronousQueue不进行线程的保存，直接进行转发。容易造成OOM；ExecutorService cachedThreadPool = Executors.newCachedThreadPool();//核心线程是是1个、最大线程是1个，队列是LinkedBlockingQueue（无限大）的线程池，容易造成OOM；ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor();//核心线程数固定大小的延迟执行的一个线程池，最大线程池大小是Integer.MAX_VALUE,队列是延迟队列：DelayedWorkQueue。缺点：容易造成OOM；Executors.newScheduledThreadPool(5);//自定义线程池,IO密集型和CPU密集型的区别int coreThreads = 10;int maxThreads = 100;ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(coreThreads, maxThreads,0L, TimeUnit.MILLISECONDS,new ArrayBlockingQueue(500)); 建议的方法：自定义一个线程池: 线程池的执行流程 其他什么事OOM？如何理解？怎么排查OOM？内存泄漏和OOM的区别？见JVM。 都有哪些队列&amp;常用多线程工具？ ForkJoin 队列 什么是上下文切换？Linux操作系统的上下文切换时间为什么很少？零拷贝。 零拷贝技术，sendfile！只需要2次切换、2次拷贝 mmap技术： 4次切换、3次拷贝 ThreadLocal ThreadLocalMap是ThreadLocal的静态内部类","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/每日提问面板","date":"2022-01-15T10:20:11.960Z","updated":"2022-01-20T14:37:48.911Z","comments":true,"path":"2022/01/15/typora文件集合/拉钩/每日提问面板/","link":"","permalink":"http://example.com/2022/01/15/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E6%AF%8F%E6%97%A5%E6%8F%90%E9%97%AE%E9%9D%A2%E6%9D%BF/","excerpt":"","text":"[TOC] 多线程和锁多线程的目的与意义是什么？ 多线程的目的：充分利用多核CPU的并行处理的能力，加快程序的处理速度； 锁的存在的意义：控制资源的并发访问，使操作串行话； JUC相关的（AQS）AQS是一个用来构建锁合同步器的框架。 请解释一下AQS的原理？ 原理：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占有，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列实现的，即将暂时获取不到锁的线程加入到队列中。 CLH队列：是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点来实现锁的分配。 两种资源共享方式： Exclusive：公平锁和非公平锁。 Share： 锁相关请解释下锁（Synchronized、ReentrantLock的区别）？Synchronized、ReentrantLock的区别 两者都是可重入锁，什么是可重入锁？已获得锁的对象，可以再次获取锁； Synchronized是JVM实现的，使用起来简单；ReentrantLock是一个Java提供的API，比较灵活； Synchronized是非公平锁，ReentrantLock可以提供非公平锁和公平锁两种，利用fair参数可以控制； 都提供了等待、通知机制； Synchronized是利用了Obejct对象的notify和wait方法； ReentrantLock需要借助于condition、newCondition方法 ReentrantLock提供了中断等待机制；lock.lockInterruptibly() 请说下java对象头的结构：？MarkWord ：存储对象的hashcode、分代年龄、gc标记、同步状态、锁标志位等 kClassPointer：对象的类型指针，指向类元数据（类class文件信息，metaspace空间的方法区） Synchronized的优化&amp;Mark word 的结构 2.1 无锁（01），所有线程均可以修改某一个资源的值，但同时只能由一个线程修改成功，其他会循环尝试；2.2 偏向锁（01）：在对象头MarkWord中存放有对应的线程的id，如果发现请求线程是同一个的话，再次请求的时候，直接获取锁；偏向锁的一个撤销 ：全局安全点（没有字节码在执行），暂停拥有偏向锁的线程，并判断对象是否处于被锁定的状态，如果没有的话，则把对象置为无锁状态，并撤销偏向锁，恢复到无锁或者轻量级锁状态；2.3 轻量级锁（00）：如果在偏向锁的过程中，有其他的线程进行请求的话，就会转化为轻量级锁，或者是关闭偏向锁功能的时候（即2.2种描述的）。线程的栈帧中有一个Lock record的区域，拷贝一份Mark word到这个区域。线程会通过CAS操作，尝试讲Mark word 更新为这个栈帧中锁记录的指针，同时，LockRecord 中的owner指针也会指向Mark word。更新成功，线程就拥有对象的锁。如果CAS失败，判断Mark word是否指向当前线程的指针，是的话，就直接进入同步代码块继续执行。 另一个线程会自旋，当自旋超过一定次数之后，会膨胀为重量级锁。（自适应自旋）；另一个升级为重量级锁的原因是这个时候有另外的线程来争抢对象的锁；2.4 重量级锁（10）：每一个对象都有一个ObjectMonitor锁对象。重量级锁的时候，mark word中存储的是这个monitor锁的指针，另外monitor中，有一个owner指针，指向拥有锁的线程。ObjectMonitor对象内部结构：entryList： 在进入或者重新进入时被阻塞的线程；waitSet：在改Monitor上等待的线程；owner： monitor的所有者（线程）；这个monitor里面表示count（计数器），用于CAS操作。一次CAS操作成功，owner就会置换为指向对应最线程的指针；利用Mutex Lock这个系统提供的来实现，来进行加锁，缺点：需要从内核态切换到用户态，比较消耗性能； 同时，每一个线程都有一个monitor record列表。 2.5 GC标记（11） 如何避免线程死锁？ 线程死锁的四个条件： 互斥条件： 改资源任一时刻只能由一个线程占有； 请求与保持条件： 一个线程因请求资源而阻塞时，对已获得资源保持不放； 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕之后才能释放资源； 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系； 破坏死锁的话，需要从2至4三个点来进行考虑。 一次申请所有资源； 占用部分资源的线程进一步申请其他资源失败时，可以主动释放掉自己占有的资源； 按照某一个顺序申请资源，释放的时候，反序释放； 说下线程池：常用的线程池；优缺点；常用参数 常用线程池： 12345678910111213//创建一个固定大小（核心线程数、最大线程数）的线程池，队列是LinkedBlockingQueue。缺点：容易造成OOM；ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);//核心线程数是0，最大线程数是Integer.MAX_VALUE，队列是SynchronousQueue的线程池。SynchronousQueue不进行线程的保存，直接进行转发。容易造成OOM；ExecutorService cachedThreadPool = Executors.newCachedThreadPool();//核心线程是是1个、最大线程是1个，队列是LinkedBlockingQueue（无限大）的线程池，容易造成OOM；ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor();//核心线程数固定大小的延迟执行的一个线程池，最大线程池大小是Integer.MAX_VALUE,队列是延迟队列：DelayedWorkQueue。缺点：容易造成OOM；Executors.newScheduledThreadPool(5);//自定义线程池,IO密集型和CPU密集型的区别int coreThreads = 10;int maxThreads = 100;ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(coreThreads, maxThreads,0L, TimeUnit.MILLISECONDS,new ArrayBlockingQueue(500)); 建议的方法：自定义一个线程池: 线程池的执行流程 其他什么事OOM？如何理解？怎么排查OOM？内存泄漏和OOM的区别？见JVM。 都有哪些队列&amp;常用多线程工具？ ForkJoin 队列 什么是上下文切换？Linux操作系统的上下文切换时间为什么很少？零拷贝。 零拷贝技术，sendfile！只需要2次切换、2次拷贝 mmap技术： 4次切换、3次拷贝 ThreadLocal ThreadLocalMap是ThreadLocal的静态内部类","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/1月12号答疑","date":"2022-01-12T13:05:55.757Z","updated":"2022-02-09T09:27:43.680Z","comments":true,"path":"2022/01/12/typora文件集合/拉钩/JVM/1月12号答疑/","link":"","permalink":"http://example.com/2022/01/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/1%E6%9C%8812%E5%8F%B7%E7%AD%94%E7%96%91/","excerpt":"","text":"G1什么时候引发Full Gc？G1的回收是混合GC（Mixed GC），老年代只是筛选部分 Region 来回收，并不是整个老年代。 触发 Mixed GC 的时机： 老年代不足 元空间不足 分配担保条件不满足（老年代最大可用连续空间大于新生代对象总大小或历次晋升的平均大小） 大对象进入老年代由于空间碎片太多，没有足够的连续空间来分配 ![image-20220112211256341](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220112211256341.png) 你就说，我们的目标是保证gc耗时的tp99与tp90是稳定的。不能出现尖刺。所以我选择G1，因为G1的定位就是能精确的控制停顿时长的回收器。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/Tomcat预习资料","date":"2022-01-10T17:36:04.492Z","updated":"2022-02-14T12:08:11.952Z","comments":true,"path":"2022/01/11/typora文件集合/拉钩/JVM/Tomcat预习资料/","link":"","permalink":"http://example.com/2022/01/11/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/Tomcat%E9%A2%84%E4%B9%A0%E8%B5%84%E6%96%99/","excerpt":"","text":"Tomcat总体架构两个核心组件：Connector、Container，连接器负责对外交流，容器负责内部处理。 连接器 Server 对应的一个Tomcat实例 Service 默认只有一个，也就是一个Tomcat实例默认一个Service； Connector：一个Service可能多个连接器，接收不同的连接协议； Container：多个连接器对应一个容器，顶层容器其实就是Engine。 三个核心的组件：Endpoint、Processor、Adapter ProtocolHandler组件： EndPoint通信端点。通信监听的接口，是具体的Socket接收和发送的处理器，是对传输层的抽象。是用来实现TCP/IP协议数据读写的，本质调用操作系统的socket接口。 Processor Adapter组件引入了CoyoteAdapter，采用适配器的模式， 容器：负责处理Servlet请求。Tomcat设计了4中容器，分别是Engine、Host、Context和Wrapper。关系如下图所示： Tomcat的类加载机制Tomcat的热加载主要做了以下几个事情： 停止和销毁Context容器及其所有子容器，子容器其实就是Wrapper，也就是Wrapper实例也被销毁了。 停止和销毁Context下的Listener 和Filter； 停止和销毁Context下的Pipeline 和各种Value； 停止和销毁Context的类加载器，以及类加载器加载的类文件资源； 启动Context容器，在这个过程中会重新创建前面四步被销毁的资源。 Tomcat的类加载器Tomcat的自定义类加载器WebAppClassLoader打破了双亲委派机制，它首先自己尝试去加载某个类，如果找不到再代理给父类加载器，其目的是优先加载Web应用自己定义的类。具体的就是重写了ClassLoader的findClass和loadClass两个方法。主要步骤： 先在本地Cache查找该类是否已经加载过，也就是Tomcat的类加载器是否加载过这个类； 如果Tomcat的类加载器没有加载过，再看系统类加载器是否可以加载； 如果都不可以，就让ExtClassLoader去加载。目的就是为了防止Web应用自己的类覆盖JRE的核心的类。 如果ExtClassLoader没有加载到，那么就在本地Web应用目录下查找并加载； 如果本地没有这个类，说明不是Web应用自己定义的类，那么由系统类加载器去加载。这里，web应用程序通过Class.forName()调用交给系统类加载器的。 如果上述加载都失败，则抛出ClassNotFound异常。 WebAppClassLoader Tomcat自定义类加载器WebClassLoader，并且给每个Web应用创建一个类加载器实例。一个web应用程序对应一个Context容器。因此，每个Context容器负责创建和维护一个WebClassLoader加载器实例。这样的话，不同的web应用程序，就会有不同的类加载器实例。即使存在两个类的名称相同，但是由于是不同的加载器实例加载的，所以依然是两个不相同的类。 SharedClassLoader作为WebClassLoader的父类加载器，专门用来加载Web应用程序之间共享的类。如果WebAppClassLoader自己没有加载到某个类，就会委托父类加载器SharedClassLoader去加载这个类。SharedClassLoader会在指定的目录下加载共享类，之后返回给WebAppClassLoader。 CatalinaClassLoader专门用来加载Tomcat自身的类。 ComonClassLoaderTomcat和各Web应用程序共享的类的加载器。 虚拟机字节码执行引擎运行时栈桢结构局部变量表是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。 PS：局部变量在定义的时候必须覆以初始值； 操作数栈用于计算、赋值。 动态链接当前方法在运行时常量池中所属方法的引用。每次调用新方法创建栈桢时，都需要通过解析，明确被调用的具体方法是谁，并获取其引用。 方法返回地址保存主调用方法的程序计数器的值。 方法调用不等于方法的执行，任务是确定被调用方法的版本（即调用哪一个方法）。一切方法调用在Class文件里面存储的都是符号的引用，而不是方法在实际运行时内存布局的入口地址（也就是之前说的直接引用）。 解析类加载期间的符号引用转为直接引用的前提：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期间是不可改变的。==静态方法、私有方法==。调用字节码指令： invokestatic 调用静态方法； Invokespecial 调用构造器&lt;init&gt;()方法、私有方法和父类中的方法； Invokevirtual 用于调用所有的虚方法； Invokeinterfaec 用于接口调用方法，会在运行期再确定一个实现该接口的对象。 Invokedynamic 先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法。由用户设定的引导方法来决定。 注意：final 方法虽然使用的是invokevirtual指令来调用的，但是这样的方法是非虚方法。 分派 静态分派：（与重载有关系）所有依赖静态类型来决定方法执行版本的分派动作，都称为静态分派。最典型的是方法重载。它发生在编译阶段。 动态分派（java的多态相关） ​ invokevirtual指令的运行时解析过程： 1）找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C。 2）如果在类型C中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；不通过则返回java.lang.IllegalAccessError异常。 3）否则，按照继承关系从下往上依次对C的各个父类进行第二步的搜索和验证过程； 4）如果始终，没有找到合适的方法，则抛出java.lang.AbstractMethodError异常； 注意：java里面只有虚方法存在，字段永远不可能是虚的。字段永远不参与多态，哪个类的方法访问某个名字的字段时，该名字指的就是这个类能看到的那个字段。 单分派与多分派==宗量==：方法的接收者和方法的参数统称为方法的宗量。单分派：根据一个宗量对目标方法进行选择，多分派：根据多于一个宗量对目标方法进行选择。java语言中的静态分派属于==多分派类型==；动态分派属于==单分派类型==。 虚拟机动态分派的实现虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表中的地址入口和父类相同的方法的地址入口是一致的，都指向了父类的实现入口。如果子类重写了这个方法，子类虚方法表中的地址也会被替换为指向子类实现版本的入口地址。为了实现方便，具有相同签名的方法，在父类、子类的虚方法表中都应该具有一样的索引序号，这样当类型变换时，仅需要变更查找的虚方法表，就可以从不同的虚方法表中按照索引转换出所需要的入口地址。一般在类加载阶段的连接阶段进行初始化。 动态类型语言的支持==invokedynamic指令==: 为实现动态类型语言支持而进行的改进。 Java 与动态类型 java.lang.invoke包方法句柄。 MethodHandle与Reflection的区别： Reflection是在模拟Java代码层次的方法调用，而MethodHandle是在模拟字节码层次的方法调用。在MethodHandles.Lookup上的3个方法findStatic()、findVirtual()、findSpecical()正是为了对应invokestatic、invokevirtual、invokespecial这几条字节码指令的执行权限校验行为，而这些底层细节在使用Reflection API时是不需要关心的。 Reflection是重量级的，而MethodHandle是轻量级。 MethodHandle可以采用虚拟机对字节码的优化措施，而通过反射不可以的； invokedynamic指令解决原有4条”invoke” 指令方法分派规则完全固化在虚拟机中的问题，把如何查找目标方法的决定权从虚拟机转嫁到具体的用户代码之中。每一处含有invokeDynamic指令的位置都被称为“动态调用点”，这条指令的第一个参数不再是代表方法符号引用的CONSTANT_Methodref_info常量，而是JDK7中新加入的CONSTANT_InvokeDynamic_info常量，从这个常量可以得到3项信息：引导方法（Bootstrap Method，该方法存放在新增的Bootstrap Methods属性中）、方法类型（MethodType）和名称。引导方法是有固定的参数，并且返回值规定是java.lang.invoke.CallSite对象，这个对象代表了真正要执行目标方法调用。根据CANSTANT_InvokeDynamic_info常量中提供的信息，虚拟机可以找到并且执行引导方法，从而获得一个CallSIte对象。最终调用到要执行的目标方法上。 基于栈的字节码执行引擎抽象语法树（Abstract Syntax Tree ，AST）。在java语言中，Javac编译器完成了程序代码经过词法分析、语法分析到抽象语法树，再遍历语法树生成线性的字节码指令流的过程。因为这一部分动作是在Java虚拟机之外进行的，而解释器在虚拟机的内部，所以Java程序的编译器是半独立的实现。 基于栈的指令集与基于寄存器的指令集。 Java编译器输出的字节码指令流，基本上是一种基于栈的指令集架构（ISA），字节码指令流里面的指令大部分都是零地址指令，他们依赖操作数栈进行工作。 区别： 基于栈的指令集是可移植的，因为寄存器由硬件直接提供，程序直接依赖这些硬件寄存器不可避免地受到硬件的约束。其他优点：实现起来简单、代码相对更加的紧凑 基于栈架构的指令集的主要缺点就是理论上执行速度相对于寄存器指令集而言要稍微慢意一些。一方面完成相同功能所需要的指令数量一般会比寄存器架构来的更多，因为出栈、入栈操作本身就产生了相当大量的指令。另一方面栈的实现在内存中，频繁的栈访问也就意味着频繁的访问内存，但是CPU和内存的执行速度是有数量级差距的。 类加载及执行子系统Tomcat的类加载结构 4组常见的目录： 放置在/common目录，类库可被Tomcat和所有的Web应用程序共同使用； 放置在/server目录中，类库可被Tomcat使用，对所有应用程序不可见； 放置在/shared目录中，类库可对所有的web应用程序可见，对Tomcat不可见； 放置在WebApp/WEB-INF目录中，类库仅仅可被该Web应用程序使用，对Tomcat和其他Web应用程序都不可见； Tomcat 6以后，默认把/common、/server、/shared三个目录合并成了一个/lib目录。 解释器与执行器的区别？","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/Stream","date":"2022-01-10T14:55:42.765Z","updated":"2022-01-10T16:19:57.972Z","comments":true,"path":"2022/01/10/typora文件集合/技术/技术笔记/源码/Stream/","link":"","permalink":"http://example.com/2022/01/10/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/Stream/","excerpt":"","text":"Stream定义：来自数据源的元素队列并支持聚合操作。特点： Pipelining：中间操作都会返回流对象本身。这样多个操作可以串成一个管道，如同流式风格（fluent style）。这样做可以对操作进行优化，比如延迟执行、短路； 内部迭代：以前对集合遍历都是通过Iterator或者For-Each的方式，显式的在集合外部进行迭代，这叫做外部迭代。Stream提供了内部迭代的方式，通过==访问者模式==实现。 PS：Stream依赖JDK 7中引入的Fork/Join框架； BaseStream接口定义： 1234567891011public interface BaseStream&lt;T, S extends BaseStream&lt;T, S&gt;&gt; extends AutoCloseable &#123; Iterator&lt;T&gt; iterator(); Spliterator&lt;T&gt; spliterator(); boolean isParallel(); S sequential(); S parallel(); S unordered(); S onClose(Runnable closeHandler); void close(); &#125; 其中，T为流中元素的类型，S为一个BaseStream的实现类，它里面的元素也是T并且S同样是自己。 Stream接口定义： 1public interface Stream&lt;T&gt; extends BaseStream&lt;T, Stream&lt;T&gt;&gt; 并行流框架的性能受以下因素影响： 数据大小：数据够大，每个管道处理时间够长，并行才有意义； 源数据结构：每个管道操作都是基于初始数据源，通常是集合，将不同的集合数据源分割会有一定消耗； 装箱：处理基本类型比装箱类型要快； 核的数量：默认情况下，核数量越多，底层fork/join线程池启动线程就越多； 单元处理开销：花在流中每个元素身上的时间越长，并行操作带来的性能提升越明显；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/ForkJoin","date":"2022-01-10T03:59:52.474Z","updated":"2022-01-10T16:18:45.490Z","comments":true,"path":"2022/01/10/typora文件集合/技术/技术笔记/源码/ForkJoin/","link":"","permalink":"http://example.com/2022/01/10/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/ForkJoin/","excerpt":"","text":"ForkJoin框架解读模块： 任务对象： ForkJoinTask（RecursiveTask、RecursiveAction、CountedCompleter） 执行Fork/Join任务的线程：ForkJoinWorkerThread 线程池：ForkJoinPool 核心思想work-stealing（工作窃取）算法每一个ForkJoinWorkerThread 都对应一个WorkQueue，工作线程优先处理来自自身队列的任务（LIFO或FIFO顺序，参数mode决定），然后以==FIFO==的顺序随机窃取其他任务队列中的任务。 每一个线程都有自己的一个workQueue，该工作队列是一个双端队列； 队列支持三个功能：push（向队列中添加一个任务）、pop（从队列中弹出一个任务）、poll（返回队列的头部元素，并从队列中移除）； push/pop只能被队列的所有者线程调用，而poll可以被其他线程调用； 划分的子任务调用fork时，都会被push到自己的队列中； 默认情况下，工作线程从自己的双端队列获取任务并执行； 当自己的队列为空时，线程随机从另一个线程的队列末尾调用poll方法窃取任务； 执行流程： 内部类介绍： workQueue：是一个work-stealing模式的双端任务队列，内部存放ForkJoinTask对象任务，使用@Contented注解修饰防止伪共享。 什么是伪共享状态？缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续的字节，一般是32～256个字节。最常见的缓存行大小是64个字节。当多线程修改相互独立的变量时。如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 源码解析：ForkJoinPool继承关系 ForkJoinTask继承关系 ForkJoinPoolForkJoinPool的内部状态是通过一个64位的long型变量ctl来存储。它有四个16位的子域组成： AC：正在运行工作线程数减去目标并行度，高16位； TC：总工作线程数减去目标并行度，中高16位； SS： 栈顶等待线程的版本计数和状态，中低16位； 栈顶workQueue在池中的索引（poolIndex），低16位。 构造参数：1234567891011public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode) &#123; this(checkParallelism(parallelism), checkFactory(factory), handler, asyncMode ? FIFO_QUEUE : LIFO_QUEUE, &quot;ForkJoinPool-&quot; + nextPoolId() + &quot;-worker-&quot;); checkPermission();&#125; 说明： parallelism：并行度，默认是CPU数，最小为1； factory：工作线程工厂； handler：处理工作线程运行任务时的异常情况类，默认为null； ayncModel：处理工作线程运行任务时的异常情况类，默认为null； ForkJoinPool.commonPool()方法的构造： 1234567891011121314151617181920212223242526272829303132333435private static ForkJoinPool makeCommonPool() &#123; int parallelism = -1; ForkJoinWorkerThreadFactory factory = null; UncaughtExceptionHandler handler = null; try &#123; // ignore exceptions in accessing/parsing String pp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;);//并行度 String fp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.threadFactory&quot;);//线程工厂 String hp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.exceptionHandler&quot;);//异常处理类 if (pp != null) parallelism = Integer.parseInt(pp); if (fp != null) factory = ((ForkJoinWorkerThreadFactory) ClassLoader. getSystemClassLoader().loadClass(fp).newInstance()); if (hp != null) handler = ((UncaughtExceptionHandler) ClassLoader. getSystemClassLoader().loadClass(hp).newInstance()); &#125; catch (Exception ignore) &#123; &#125; if (factory == null) &#123; if (System.getSecurityManager() == null) factory = defaultForkJoinWorkerThreadFactory; else // use security-managed default factory = new InnocuousForkJoinWorkerThreadFactory(); &#125; if (parallelism &lt; 0 &amp;&amp; // default 1 less than #cores (parallelism = Runtime.getRuntime().availableProcessors() - 1) &lt;= 0) //可以看出，对于多core的CPU，并行度等于CPU核数-1 parallelism = 1;//默认并行度为1 if (parallelism &gt; MAX_CAP) parallelism = MAX_CAP; return new ForkJoinPool(parallelism, factory, handler, LIFO_QUEUE, &quot;ForkJoinPool.commonPool-worker-&quot;);&#125; 任务的提交： 外部任务的提交有两种方式：external/submissions task提交向FJP中提交任务有三种方式： invoke()会等待任务执行完毕并返回计算结果； execute() 是直接向池中提交一个任务来异步执行，没有返回结果； submit() 也是异步执行，但是会返回提交的任务，在适当的时候可以通过task.get()获取支执行结果； 这三种提交方式都是调用externalPush()方法来完成的。externalPush()的执行流程： 先找到一个随机偶数槽位的workQueue； 把任务放入这个workQueue的任务数组中，并更新top位。 如果队列的剩余任务数小于1，则尝试创建或激活一个工作线程来运行任务。 externalSubmit()是externalPush()的完整版本，具体的执行流程如下： 如果线程池为终止状态（runState&lt;0），调用tryTerminate来终止线程池，并抛出任务拒绝异常； 如果尚未初始化，就为FJP来执行初始化操作：初始化stealCounter、创建workQueues，然后自旋； 初始化完成后，执行在externalPush中相同的操作：获取workQueue，放入指定任务。任务提交成功后调用signalWork方法创建或激活线程； 如果在上一步中获取到的workQueue为null，会在这一步中创建一个workQueue，创建成功继续自旋执行第三步操作； 如果非上述情况，或者有线程争用资源导致获取锁失败，就重新获取线程探针值继续自旋。 createWorker() 123456789101112131415private boolean createWorker() &#123; ForkJoinWorkerThreadFactory fac = factory; Throwable ex = null; ForkJoinWorkerThread wt = null; try &#123; if (fac != null &amp;&amp; (wt = fac.newThread(this)) != null) &#123;//创建线程并启动 wt.start(); return true; &#125; &#125; catch (Throwable rex) &#123; ex = rex; &#125; deregisterWorker(wt, ex);//线程创建失败处理 return false;&#125; ForkJoinWorkerThread 构造函数： 123456protected ForkJoinWorkerThread(ForkJoinPool pool) &#123; // Use a placeholder until a useful name can be set in registerWorker super(&quot;aForkJoinWorkerThread&quot;); this.pool = pool; this.workQueue = pool.registerWorker(this); //注册生成workQueue,线程执行该workQueue中的任务&#125; PS:为工作线程创建的WorkQueue是放在奇数索引上的。 子任务的提交ForkJoinTask.fork() 12345678public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) //判断是不是Worker线程，是的话，说明是当前任务fork出的子任务 ((ForkJoinWorkerThread)t).workQueue.push(this); //把任务直接放到自己的等待队列中； else ForkJoinPool.common.externalPush(this); //不是当前woker线程fork出的子任务，提交到一个随机等待的队列中去。 return this;&#125; ForkJoinPool.WorkQueue.push() 123456789101112131415final void push(ForkJoinTask&lt;?&gt; task) &#123; ForkJoinTask&lt;?&gt;[] a; ForkJoinPool p; int b = base, s = top, n; if ((a = array) != null) &#123; // ignore if queue removed int m = a.length - 1; // fenced write for task visibility U.putOrderedObject(a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, task); U.putOrderedInt(this, QTOP, s + 1); if ((n = s - b) &lt;= 1) &#123;//首次提交，创建或唤醒一个工作线程 if ((p = pool) != null) p.signalWork(p.workQueues, this); &#125; else if (n &gt;= m) //任务数组容量过小，进行扩容 growArray(); &#125;&#125; 执行流程ForkJoinWorkerThread.run()方法 1234567891011121314151617181920public void run() &#123; if (workQueue.array == null) &#123; // only run once Throwable exception = null; try &#123; onStart();//钩子方法，可自定义扩展 pool.runWorker(workQueue); &#125; catch (Throwable ex) &#123; exception = ex; &#125; finally &#123; try &#123; onTermination(exception);//钩子方法，可自定义扩展 &#125; catch (Throwable ex) &#123; if (exception == null) exception = ex; &#125; finally &#123; pool.deregisterWorker(this, exception);//处理异常 &#125; &#125; &#125;&#125; ForkJoinPool.runWorker(WorkQueue w) 1234567891011121314final void runWorker(WorkQueue w) &#123; w.growArray(); // allocate queue int seed = w.hint; // initially holds randomization hint int r = (seed == 0) ? 1 : seed; // avoid 0 for xorShift for (ForkJoinTask&lt;?&gt; t; ; ) &#123; if ((t = scan(w, r)) != null)//扫描任务执行 w.runTask(t); else if (!awaitWork(w, r)) break; r ^= r &lt;&lt; 13; r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; // xorshift &#125;&#125; 说明: runWorker是 ForkJoinWorkerThread 的主运行方法，用来依次执行当前工作线程中的任务。函数流程很简单: 调用scan方法依次获取任务，然后调用WorkQueue .runTask运行任务；如果未扫描到任务，则调用awaitWork等待，直到工作线程/线程池终止或等待超时。 scan函数的执行流程： 取随机位置的一个WorkQueue; 获取base位的ForkJoinTask，成功取到后更新base位并返回任务；如果取到的WorkQueue中任务数大于1，则调用signalWork创建或唤醒其他工作线程； 如果当前工作线程处于不活跃状态（INACTIVE），则调用tryRelease尝试唤醒栈顶工作线程来执行； 如果base位任务为空或发生偏移，则对索引位进行随机移位，然后重新扫描； 如果扫描整个workQueues之后没有获取到任务，则设置当前工作线程为INACTIVE;然后重置checksum，再次扫描一圈后如果还没有任务则跳出循环返回null； WorkQueue.runTask() 1234567891011121314final void runTask(ForkJoinTask&lt;?&gt; task) &#123; if (task != null) &#123; scanState &amp;= ~SCANNING; // mark as busy (currentSteal = task).doExec();//更新currentSteal并执行任务 U.putOrderedObject(this, QCURRENTSTEAL, null); // release for GC execLocalTasks();//依次执行本地任务 ForkJoinWorkerThread thread = owner; if (++nsteals &lt; 0) // collect on overflow transferStealCount(pool);//增加偷取任务数 scanState |= SCANNING; if (thread != null) thread.afterTopLevelExec();//执行钩子函数 &#125;&#125; 大概流程如下： 标记scanState为正在执行状态； 更新currentSteal为当前获取到的任务并执行它，任务的执行调用了ForkJoinTask.doExec()方法； 调用execLocalTasks依次执行当前WorkQueue中的任务，会判断是按照FIFO模式还是按照LIFO模式；代码如下： 1234567891011121314151617181920//执行并移除所有本地任务final void execLocalTasks() &#123; int b = base, m, s; ForkJoinTask&lt;?&gt;[] a = array; if (b - (s = top - 1) &lt;= 0 &amp;&amp; a != null &amp;&amp; (m = a.length - 1) &gt;= 0) &#123; if ((config &amp; FIFO_QUEUE) == 0) &#123;//FIFO模式 for (ForkJoinTask&lt;?&gt; t; ; ) &#123; if ((t = (ForkJoinTask&lt;?&gt;) U.getAndSetObject (a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, null)) == null)//FIFO执行，取top任务 break; U.putOrderedInt(this, QTOP, s); t.doExec();//执行 if (base - (s = top - 1) &gt; 0) break; &#125; &#125; else pollAndExecAll();//LIFO模式执行，取base任务 &#125;&#125; 更新偷取任务数； 还原scanState并执行钩子函数； 获取任务结果join() 方法 123456789101112131415161718//合并任务结果public final V join() &#123; int s; if ((s = doJoin() &amp; DONE_MASK) != NORMAL) reportException(s); return getRawResult();&#125;//join, get, quietlyJoin的主实现方法private int doJoin() &#123; int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w; return (s = status) &lt; 0 ? s : ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ? (w = (wt = (ForkJoinWorkerThread)t).workQueue). tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) : externalAwaitDone();&#125; ForkJoinTask的join()方法和invoke()方法都是可以用来获取任务的执行结果，他们对外部提交任务的执行方式一致，都是通过externalAwaitDone方法等待执行结果。不同的是invoke()方法会直接执行当前任务；而join()方法则是在当前任务在队列top位时(通过tryUnpush方法判断)才能执行，如果当前任务不在top位或者任务执行失败调用ForkJoinPool.awaitJoin()方法帮助执行或阻塞当前join任务。 注意事项 避免不必要的fork()。 划分成两个子任务以后，不要同时调用两个子任务的fork()方法。一个例子（这个可以实现两个任务是并行执行的）： 1234right.fork(); // 计算右边的任务long leftAns = left.compute(); // 计算左边的任务(同时右边任务也在计算)long rightAns = right.join(); // 等待右边的结果return leftAns + rightAns; 选择合适的子任务粒度使用ForkJoin框架并不一定比顺序执行任务的效率高；如果任务太大，则无法提高并行的吞吐量；如果任务太小，子任务的调度开销可能会大于并行计算的性能提升，我们还需要考虑创建子任务、fork()子任务、线程调度以及合并子任务处理结果的耗时以及相应的内存消耗。 避免重量级任务划分与结果合并（类似System.arraycopy）； NQ模型 N是数据元素数量，Q是为每个元素执行的工作量。乘积N*Q越大，就越有可能获得并行提速。那么对于特定的规模的数据N，如果Q值越大，则执行并行化处理带来的提速就越是明显的。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/1月9号直播","date":"2022-01-09T13:44:55.137Z","updated":"2022-01-09T14:00:59.889Z","comments":true,"path":"2022/01/09/typora文件集合/拉钩/JVM/1月9号直播/","link":"","permalink":"http://example.com/2022/01/09/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/1%E6%9C%889%E5%8F%B7%E7%9B%B4%E6%92%AD/","excerpt":"","text":"系统切换开销比较大？ 用户态(函数调用)和内核态(系统调用)转换的开销： 引导机制；建立内核堆栈；验证参数；内核态映射到用户态的地址空间(内核需要访问用户态的信息)；内核态独立地址空间TLB； 缓存开销：缓存失效；频繁使用的数据 cpu 会进行缓存，切换线程后会重新缓存； 类加载器什么时候会回收？热部署的情景，会去回收类加载器，不然一般不会。 项目的架构？ 先说业务，再说技术选型，提供了sdk，请求rpc到我的集群，“削峰填谷”； 技术架构？ ​ 业务架构？ 先说背景：现状是什么？找痛点：现状里的不足是什么？定目标：目标要解决痛点；难点：集群小、上游流量大、需要不影响业务流程； 定技术方案： 详细的方案可以不出错，可以准确评估时间； 复盘，你的方案，是不是达到了目标、解决了痛点； 用最小成本，解决了问题； 预习内容： tomcat架构。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/类加载机制","date":"2022-01-08T13:43:03.047Z","updated":"2022-02-13T06:43:33.224Z","comments":true,"path":"2022/01/08/typora文件集合/拉钩/JVM/类加载机制/","link":"","permalink":"http://example.com/2022/01/08/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"类文件Class文件：Class文件是一组以字节为基础单位的二进制流，其数据结构的本质，是一系列的枚举类型（表）。枚举类型由“无符号数”、“其他枚举类型（表）”组成。Class文件中最基本、底层的类型定义如下： 字节码的本质：就是一个在二维坐标系上的16进制编码。 都有哪些东西呢？ 内容 说明 魔数 0xCAFEBABE，证明该class文件的合法性 大小版本号 表明这个类文件是有哪个版本的jdk编译的。 常量池容量 常量池所包含的常量项数。 常量池 字面量：文本字符串、被final修饰的成员变量；符号引用：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符 访问标志 作用域、是否为abstract、是否为final等 类、父类、实现的接口的索引 当前类本身、父类、实现的接口的信息。 字段表集合 接口或者类中声明的变量； 方法表集合 接口或者类中声明的方法； 属性表集合 接口或者类其本身的属性； 字节码指令？定义：由一个字节长度、代表着某种特定操作含义的数字以及跟随其后的零至多个代表操作所需的参数构成。指令概述： 类型 指令 说明 加载和存储指令 load、store、const、wide 将数据向栈桢中的操作数栈传输、存储 运行指令 加减乘除、取余、取反、位移、与或非、自增、比较 计算 类型转化指令 宽化、窄化 int转long、long转int、窄化有风险 对象创建与访问指令 创建对象、数组，访问实例、操作数组、取数组长度、检查实例 对对象和数组进行创建与操作 控制转移指令 条件分支、符合条件分支、无条件分支 控制代码分支 方法调用与返回指令 调用分派、接口调用分派、父类调用 控制方法调用 异常处理指令 抛出异常、捕捉异常 控制异常 同步指令 多线程时保证线程安全 控制并发 类加载机制类的加载时机： ![image-20220108225356052](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220108225356052.png) PS: 解析不一定按照上述的流程，它在某些条件下可以在初始化阶段之后再开始，为了支持Java语言的运行时绑定特性。需要立即对类进行初始化的情况： 遇到new、getstatic、putstatic、invokestatic(调用静态方法)这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段。 使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化。 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化； 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的类），虚拟机先初始化这个主类。 当使用JDK7 新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandler实例最后的解析结果为REF_getstatic、REF_putstatic、 REF_invokestatic、 REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。 当一个接口中定义了JDK8 新加入的默认方法（被default方法修饰的接口方法）时，如果这个接口的实现类发生了初始化，那这个接口要再其之前被初始化。 接口也有初始化过程，编译器会为接口生成”()&quot;类构造器，用于初始化接口中所定义的成员变量。不同的是，当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成初始化，只有在其真正使用到父接口的时候才会初始化。 加载 加载时机 时机 说明 遇到new、getstatic、putstatic、invokestatic字节码时 new：实例化对象；getstatic、putstatic：读取static字段；invokestatic：调用静态方法； 被反射代码调用时 main方法所在的类 动态语言支持 groovy等动态语言解析需要加载新的类 调用接口的default方法 加载来源： 功能： 通过一个类的全限定名来获取定义此类的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； PS：数组类本身时不通过类加载器创建的，它是由Java虚拟机直接在内存中动态构造出来的。但是数组中的元素类型仍然是需要类加载器来完成加载的。 验证包含一下四个阶段的验证动作：文件格式验证、元数据验证、字节码验证、符号引用验证。 文件格式验证最常见的是魔数0xCAFEBABE、主次版本号是否在当前虚拟机接收范围内；保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。 元数据验证对字节码描述的信息进行语义分析，包括： 这个类是否有父类； 这个类的父类是否继承了不允许被继承的类（被final修饰的类）； 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法； 类中的字段、方法是否与父类产生矛盾； 字节码验证通过数据流分析和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证发生在虚拟机将符号引用转化为直接引用的时候。对类自身以外的各类信息进行匹配性校验，通俗来说就是，该类是否缺少或者被禁止访问它依赖的某些外部类、方法、字段等资源。目的：保证解析行为能正常执行。 准备正式为类中定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值的阶段。这里的初始值通常情况下是数据类型的零值，但是如果类的字段属性表中存在ConstantValue属性，那么在准备阶段变量值就会被初始化为ConstantValue属性指定的值。划分内存、设置类变量初始值、初始化符号 解析解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用（symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机的内存布局无关。 直接引用（Direct References）：直接引用是可以直接指向目标的指针、相对偏移量或是一个能直接定位到目标的句柄。直接引用和虚拟机的内存布局直接相关。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符这7类符号引用进行。 初始化执行类构造器&lt;clinit&gt;()方法的过程。&lt;clinit&gt;()方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问。需要注意的点： &lt;clinit&gt;() 方法与类的构造函数不同，它不需要显式的调用父类构造器，Java虚拟机会保证在字类的&lt;clinit&gt;()方法执行完成以前，父类的&lt;clinit&gt;()方法已经执行完毕； 由于父类的&lt;clinit&gt;()先执行，所以父类中的定义的静态语句块要优先于子类的变量操作； &lt;clinit&gt;() 不是必须的； 接口中不能使用静态语句块，但仍然有变量初始化的赋值操作； Java虚拟机保证一个类的&lt;clinit&gt;()方法在多线程环境下被正确地加锁同步； 类加载器获取类的二进制字节流的代码成为==类加载器== 对于任意一个类，都必须由加载它的==类加载器和这个类本身==一起共同确立其在Java虚拟机中的唯一性。每一个类加载器，都拥有一个独立的类名称空间，比较两个类是不是相同需要在同一个类名称空间下才有意义。 下面是几个不同等级的类加载器。 Bootstrap ClassLoader 这个是加载器的大Boss，任何类的加载行为，都要经过它。它的作用是加载核心类库，也就是rt.jar、resources.jar、charsets.jar、tools.jar等。当然这些jar包的路径是可以指定的。-Xbootclasspath参数可以完成指定的操作。 这个加载器是C++编写的，随着JVM而启动。 Extension ClassLoader 扩展类加载器，主要用作加载\\lib\\ext目录下的jar包和.class文件。同样的，通过系统变量java.ext.dirs可以指定这个目录。 这个加载器是个Java类，继承自URLClassLoader，在JDK中的名字应该是ExtClassLoader； App ClassLoader 这是我们编写的Java类的默认加载器，有时候也叫做System ClassLoader。一般用来加载classpath下的其他的所有的jar包和.class文件。我们编写的代码，首先会使用这个类加载器进行加载。 Custom ClassLoader 自定义加载器，支持一些个性化的扩展功能。 双亲委派模型双亲委派机制的意思是除了顶层的启动类加载器以外，其余的类加载器，在加载以前，都会委派给它的父类加载器进行加载，这样一层一层向上传递，直到祖先们都无法胜任，它才会真正的加载。代码： 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 破坏双亲委派模型举出一个破坏双亲委派机制的例子： Tomcat的架构： 类索引、父类索引、接口索引集合类索引和父类索引是一个u2类型的数据，接口索引集合是一组u2类型的数据的集合，Class文件中由这三项数据来确定类型的继承关系。 字节码指令Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需的参数（称为操作数，Operand）构成。由于Java虚拟机采用面向操作数栈而不是面向寄存器的架构，所以大多数指令都不包含操作数，只有一个操作码，指令参数都存放在操作数栈中。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/RateLimiter","date":"2022-01-07T03:46:09.768Z","updated":"2022-01-07T05:55:02.343Z","comments":true,"path":"2022/01/07/typora文件集合/技术/技术笔记/源码/RateLimiter/","link":"","permalink":"http://example.com/2022/01/07/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/RateLimiter/","excerpt":"","text":"Guava中RateLimiter限流器源码分析（针对的都是SmoothWarmingUp的实现）： 构造器分析 12345678910111213141516public static RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit) &#123; checkArgument(warmupPeriod &gt;= 0, &quot;warmupPeriod must not be negative: %s&quot;, warmupPeriod); return create( permitsPerSecond, warmupPeriod, unit, 3.0, SleepingStopwatch.createFromSystemTimer());&#125;static RateLimiter create( double permitsPerSecond, long warmupPeriod, TimeUnit unit, double coldFactor, SleepingStopwatch stopwatch) &#123; RateLimiter rateLimiter = new SmoothWarmingUp(stopwatch, warmupPeriod, unit, coldFactor); rateLimiter.setRate(permitsPerSecond); return rateLimiter;&#125; 初始化速率相关的参数： 12345678910111213141516171819202122void doSetRate(double permitsPerSecond, double stableIntervalMicros) &#123; double oldMaxPermits = maxPermits; // 系统最冷时的令牌生产速，固定是正常速率的3倍（coldFactor固定是3.0） double coldIntervalMicros = stableIntervalMicros * coldFactor; // 门槛令牌数，上面已经讲到该值用途，这里默认就是整个预热时间除以正常速率的一半，太小的话会过早进入预热阶段，影响性能，太大的话会对系统产生压力，是一个取舍后的权衡值，可以不用纠结为什么是0.5 thresholdPermits = 0.5 * warmupPeriodMicros / stableIntervalMicros; // 最大令牌数，这个计算逻辑详见后面分析 maxPermits = thresholdPermits + 2.0 * warmupPeriodMicros / (stableIntervalMicros + coldIntervalMicros); // 坡度，计算逻辑详见后面分析 slope = (coldIntervalMicros - stableIntervalMicros) / (maxPermits - thresholdPermits); // 设置当前桶内的库存数，初始化时肯定也是系统最冷的时候，所以在初始化时，桶内默认就是maxPermits if (oldMaxPermits == Double.POSITIVE_INFINITY) &#123; // if we don&#x27;t special-case this, we would get storedPermits == NaN, below storedPermits = 0.0; &#125; else &#123; storedPermits = (oldMaxPermits == 0.0) ? maxPermits // initial state is cold : storedPermits * maxPermits / oldMaxPermits; &#125;&#125; 对应的曲线图为： *** acquire方法分析***： 这个地方是真正的获取令牌时的逻辑的处理： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overridefinal long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; // 1、根据nextFreeTicketMicros计算新产生的令牌数，更新当前未使用的令牌数storedPermits resync(nowMicros); long returnValue = nextFreeTicketMicros; // 2、计算需要阻塞等待的时间 // 2.1 先从桶中取未消耗的令牌，如果桶中令牌数不足，看最多能取多少个 double storedPermitsToSpend = min(requiredPermits, this.storedPermits); // 2.2 计算是否需要等待新的令牌（当桶中现有的令牌数不足时就需要等待新的令牌），如果需要，则看需要等待的令牌数 double freshPermits = requiredPermits - storedPermitsToSpend; // 计算需要等待的时间，需要注意的是这里用的是加号，所以是分两部分计算：waitMicros = 从桶中取storedPermitsToSpend个现有令牌代价 + 等待产生freshPermits个新令牌代价。取现成的令牌也是有代价的，storedPermitsToWaitTime方法是个抽象方法，在SmoothBursty和SmoothWarmingUp两个实现类里付出的代价不一样，详见后面源码分析，生产新令牌代价=令牌个数freshPermits * 每个令牌的耗时stableIntervalMicros long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); // 3、更新nextFreeTicketMicros this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros); // 4、扣减令牌数，更新桶内剩余令牌 this.storedPermits -= storedPermitsToSpend; // 这里需要注意，returnValue被赋值的是上次的nextFreeTicketMicros，说明当前这次的代价是由下一个线程去承受 return returnValue;&#125;// 计算从nextFreeTicketMicros到当前时间内新产生的令牌数，这个就是延迟计算void resync(long nowMicros) &#123; // if nextFreeTicket is in the past, resync to now if (nowMicros &gt; nextFreeTicketMicros) &#123; // 时间差除以生产一个新令牌的耗时，而coolDownIntervalMicros() 是抽象方法，每个子类的具体逻辑不一样 double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros(); // 更新桶内的库存令牌个数，不超过最大限制 storedPermits = min(maxPermits, storedPermits + newPermits); // 更新nextFreeTicketMicros为当前时间 nextFreeTicketMicros = nowMicros; &#125;&#125; /** * 从桶中取出库存令牌的代价， * storedPermits：当前桶中的库存令牌 * permitsToTake：从库存令牌中取出的令牌数 * &lt;p&gt;This always holds: &#123;@code 0 &lt;= permitsToTake &lt;= storedPermits&#125; */abstract long storedPermitsToWaitTime(double storedPermits, double permitsToTake);/** * 没生产一个新的令牌的耗时，由子类实现 */abstract double coolDownIntervalMicros(); 需要注意的是storedPermitsToWaitTime这个方法，在SmoothBursty和SmoothWarmingUp两个实现类里付出的代价不一样的。在SmoothWarmingUp中其实是有一个预热的阶段的。在SmoothBursty实现类中，这个时间是0，在SmoothWarmingUp类中，这个时间包含了稳定阶段维持令牌的耗时，以及预热阶段维持令牌的耗时，这两个时间段的耗时是不一样的，见下图： coolDownIntervalMicros 这个方法两个子类的实现是不一样的，但是通过计算可以发现，最终的结果都是stableIntervalMicros这个值。 SmoothWarmingUp 实现类： 获取新的令牌数耗时逻辑计算： 12345678910111213141516171819202122232425262728long storedPermitsToWaitTime(double storedPermits, double permitsToTake) &#123; // 检查当前桶内库存的令牌数是否大于门槛值 thresholdPermits double availablePermitsAboveThreshold = storedPermits - thresholdPermits; long micros = 0; // 超过的thresholdPermits，则说明当前系统已经冷下来了，需要进入预热期，计算预热期的令牌耗时 if (availablePermitsAboveThreshold &gt; 0.0) &#123; // 计算在超过门槛值的令牌中需要取出多少个令牌，并计算耗时 double permitsAboveThresholdToTake = min(availablePermitsAboveThreshold, permitsToTake); // 预热阶段的耗时 double length = // 计算初始速度 permitsToTime(availablePermitsAboveThreshold) // 计算结束速度 + permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake); // 总耗时 = ((初速度+结束速度) *令牌数)/2 micros = (long) (permitsAboveThresholdToTake * length / 2.0); permitsToTake -= permitsAboveThresholdToTake; &#125; // 加上稳定阶段令牌的耗时就是总耗时 micros += (long) (stableIntervalMicros * permitsToTake); return micros;&#125;// 翻译成数学题就是：已知每生产一个令牌，下一个令牌的耗时就会固定增加slope微秒，那么在知道初始耗时stableIntervalMicros的情况下，求出生产第permits个令牌的耗时，很容易想到的公式就是：耗时=初始耗时stableIntervalMicros+(slope * permits）private double permitsToTime(double permits) &#123; return stableIntervalMicros + permits * slope;&#125; 参考博文：https://juejin.cn/post/6961815018488725541","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/AQS","date":"2022-01-05T02:34:34.253Z","updated":"2022-01-05T02:34:45.308Z","comments":true,"path":"2022/01/05/typora文件集合/技术/技术笔记/源码/AQS/","link":"","permalink":"http://example.com/2022/01/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/AQS/","excerpt":"","text":"AQS","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/ThreadLocal","date":"2022-01-03T14:05:20.345Z","updated":"2022-01-03T16:16:39.123Z","comments":true,"path":"2022/01/03/typora文件集合/技术/技术笔记/源码/ThreadLocal/","link":"","permalink":"http://example.com/2022/01/03/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/ThreadLocal/","excerpt":"","text":"ThreadLocal 是一个桥梁，建立起Thread和对应的变量之间的关系。这种关系是维护在Thread自身的一个map中的，而ThreadLocal是用来维护这个map的。 ThreadLocalMap的构造函数： ![image-20220103222751332](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220103222751332.png) InheritableThreadLocal可以实现子线程继承父线程中的ThreadLocalMap中的变量。![image-20220104000627722](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220104000627722.png) 在执行init方法的时候，通过把inheritThreadLocals入参始终设置为true。 然后会有这么一个判断： parent.inheritableThreadLocals是否不等于null； ![image-20220104000732987](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220104000732987.png) 这个parent是这么获取的呢？![image-20220104000846492](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220104000846492.png) 可以看到这个parent的获取调用了native方法，得到对应的父线程；如果我们此时采用InheritableThreadLocal来进行变量的存放，有InheritableThreadLocal的源代码可以看出：![image-20220104001059973](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220104001059973.png) InheritableThreadLocal 进行getMap与createMap的时候，都是向inheritableThreadLocals这个ThreadLocal.ThreadLocalMap类型的变量中存入数据的。所以上面的判断会一直是成立的。所以就实现了父线程向子线程传递变量。但是我们看到：![image-20220104001448030](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220104001448030.png) ThreadLocalMap的传递是以复制的方式由父线程到子线程的。而且是在子线程初始化的时候，这就会导致父子线程中ThreadLocalMap的值在以后是会出现不一致的情况的，","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/HashMap","date":"2022-01-03T14:04:03.742Z","updated":"2022-02-17T03:03:59.130Z","comments":true,"path":"2022/01/03/typora文件集合/技术/技术笔记/源码/HashMap/","link":"","permalink":"http://example.com/2022/01/03/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/HashMap/","excerpt":"","text":"HashMap源码剖析基于JDK1.8，底层数据结构由数组+链表+红黑树; 允许出现null键和null值。 构造方法总共有4个构造方法。 初始化threshold123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 本质上这个方法的作用是找到大于或等于cap的最小2的幂。 负载因子： 反应了HashMap桶数组的使用情况。调低负载因子，是一个空间换时间的做法；调高负载因子，是一个时间换空间的做法； 查找 寻址的优化用与运算替代取模，提升性能 与运算：(n - 1) &amp; hash n为hashMap的长度 hash算法的优化对每个hash值，在他的低16位中，让原先的高低16位进行了异或，让他的低16位同时保持了原先的高低16位的特征，尽量避免一些hash值后续出现冲突，大家可能会进入数组的同一个位置。 遍历遍历器是HashIterator，基本原理是从桶数组中找到包含链表节点引用的桶，然后对这个桶指向的链表进行遍历； 从桶数组中找到包含链表节点引用的桶： 123456789101112final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e;&#125; 对上面得到的桶指向的链表进行遍历： 1234567891011121314public final void forEach(Consumer&lt;? super K&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125;&#125; 插入插入的流程： 当桶数组table是空的时候，通过扩容的方式初始化table; 查找要插入的键值对是否已经存在，存在的话根据条件判断是否需要用新值替换旧值； 如果不存在，则将键值对插入链表中，并根据链表长度决定是否将链表转为红黑树； 判断键值对数量是否大于阀值，大于的话则进行扩容； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 初始化桶数组 table，table 被延迟到插入新数据时再进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果桶中不包含键值对节点引用，则将新键值对节点的引用存入桶中即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 如果键的值以及节点 hash 等于链表中的第一个键值对节点时，则将 e 指向该键值对 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果桶中的引用类型为 TreeNode，则调用红黑树的插入方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 对链表进行遍历，并统计链表长度 for (int binCount = 0; ; ++binCount) &#123; // 链表中不包含要插入的键值对节点时，则将该节点接在链表的最后 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 如果链表长度大于或等于树化阈值，则进行树化操作 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 条件为 true，表示当前链表包含要插入的键值对，终止遍历 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 判断要插入的键值对是否存在 HashMap 中 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // onlyIfAbsent 表示是否仅在 oldValue 为 null 的情况下更新键值对的值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 键值对数量超过阈值时，则进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 插入的时候，如果是链表，会将该节点接在链表的最后； 扩容在HashMap中，桶数组的长度均是2的幂，阀值大小为桶数组长度与负载因子的乘积。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 如果 table 不为空，表明已经初始化过了 if (oldCap &gt; 0) &#123; // 当 table 容量超过容量最大值，则不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 按旧容量和阈值的2倍计算新容量和阈值的大小 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold /* * 初始化时，将 threshold 的值赋值给 newCap， * HashMap 使用 threshold 变量暂时保存 initialCapacity 参数的值 */ newCap = oldThr; else &#123; // zero initial threshold signifies using defaults /* * 调用无参构造方法时，桶数组容量为默认容量， * 阈值为默认容量与默认负载因子乘积 */ newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // newThr 为 0 时，按阈值计算公式进行计算 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; // 创建新的桶数组，桶数组的初始化也是在这里完成的 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 如果旧的桶数组不为空，则遍历桶数组，并将键值对映射到新的桶数组中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 重新映射时，需要对红黑树进行拆分 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历链表，并将链表节点按原顺序进行分组 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将分组后的链表映射到新桶中 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 总结： 计算新桶数组的容量newCap和新阀值newThr; 根据计算出的newCap创建新的桶数组，桶数组table也是在这里进行初始化的； 将键值对节点重新映射到新的桶数组中；如果节点是TreeNode类型，则需要拆分红黑树。如果是普通节点，则节点按原顺序进行分组； 注意点： newThr 为 0 时，按阈值计算公式进行计算； 链表进行有序分组，创建了四个变量：loHead , loTail这两个是存放扩容后位置不变的桶；hiHead, hiTail 这两个是存放位置发生变化的桶；通过实际的hash定位我们可以看出：实际上扩容后位置的变化就两种情况：不变和原位置+oldCap（这个取决于扩容后n-1的二进制的最高位对应的hash的位置上是0还是1。为0的则位置不发生变化，为1的则新位置等于老位置+oldCap）,那么我们怎么确定是不是1呢？通过观察发现，可以采用hash&amp;oldCap是不是等于0来判断(==oldCap的二进制和（2*oldCap-1）的二进制的最高位是一样的==),如果等于0，则新的扩容后的桶位置不变，不等于0，则新的扩容后的位置等于原位置+oldCap。对应于下面这段代码：![image-20220104185904728](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220104185904728.png) 红黑树链表树化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static final int TREEIFY_THRESHOLD = 8;/** * 当桶数组容量小于该值时，优先进行扩容，而不是树化 */static final int MIN_TREEIFY_CAPACITY = 64;static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125;&#125;/** * 将普通节点链表转换成树形节点链表 */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; // 桶数组容量小于 MIN_TREEIFY_CAPACITY，优先进行扩容而不是树化 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // hd 为头节点（head），tl 为尾节点（tail） TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; // 将普通节点替换成树形节点 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); // 将普通链表转成由树形节点链表 if ((tab[index] = hd) != null) // 将树形链表转换成红黑树 hd.treeify(tab); &#125;&#125;TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; 树化需要满足的两个条件： 链表长度大于等于 TREEIFY_THRESHOLD=8 桶数组容量大于等于 MIN_TREEIFY_CAPACITY=64 红黑树拆分首先一点，在将普通的链表转成红黑树时，HashMap通过额外的两个引用next和prev保留了原链表的节点顺序。这样再对红黑树进行重新映射时，完全可以按照映射链表的方式进行。这样就可以避免将红黑树转成链表之后再进行映射，提高了效率。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 红黑树转链表阈值static final int UNTREEIFY_THRESHOLD = 6;final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; /* * 红黑树节点仍然保留了 next 引用，故仍可以按链表方式遍历红黑树。 * 下面的循环是对红黑树节点进行分组，与上面类似 */ for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; // 如果 loHead 不为空，且链表长度小于等于 6，则将红黑树转成链表 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; /* * hiHead == null 时，表明扩容后， * 所有节点仍在原位置，树结构不变，无需重新树化 */ if (hiHead != null) loHead.treeify(tab); &#125; &#125; // 与上面类似 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; 可以看出，这个重新树的重新拆分的逻辑和链表的是差不多的。不同的地方在于，树的重新映射后，会讲红黑树拆分成两条由TreeNode组成的链表。如果链表长度小于UNTREEIFY_THRESHOLD,则将链表转成普通的链表，否则根据条件重新将TreeNode链表树化。 红黑树链化123456789101112131415161718final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; // 遍历 TreeNode 链表，并用 Node 替换 for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; // 替换节点类型 Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 这里的TreeNode到普通Node的转换，还是挺简单的，没有很复杂的逻辑处理。主要是使用了replacementNode这个方法； 删除12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // 1. 定位桶位置 (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // 如果键的值与链表第一个节点相等，则将 node 指向该节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; // 如果是 TreeNode 类型，调用红黑树的查找逻辑定位待删除节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; // 2. 遍历链表，找到待删除节点 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 3. 删除节点，并修复链表或红黑树 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 删除的逻辑还是很清晰的，主要也是现在桶中定位，定位到了如果是某个位置上的链表的第一个节点，则删除该node；如果是链表中某个节点，则将该节点进行删除。 PS： HashMap中使用了readObject和writeObject两个方法自定义了序列化的内容。没有使用Java默认的序列化机制。table变量被transient修饰，不会被默认的序列化机制序列化。原因是键值对在不同的JVM虚拟机下，所处的桶的位置有可能是不同的，在不同的JVM虚拟机下进行反序列化table可能会发生错误；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/gRPC/GRPC框架的使用","date":"2021-12-30T03:22:37.281Z","updated":"2022-01-12T09:11:33.341Z","comments":true,"path":"2021/12/30/typora文件集合/技术/gRPC/GRPC框架的使用/","link":"","permalink":"http://example.com/2021/12/30/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/gRPC/GRPC%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"GRPC框架的使用：1ClientInterceptor 拦截器的作用？轮询策略：![image-20211230113255423](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211230113255423.png) Grpc的设计理念： 服务而非对对象、消息而非引用。grpc的诞生就是为了适应为微服务。原话：促进微服务的系统间粗粒度消息交互设计理念，同时避免分布式对象的陷阱和分布式计算的缪误。 普遍并且简单适用于移动的设备，迎合现在的移动互联场景；原话：该基础框架应该再任何流行的开发平台上适用，并且易于个人在自己的平台上构建。它在CPU和内存有限的设备上也应该切实可行。 流适应大数据的处理；原话：存储系统依赖于流和流控来传递大数据集。像语音转文本或股票代码等其他服务，依靠流表达时间相关的消息序列。 元数据交换抽离出与业务逻辑无关的代码；原话：常见的横切关注点，如认证或跟踪，依赖数据交换,但这不是服务公共接口中的一部分。部署依赖于他们将这些特性以不同速度演进到服务暴露的个别API的能力。 Grpc中的几个核心的概念： Stub：（桩）该层是暴露给大多数开发者的，提供类型安全的绑定到正在适应的数据模型/IDL/接口。gRPC带有一个proto-buffer编译器的插件。用来从.proto文件中生成Stub接口。 关键接口： Stream Observe Channel该层是传输处理之上的抽象，适合拦截器/装饰器，并比Stub层暴露更多的行为给应用。它像让应用框架可以简单的使用这个层来定位横切关注点，如日志、监控、认证等。流程控制也在这个层上暴露，允许更多复杂的应用来直接使用它进行交互。 Common Client NameResolver是一个可拔插的组件，用以解析目标URL并返回地址给调用者；NameResolver使用URI的schema来检测是否可以解析它，再使用schema后面的组件来做实际处理。目标的地址和属性可能随着时间的过去发生修改，因此调用者注册Listener来接受持续的更新；扩展术语： 123456789101112131415161718URI：（统一资源标识符）通用的形式：schema:[//[user:password@]host:[port]][/]path[?query][#fragment]1.schema:由一系列字符组成，以字母开头，跟着有字母，数字，加号(+)，点号(.)或者中划线(-)的任何组合。流行的schema包括：http、ftp、malito(邮箱服务中)、file和data。2.双斜杠（//）某些 scheme 要求有这个， 而有些 scheme 不要求。当 authority 部分缺失时， path 部分不能以双斜杠开始。3.authority部分包括： 可选认证部分：有用户名和密码，冒号分割，带一个@符号； host：可以是hostname、ip等； 可选的端口号：和hostname之间用冒号分割；4.路径包含数据，通常以层次形式组织，表现为一系列斜杠分割的部分。5.可选的query通常是一系列的属性值对，以分隔符分割；6.可选的fragment/片段和之前的部分以#分割。fragment包括一个fragment identifier片段标识，提供到间接资源的引导。 ![image-20211230143739616](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211230143739616.png) 1authority代表URI中的 [userinfo@]host[:port]，包括host(或者ip)和可选的port和userinfo。这个是RPC框架中比较常见的一个术语。 Metadata 提供对读取和写入元数据数值的访问，元数据值在调用期间交换内部定义的类：Marshaller：定义了两个Marshaller的interface，分别处理二进制和ASCII自字符的值； BInaryMarshaller：用于序列化为原始二进制的元数据值的装配器； AsciiMarshaller: 用序列化为ASCII字符的元数据值的装配器，值只包含下列字符： 空格：0x20 ASCII可见字符（0x21-0x7E） 。 内部类：Metadata.Key元数据项的key，是为了元数据的解析和序列化；有效字符串： 1234数字： 0-9大写字符： A-Z（标准化到小写)小写字符： a-z特殊字符： -_. Channel通道。核心方法：ClientCall方法： 12public abstract &lt;RequestT, ResponseT&gt; ClientCall&lt;RequestT, ResponseT&gt; newCall( MethodDescriptor&lt;RequestT, ResponseT&gt; methodDescriptor, CallOptions callOptions); 作用：构建一个用于远程操作的ClientCall对象，通过给定的MethodDescriptor来制定。返回的ClientCall对象不会触发任何远程行为，直到ClientCall.start(ClientCall.Listener,Metadata)方法调用。 ManagedChannelManagedChannel在Channel的基础上提供了对Channel生命周期管理功能； 实际实现式就是添加了 shutdown()/shutdownNow() 方法用于关闭 Channel，isShutdown()/isTerminated() 方法用于检测 Channel 状态， 以及 awaitTermination() 方法用于等待关闭操作完成。 ManagedChannelImpl InUseStateAggregator：正在使用的状态的聚合器，聚合一个对象集合的正在使用的状态。实现原理：每个要使用这个聚合器的调用者都要存进来一个对象（范型T），然后用完之后再取出来，这样就可以通过保存对象数量的变化来判断开始使用或者已经不在使用。 NameResolvername resolver的start()方法，也就是name resolver要开始解析name的这个工作，只有两种情况下开始： 第一次rpc请求：此时要调用Channel的newCall()方法得到ClientCall的实例，然后调用ClientCall的start()方法，期间获取ClientTransport时激发一次name reslover的start()方法;![image-20220101185222825](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101185222825.png) 在ManagedChannelImpl的第361行的这个方法中，只有第一次调用的时候，inUseStateAggregator.,isInUse()这个方法返回的才有可能是false，这个时候回去创建timer以便在稍后进入空闲模式，然后回去创建lb以及触发name reslver的start方法。![image-20220101185517463](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101185517463.png) 再一次调用rpc方法的时候，这个时候lbHelper就不是null了，所以也就不会出发name resolver的start方法了。那这个name resolver最终调用的是哪里呢？通过项目启动时，配置的BeanConfig中可以看出，每一个bean初始化的时候，都回去初始化一下ManagedChannelImpl这个类，通过上面的分析可以看出，这个是个Channel的管理类，负责网络的通信。然后这个ManagedChannelImpl也是会注入在对应的接口sub的实现类中，为后续的请求做准备。每个sub中的NameResolver类也是在这个过程中创建的。NameResolver类初始化的流程：第一步：![image-20220101195048927](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101195048927.png) 第二步：![image-20220101195109926](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101195109926.png) 第三步： ![image-20220101195150543](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101195150543.png) 第四步：![image-20220101195220372](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101195220372.png) 最终： ![image-20220101195553821](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101195553821.png) 可以看出，最终创建的NameResolverder的实现类时OstrichNameResolver。 所以，实际上的上面所说的调用的nameResolver的start方法，真的调用的是OstrichNameResolver的start方法。如下图：![image-20220101200036448](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101200036448.png) 然后，我们看下这个start方法中做了什么事情。 之前创建OstrichNameResolver的时候，初始化了两个线程池——GrpcUtil.SHARED_CHANNEL_EXECUTOR, GrpcUtil.TIMER_SERVICE，当然，它们都是包装的，具体的线程池在其内部。一个时常规的线程池、一个时定时任务的线程池。这个方法的主要作用就是查询注册中心，然后把一些列的服务地址，写入Listener中，如下图：![image-20220101203628916](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101203628916.png) 然后调用了ManagedChannelImpl中onResult方法：![image-20220101205018535](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101205018535.png) 大体而言，此方法的主要目的就是将上面的到的服务的ip:host信息写入LoadBalance中。最终会走到RoundRobinLoadBalancer的handleResolvedAddresses方法中：![image-20220101231409755](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101231409755.png) 服务拉取的时间间隔（5分钟）![image-20220101194149585](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20220101194149585.png) ​ 参考博文：https://skyao.gitbooks.io/learning-grpc/content/channel/channel/impl/idle_mode.html","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/12月29号答疑","date":"2021-12-29T13:05:04.841Z","updated":"2022-02-09T09:27:21.934Z","comments":true,"path":"2021/12/29/typora文件集合/拉钩/JVM/12月29号答疑/","link":"","permalink":"http://example.com/2021/12/29/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/12%E6%9C%8829%E5%8F%B7%E7%AD%94%E7%96%91/","excerpt":"","text":"12月29号答疑：鉴权数据会存在分布式缓存上，比如redis，客户端本地应该也会有jvm缓存； jvm缓存查鉴权信息失败，会再去redis中再查一下，如果还没有就认为没有权限。把mysql和redis的数据一致性做好即可。 服务端鉴权就是把可以请求这个服务的上游服务，让当前服务感知到。好处是比较节约客户端集群的内存消耗，但是会浪费网络io。 我认为难点是两个：1.拿什么样的结果；2.如何对线上不造成影响 的意思是，你本次压测的目的是什么，是想要这个接口的qps极限的话，你就得事先把需要统计的指标都设计好,cpu idle、gc、网络io、磁盘io，接口耗时的tp90、tp99啥的; 然后第二个问题，就是如何不影响线上。这个一般都是通用套路，比如影子表，关键节点（比如发mq）跳过之类的. 影子表: 其实本质就是在同一个库上创建一个跟原表结构一模一样，表名加个_shadow_前缀的表 。 Q：怎么识别是压测线程？ A：rpc调用有个叫trace的概念，内部有点类似threadlocal，但是是全链路的threadlocal，把压测标识埋到这个里面。所以我之前说过大家学习源码的重点之一，是学习人家的设计。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/12月26号答疑","date":"2021-12-25T05:28:00.173Z","updated":"2022-02-13T07:49:55.909Z","comments":true,"path":"2021/12/25/typora文件集合/拉钩/JVM/12月26号答疑/","link":"","permalink":"http://example.com/2021/12/25/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/12%E6%9C%8826%E5%8F%B7%E7%AD%94%E7%96%91/","excerpt":"","text":"JVM保守式GC：JVM选择不记录栈里面数据的类型，无法区分出内存里面某个位置上的数据到底应该解读为引用类型还是整型还是别的什么。这种实现出来的GC我们称为保守式GC。优点：实现简单。缺点： 会有部分对象本来应该已经死了，但有疑似指针指向它们，使它们逃过GC的收集。 由于不知道疑似指针是否真的是指针，所以它们的值都不能改写，移动对象就意味着要修改指针。怎么解决？增加一层间接层-句柄。不直接通过指针来实现引用，所有引用先指到一个句柄表里，再从句柄表找到实际对象。 半保守式GC：JVM可以选择不在栈上记录类型信息，而在对象上记录类型信息。这样，扫描栈的时候仍然会跟上面说的过程一样，但扫描到GC堆内的对象时因为对象带有足够的类型信息了，JVM就能够判断出对象内什么位置的数据是引用类型的了。半保守GC支持部分对象的移动。只将保守扫描能直接扫到的对象设置为不可移动（pinned），而从它们出发再扫描到的对象就可以移动了。 准确式GC：JVM可以准确判断出所有位置上的数据是不是指向GC堆里的引用。包括活动记录（栈+寄存器）里的数据。 实现方式： 让数据自身带上标记（tag）； 让编译器为每个方法生成特别的扫描代码； 从外部记录下类型信息，保存成映射表。HotSpot中把这样的数据结构称为OopMap； OopMap：对象的类型信息中记录自己的OopMap，记录了该类型的对象内什么偏移量上是什么类型的数据。这些数据是在类加载过程中计算得到的。每个被JIT编译过后的方法也会在一些特定的位置记录下OopMap，记录了执行到该方法的某条指令的时候，栈上和寄存器里哪些位置是引用。这样GC在扫描栈的时候就就会查询这些OopMap就知道哪些是引用了。使用映射表的两种方式： 每次都遍历原始的映射表，循环的一个一个偏移量扫描过去。这种叫做解释式；HotSpot采用； 为每个映射表生成一块定制的扫描代码，以后每次要用映射表就直接执行生成的扫描代码。这种叫做编译式。 对于JNI方法的处理：由于JNI方法不是JVM中的解释器执行的，也不是由JVM的JIT编译器生成的，所以会缺少OopMap信息。HotSpot的解决方案：所有经过JNI调用边界（调用JNI方法传入的参数、从JNI方法传回的返回值）的引用都必须用“句柄”包装起来。JNI调用Java API的时候也必须自己用句柄包装指针。这样也导致JNI方法执行的比较慢，因为有句柄的包装和拆包装操作。参考博文：https://blog.csdn.net/u014028317/article/details/107435049 ![image-20211226170248456](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211226170248456.png) 主动式中断：首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。已经废弃。 抢占式中断：设置一个中断标志，各个线程运行到safe point的时候主动轮询这个安全标志，如果中断标志为真，则将自己进行中断挂起。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/12月19号直播","date":"2021-12-19T12:39:05.541Z","updated":"2021-12-19T14:23:52.967Z","comments":true,"path":"2021/12/19/typora文件集合/拉钩/JVM/12月19号直播/","link":"","permalink":"http://example.com/2021/12/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/12%E6%9C%8819%E5%8F%B7%E7%9B%B4%E6%92%AD/","excerpt":"","text":"为什么不能直接在对象上直接保留跨代引用标记？而一定要引入卡表的设计？ 增加了扫描的工作量， ![image-20211219205036319](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211219205036319.png) 染色指针： ZGC垃圾收集器：并发标记： 并发预备重分配： Region： 动态分配内存，减少了分代中对象从一个分代到另一个分代的复制移动成本； 粒度更细，可预测； 答疑： ZGC ：读屏障、指针关联、指针重新定向（指针治愈）； 作业： ![image-20211219214925252](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211219214925252.png) 当前收集器的缺点、优点； 下一个收集器如何解决了这些缺点； G1中的Eden区域、Servivor区域的划分： G1中的Region区是不连续的。 为什么G1 的记忆表 在每个 Region 里存储？ 看下各个基础的GC算法：复制、标记-清除、标记-整理","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/JVM调优","date":"2021-12-19T09:43:10.014Z","updated":"2022-02-16T02:26:06.455Z","comments":true,"path":"2021/12/19/typora文件集合/拉钩/JVM/JVM调优/","link":"","permalink":"http://example.com/2021/12/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/JVM%E8%B0%83%E4%BC%98/","excerpt":"","text":"命令1.1 jps jps 是(java process Status Tool), Java版的ps命令，查看java进程及其相关的信息，如果你想找到一个java进程的pid，那可以用jps命令替代linux中的ps命令了，简单而方便。 JVM常见优化及参数： 查看参数的默认值： 1java -XX:+PrintFlagsFinal -XX:+UseG1GC 2&gt;&amp;1 | grep UseAdaptiveSizePolicy 以ES的JVM参数使用为例，我们看下JVM常见的优化点： 堆空间配置下面是 ES 对于堆空间大小的配置。 12-Xms1g-Xmx1g 通过 Xmx 可指定堆的最大值，通过 Xms 可指定堆的初始大小。我们通常把这两个参数，设置成一样大小的，可避免堆空间在动态扩容时的时间开销。 在配置文件中还有 AlwaysPreTouch 这个参数。 1-XX:+AlwaysPreTouch 线上故障排查","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/多线程/多线程学习笔记","date":"2021-12-18T14:04:43.180Z","updated":"2021-12-18T14:04:48.372Z","comments":true,"path":"2021/12/18/typora文件集合/拉钩/多线程/多线程学习笔记/","link":"","permalink":"http://example.com/2021/12/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"多线程学习笔记","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/JVM内存分配机制","date":"2021-12-12T15:08:33.441Z","updated":"2022-02-12T18:19:05.362Z","comments":true,"path":"2021/12/12/typora文件集合/拉钩/JVM/JVM内存分配机制/","link":"","permalink":"http://example.com/2021/12/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/JVM%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%9C%BA%E5%88%B6/","excerpt":"","text":"JVM内存分配机制 见博客：https://www.cnblogs.com/itpower/p/15401004.html 对象内存分配的两种方式： 指针碰撞；默认采用的是指针碰撞的方式。如果Java堆中的内存是绝对规整，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界嗲的只是器，那所分配的内存就仅仅是把那个指针向空闲的那边挪动一段与对象大小相等的距离。 空闲列表；如果java堆中的内存不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单的进行指针碰撞了，虚拟机就必须维护一个列表，记录哪些内存是可用的，再分配的时候从列表中找到一块足够大的内存空间分配给对象实例，并更新列表上的记录； 多个对象并发占用空间的问题？ 解决方案一：CAS，失败重试的方式保证更新操作的原子性来对分配空间的动作进行同步处理； 解决方案二：TLAB，（Thread Local Allocation Buffer）,在每个线程初始化的时候，提前在堆空间中为线程分配一块专属的内存。jdk8默认的内存分配方式。开启：-XX:+UseTLAB，制定大小:-XX:TLABSize 指针压缩：在64位操作系统中，jvm默认开启指针压缩。指针压缩就是将KClass Pointer类型指针进行压缩。 开启指针压缩的命令：-XX:+UseCompressedOops 为什么要进行指针压缩？ 减少64位平台下的内存消耗，默认启用指针压缩； 32位地址最大支持4GB内存，可以通过对对象指针的压缩编码、解码方式进行优化，使得jvm只用32位地址就可以支持更大的内存配置； 堆内存小于4G时，不需要启用指针压缩，jvm会直接去除高32位地址，即使用低虚拟地址空间； 堆内存大于32G时，压缩指针会失效，会强制使用64位（即8字节）来对java对象寻址，这就会出现1中的问题，所以堆内存不要大于32G为好。为什么会失效？首先，不压缩的情况下，KClassPointer的存储空间是8个字节，压缩的情况下是4个字节。 JVM中，对象的内存地址一般是8字节的倍数，不足8字节的，需要补齐。 内存分配的流程： 涉及的内容包括：逃逸分析、TLAB、GC、分代担保机制、动态年龄判断 第一步：判断是不是可以在栈上分配对象。 原因：将所有对象都放在对上创建，会导致堆上容易触发GC、影响应用性能。 手段：通过==逃逸分析==技术，确定对象会不会被外部访问。如果不会逃逸（不会被外部访问到），那么就会将该对象在栈上分配内存。随着栈桢出栈而销毁，从而减轻了GC的压力。然后再结合标量替换技术，进行内存的实际分配。 什么是标量替换？ 当栈桢没有一块连续的空间去放得下一个对象时，JVM这个时候不会去创建改对象，而是会将该对象的成员变量分解为若干个被方法使用的局部变量。这些替代的局部变量在栈桢或寄存器上分配空间。可以通过参数控制是否开启标量替换：-XX:+EliminateAllocations PS: 标量：不能被进一步分解的量，比如Java中的基础数据类型就是标量； 聚合量：可以被进一步分解的量，比如对象就是一个聚合量。 第二步：判断是不是大对象。 是否是大对象？放入老年代中：是否开启TLAB？在Eden中分配一小块空间给线程：直接在Eden中进行分配。 TLAB：Thread Local Allocation Buffer。 参数控制：-XX:+UseTLAB。 这个地方就涉及到了JVM的中的堆内存划分了，如下图所示： 对象动态年龄判断 ​ 如果Survivor区域里面，一批对象的总大小大于这块Survivor区域内存大小的50%（-XX:TargetSurvivorRatio可以指定），那么此时大于等于这批对象年龄最大值的对象，就可以直接进入老年代了。作用：希望那些可能是长期存活的对象，尽早进入老年代。对象动态年龄判断机制一般是在minor gc之后触发的。 老年代的空间分配担保机制(存在的意义就是提前进行预判，避免发生OOM，因为我们之前已经提到，minor GC之后会存在Eden区的对象往Old区中移动)。 年轻代每次minor GC之前JVM都会计算下老年代的可用空间。如果这个可用空间小于年轻代里现有的所有对象大小之和（包括垃圾对象），就会看一下 -XX:-HandlePromotionFailure的参数是否设置了，如果有这个参数，就会看老年代的可用内存大小，是否大于之前每一次minor GC之后进入老年代的对象的平均大小； 如果老年代可用内存大小&lt;平均minor GC之后进入老年代的对象的大小或者没有开启允许担保失败的参数，那么就会直接触发一次Full GC，然后再出发一次Minor GC，如果回收完还是没有足够的空间存放新对象就会发生OOM； 如果minor GC之后剩余存活的需要挪动到老年代的对象的大小还是大于老年代的可用空间，那么也会出发Full GC，Full GC完之后如果没有空间放minor GC（说明老年代还是太小了），这个时候也会发生OOM。 周三答疑记录： 进入老年代有如下几种情况：1.对象经过几次垃圾回收，熬到设定的年龄阈值，就会晋升到老年代。2.如果直接分配大对象，该大对象超出了JVM设置的限定值，就会直接分配到老年代。3.在一次新生代GC后，Survivor区域中的几个年龄对象加起来超过了Survivor区内存的一半，那么根据动态年龄判定规则，从最小的年龄加起，比如年龄1+年龄2+年龄3的对象大小总和，超过了Survivor区内存的一半，此时年龄3以上的对象就会晋升老年代。4.新生代GC后，存活下来的对象太多，Survivor区放不下，此时对象直接晋升老年代。 CMS垃圾收集器中的增量更新与原始快照问题； ​ 2.1 卡表是什么？ ​ 2.2 CMS采用的是增量更新 漏标的两个充要条件 一、有至少一个黑色对象在自己被标记之后指向了这个白色对象；二、所有的灰色对象在自己引用扫描完成之前删除了对白色对象的引用这两个条件,必须全满足,才会造成漏标问题。 换言之,我们破坏任何一个条件.这个白色对象,就不会再被漏标 这样就产生了两个解决办法 CMS采用的是增量更新 增量更新破坏的是第一个条件,我们在这个黑色对象增加了对白色对象的引用之后,将它的这个引用,记录下来,在最后标记的时候,再以这个黑色对象为根,对它的引用进行重新扫描. 可以简单理解为,当一个黑色对象增加了对白色对象的引用,那么这个黑色对象就被变灰 这样有一个缺点。就是会重新扫描这个黑色对象的所有引用,比较浪费时间； G1采用的是原始快照 原始快照破坏的是第二个条件,我们在这个灰色对象取消对白色对象的引用之前,将这个引用记录下来,在最后标记的时候,再以这个引用指向的白色对象为根,对它的引用进行扫描 可以简单理解为,当一个灰色对象取消了对白色对象的引用,那么这个白色对象被变灰。 这样做的缺点就是,这个白色对象有可能并没有黑色对象去引用它,但是它还是被变灰了,就会导致它和它的引用,本来应该被垃圾回收掉,但是此次GC存活了下来,就是所谓的浮动垃圾.其实这样是比较可以忍受的,只是让它多存活了一次GC而已,浪费一点点空间,但是会比增量更新更省时间。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/JVM-拉钩","date":"2021-12-05T12:49:58.787Z","updated":"2022-03-09T11:19:58.830Z","comments":true,"path":"2021/12/05/typora文件集合/拉钩/JVM/JVM-拉钩/","link":"","permalink":"http://example.com/2021/12/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/JVM-%E6%8B%89%E9%92%A9/","excerpt":"","text":"Q：哪些是线程共享的？哪些是线程隔离的？ A：是否会存在对对象的成员变量进行引用、处理、计算， 线程之间需要隔离、通信； Q：栈？ A：运行时遵循先进先出的顺序，和栈的逻辑是一样的； Q：StackOverFlowError 异常的原因？ 存在无限递归调用，栈的分配的空间不够使用； 循环调用；有一个参数可以控制栈的深度； Q： A：堆、方法区，因为这里存储的是对象的实例数据，占用了主要的JVM内存大小，其他的部分主要是对堆中对象的引用、计算； Java对象创建的过程？ 内存分配方法：指针碰撞、空闲列表； 句柄池： 并发问题解决思路？ CAS+失败重试； 本地线程分配缓冲-TLAB（Thread Local Allocation Buffer）, 当线程请求的栈深度大于虚拟机所允许的最大深度，将抛出 StackOverflowError，一般是递归调用或循环调用没有结束。 JVM 提供了参数来设置虚拟机栈的大小【Xss 和 ThreadStackSize】，同样的虚拟机栈大小，栈深度取决于调用的方法需要分配多少内存。 如果方法的本地变量很多，那每个栈帧需要的内存就越多，那么最大栈深度就越小。 另外，如果虚拟机栈的容量可以动态扩展（HotSpot不允许），当扩展的时候无法申请到足够的内存就会抛出 OutOfMemoryError 异常。 内存管理：运行时内存、垃圾回收、监控故障处理、性能调优； 虚拟机执行子系统：类文件结构、类加载、字节码执行 程序编译与代码优化：前端编译优化、后端编译优化； 高效并发：Java并发模型与线程、线程安全与锁优化； ![image-20211205220712674](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211205220712674.png) Java字节码文件： javap &lt;options&gt;&lt;classes&gt; 中的options选项： 1234567891011121314151617-help --help -? 输出此用法消息-version 版本信息-v -verbose 输出附加信息-l 输出行号和本地变量表-public 仅显示公共类和成员-protected 显示受保护的/公共类和成员-package 显示程序包/受保护的/公共类 和成员 (默认)-p -private 显示所有类和成员-c 对代码进行反汇编-s 输出内部类型签名-sysinfo 显示正在处理的类的 系统信息 (路径, 大小, 日期, MD5 散列)-constants 显示最终常量-classpath &lt;path&gt; 指定查找用户类文件的位置-cp &lt;path&gt; 指定查找用户类文件的位置-bootclasspath &lt;path&gt; 覆盖引导类文件的位置 字节码文件信息：开头的7行信息包括： Class文件当前所在位置、最后修改时间、文件大小、MD5值、编译自哪个文件、类的全限定名、jdk次版本号、jdk主版本号； 类的访问标志： 访问名称 标志值 含义 ACC_PUBLIC 0x0001 是否为public类型 ACC_FINAL 0x0010 是否被声明为final，只有类可以设置 ACC_SUPER 0x0020 是否允许使用invokespecical字节码指令的新语义 ACC_INTERFACE 0x0200 标志这个是一个接口 ACC_ABSTRACT 0x0400 是否是abstract类型，对于接口或者抽象类来说，其标志值为真，其他类型为假 ACC_SYNTHETIC 0x1000 标志这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 标志这个是一个注解 ACC_ENUM 0x4000 标志这个是一个枚举 常量池：Constant pool，可以理解为Class 文件中的资源仓库，主要存放两大类常量：字面量（Literal）和符号引用（Symbolic Reference）。字面量类似于java中的常量概念，如文本字符串、final常量等，而符号引用则属于编译原理方面的概念，主要包括以下三种： 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符号（Descriptor） 方法的名称和描述符号 字节码类型： 含义 标识字符 B 基本类型byte C 基本类型char D 基本类型double F 基本类型float I 基本类型int J 基本类型long S 基本类型short Z 基本类型boolean V 特殊类型void L 对象类型，以分号结尾，如Ljava/lang/Object; 方法表集合：在常量池以后是对类内部的方法描述，在字节码中以表的集合的形式表现。主要属性有： stack：最大操作数栈，JVM在运行时会根据这个值来分配栈帧（Frame）中的操作栈深度； locals：局部变量所需的存储空间。单位Slot，Slot是虚拟机为局部变量分配内存时所使用的最小单位 ，为4个字节大小。方法参数（包括实例方法中的隐藏参数this）、显示异常处理器的参数（try catch中的catch块所定义的异常）、方法体中定义的局部变量都需要使用局部变量表来存放。需要注意的是，locals的大小并不一定等于所有局部变量所占的Slot之和，因为局部变量中的Slot是可以重用的。 args_size：方法中参数的个数，每个实例方法都有一个隐藏参数this； attribute_info:方法体内容，主要是栈的入栈与出栈； LineNumberTable: 该属性的作用是描述源码行号与字节码行号（字节码偏移量）之间的对应关系。 LocalVariableTable: 该属性的作用是描述栈帧中局部变量与源码中定义的变量之间的关系。 类名：源码文件； 运行时、加载时 指令：istore/","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/11月25号购物车提示预览失败","date":"2021-11-29T05:34:55.033Z","updated":"2021-11-29T09:32:40.358Z","comments":true,"path":"2021/11/29/typora文件集合/事故/11月25号购物车提示预览失败/","link":"","permalink":"http://example.com/2021/11/29/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/11%E6%9C%8825%E5%8F%B7%E8%B4%AD%E7%89%A9%E8%BD%A6%E6%8F%90%E7%A4%BA%E9%A2%84%E8%A7%88%E5%A4%B1%E8%B4%A5/","excerpt":"","text":"问题 11月25号晚上，线上APP下单提示预览订单失败，请稍后重试； 问题排查过程： 11月25号晚上9点02分，业务反馈App下单提示预览失败， 9点半左右，接受到这个反馈，发现是线上master被杨航重新部署了。之前一天有问题的代码合并到了master上。快速把本地的代码重新合到master，重新部署以后，线上恢复正常； 问题原因：之前item增加了线上问题的告警，夏振宇下掉了单品扣点的代码（这部分业务逻辑已经不在商品维护）。但是下单的时候，到家store服务调用了营销marketing的服务，marketing中调用了商品的单品扣点服务，导致服务不可用，营销到了到家购物车的下单。 后续Action： 和营销同学沟通，去掉对商品扣点服务的依赖； 下掉服务的时候，要看下有没有被外域调用，最好和相应的外域沟通下，有时候通过监控也不能避免这个问题；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/分享/分享","date":"2021-11-26T10:03:01.012Z","updated":"2022-01-23T12:29:44.286Z","comments":true,"path":"2021/11/26/typora文件集合/拉钩/分享/分享/","link":"","permalink":"http://example.com/2021/11/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%88%86%E4%BA%AB/%E5%88%86%E4%BA%AB/","excerpt":"","text":"Synchronized 锁（Synchronized、ReentrantLock的区别） Synchronized、ReentrantLock的区别 两者都是可重入锁，什么是可重入锁？已获得锁的对象，可以再次获取锁； Synchronized是JVM实现的，使用起来简单；ReentrantLock是一个Java提供的API，比较灵活； Synchronized是非公平锁，ReentrantLock可以提供非公平锁和公平锁两种，利用fair参数可以控制； 都提供了等待、通知机制； Synchronized是利用了Obejct对象的notify和wait方法； ReentrantLock需要借助于condition、newCondition方法 ReentrantLock提供了中断等待机制；lock.lockInterruptibly() Java对象头的结构： MarkWord ：存储对象的hashcode、分代年龄、gc标记、同步状态、锁标志位等 kClassPointer：对象的类型指针，指向类元数据（类class文件信息，metaspace空间的方法区） Synchronized的优化&amp;Mark word 的结构 2.1 无锁（01），所有线程均可以修改某一个资源的值，但同时只能由一个线程修改成功，其他会循环尝试；2.2 偏向锁（01）：在对象头MarkWord中存放有对应的线程的id，如果发现请求线程是同一个的话，再次请求的时候，直接获取锁；偏向锁的一个撤销 ：全局安全点（没有字节码在执行），暂停拥有偏向锁的线程，并判断对象是否处于被锁定的状态，如果没有的话，则把对象置为无锁状态，并撤销偏向锁，恢复到无锁或者轻量级锁状态；2.3 轻量级锁（00）：如果在偏向锁的过程中，有其他的线程进行请求的话，就会转化为轻量级锁，或者是关闭偏向锁功能的时候（即2.2种描述的）。线程的栈帧中有一个Lock record的区域，拷贝一份Mark word到这个区域。线程会通过CAS操作，尝试讲Mark word 更新为这个栈帧中锁记录的指针，同时，LockRecord 中的owner指针也会指向Mark word。更新成功，线程就拥有对象的锁。如果CAS失败，判断Mark word是否指向当前线程的指针，是的话，就直接进入同步代码块继续执行。 另一个线程会自旋，当自旋超过一定次数之后，会膨胀为重量级锁。（自适应自旋）；另一个升级为重量级锁的原因是这个时候有另外的线程来争抢对象的锁；2.4 重量级锁（10）：升级到重量级锁的时候，会创建一个ObjectMonitor锁对象。重量级锁的时候，mark word中存储的是这个monitor锁的指针，另外monitor中，有一个owner指针，指向拥有锁的线程。ObjectMonitor对象内部结构：entryList： 在进入或者重新进入时被阻塞的线程；waitSet：在改Monitor上等待的线程；owner： monitor的所有者（线程）；count: 这个monitor里面表示count（计数器），用于CAS操作。一次CAS操作成功，owner就会置换为指向对应线程的指针；利用Mutex Lock这个系统提供的来实现，来进行加锁，缺点：需要从内核态切换到用户态，比较消耗性能； 同时，每一个线程都有一个monitor record列表。 ObjectMonitor初始化： ReentrantLock基于AQS实现。可重入的获取锁的工具类。 AQS基于CLH 队列实现线程阻塞等待以及被唤醒时锁分配的机制的。 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 获取锁： 一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取锁，直到获取成功或者不再需要获取（中断）","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/11月23号ES接口超时","date":"2021-11-24T05:44:09.649Z","updated":"2021-11-29T05:51:49.601Z","comments":true,"path":"2021/11/24/typora文件集合/事故/11月23号ES接口超时/","link":"","permalink":"http://example.com/2021/11/24/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/11%E6%9C%8823%E5%8F%B7ES%E6%8E%A5%E5%8F%A3%E8%B6%85%E6%97%B6/","excerpt":"","text":"问题描述：商家商品列表查询报Service timeout； 问题排查过程 11月23号下午4点，测试张璠以及产品反馈商家商品列表打不开，报service timeout，小黄人开始跟进这个问题； 下午4点半的时候，夏振宇开始跟进这个问题，排查下来发现是kernel-item调用matrix查询es出现超时； 通过kibana控制台发现，shop_single_item_docs_v1这个索引出现了大量的段合并，shop_item以及shop_item_sku两张表有大量的binglog消息，消耗了比较多的CPU资源。于是在4点50分左右的时候，手动冻结了这个索引，使其不能进行段合并以及写入； 冻结了shop_single_item_docs_v1这个索引以后，发现之前负载比较高的两个节点，其中一个节点的CPU利用率降下来了，但是另外一个节点的还是很高。于是开始进行ES线程分析，查询导致CPU负载比较高的线程使用情况；发现其中的一个索引shop_item_docs的请求都打到了同一个es节点上，但是主副分片是在两个不同的node上的。怀疑是es内部的负载不均衡导致的，于是删除了这个索引的副本，重新设置。新的副本重新设置好以后。节点负载恢复正常； 下午7点00分的时候，线上ES恢复正常； 下午7点左右，重新打开之前冻结的shop_single_item_docs_v1索引，开始正常提供APP搜索服务； 后续Action： 我们的ES查询现在存在两个比较致命的问题： 为了实现类似MySQL中的like查询效果，使用了比较占用CPU资源的wildcard查询语句； shop_single_item_docs_v1 这个索引设计的不合理，单个document（文档）占用了比较大的内存，导致段合并的时候，比较消耗性能； 优化点： 针对第一个问题，一方面对这种条码、plu码的模糊搜索的功能，需要限制用户输入的最小、最大长度；另一方面，需要引入新的分词Ngram技术，这个在和顺晴讨论中，需要进行详细的技术方案设计； 第二个问题，后续需要把这个shop_single_item_docs_v1精简下，去掉不用的字段，需要全量刷下ES中的数据；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/调价单问题复盘","date":"2021-11-08T03:44:12.057Z","updated":"2021-11-29T05:10:23.475Z","comments":true,"path":"2021/11/08/typora文件集合/事故/调价单问题复盘/","link":"","permalink":"http://example.com/2021/11/08/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E8%B0%83%E4%BB%B7%E5%8D%95%E9%97%AE%E9%A2%98%E5%A4%8D%E7%9B%98/","excerpt":"","text":"中台前端价格显示不一致问题 问题描述业务反馈APP端商品的价格和商品中台的不一致； 问题排查过程 11月3号下午3点33分，APP测试徐梦圆反馈APP端价格和商品中台不一致； 11月3号下午7点37分，排查发现是价格支持差异化发布异常导致：价格发布的过程中，有些业务商品调价回写老系统异常，反馈给业务，业务说有些商品还是不行； 11月4号上午12点半点左右，和张帅开始排查，排查是老系统商家商品规格消息下发，修改了地点的价格， 导致地点商品的价格被覆盖； 11月4号下午1点钟，写脚本导出受影响的商品信息的正确售价给到产品和业务进行确认； 11月4号下午5点28分，在业务确认好之后，恢复了有问题的商品的价格； 售价修改之后，业务反馈还是有部分商品价格不对，再次进行排查发现是消费的消息的topic不对，导致不能被正确的ACK掉。发现是使用的pulsar组件有问题，然后这部分有问题的商品消息被手动的清空掉； 后续Action 这个问题应该是有多方面的原因导致的，最初怀疑的价格发布的bug应该只是表象，深层次的原因还是pulsar组件的问题； 消息堆积没有告警，要添加上（已添加上）； 这个问题牵涉到很多的域和系统，需要大家一起协同配合排查； 门店端价格错误 问题描述 线下门店反馈区域价格被修改掉； 问题排查过程 11月5号晚上3点钟左右，业务反馈定时任务调价有问题，商品开始进行排查； 11月5号晚上4点半排查，发现是有一个重庆初始化的调价单（10月26号执行的）有问题：售价、进价均为0，导致这个日期后面的定时任务的调价单执行不了，任务阻塞，然后赵毅成提工单删除了这一笔调价单； 定时任务重新执行，把之前已经积压的老的调价单重新执行了一部分（15个调价单），受影响15个门店，这15个门店的价格被覆盖掉，不久之后，门店反馈POS价格和中台价格不一致； 11月5号晚上5点半开始写脚本进行修复，大概9点半所有受影响的门店的价格都恢复正常； 11月6号上午11点左右，门店反馈价格POS上和中台价格又对应不上，开发收到通知开始排查； 11点10分定位到是定时任务在已经关闭的情况下，又开始执行，又有11单老数据被重新执行，影响了11个门店； 重新跑脚本刷新价格，大概1点钟恢复； 后续Action 处理问题的方式，要第一时间周知到我，不允许私下直接写脚本或者写SQL处理; 对问题处理要有完整性；类似问题，影响的数据，都要排查出来修复，需要从根本上解决问题 后续的技术方案评审，各个模块的负责人必须参加;","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/接口思路","date":"2021-11-01T09:40:34.219Z","updated":"2021-11-23T05:53:44.226Z","comments":true,"path":"2021/11/01/typora文件集合/接口思路/","link":"","permalink":"http://example.com/2021/11/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8E%A5%E5%8F%A3%E6%80%9D%E8%B7%AF/","excerpt":"","text":"Pms做更改？ 边界：业务service的作用是什么？仓储层的作用？ 内部： 外部： 接口文档： client和proto服务的区别：client中聚合了proto中的服务，client中也是按照模型进行提供的服务；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/CompletableFuture","date":"2021-10-29T03:07:34.440Z","updated":"2021-10-29T03:09:31.798Z","comments":true,"path":"2021/10/29/typora文件集合/技术/技术笔记/CompletableFuture/","link":"","permalink":"http://example.com/2021/10/29/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/CompletableFuture/","excerpt":"","text":"CompletableFuture参考地址","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/shardingJDBC查询原理","date":"2021-10-27T12:28:18.471Z","updated":"2021-10-28T02:08:23.102Z","comments":true,"path":"2021/10/27/typora文件集合/技术/技术笔记/shardingJDBC查询原理/","link":"","permalink":"http://example.com/2021/10/27/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/shardingJDBC%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86/","excerpt":"","text":"shardingJDBC分库分表的原理：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/20211023【POS】商品改价后，POS机器上没有显示最新的改价金额","date":"2021-10-25T07:13:31.061Z","updated":"2021-10-25T07:44:30.015Z","comments":true,"path":"2021/10/25/typora文件集合/事故/20211023【POS】商品改价后，POS机器上没有显示最新的改价金额/","link":"","permalink":"http://example.com/2021/10/25/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/20211023%E3%80%90POS%E3%80%91%E5%95%86%E5%93%81%E6%94%B9%E4%BB%B7%E5%90%8E%EF%BC%8CPOS%E6%9C%BA%E5%99%A8%E4%B8%8A%E6%B2%A1%E6%9C%89%E6%98%BE%E7%A4%BA%E6%9C%80%E6%96%B0%E7%9A%84%E6%94%B9%E4%BB%B7%E9%87%91%E9%A2%9D/","excerpt":"","text":"20211023【POS】商品改价后，POS机器上没有显示最新的改价金额 事故现象：商品改价后，POS机器上没有显示最新的改价金额 事故定级：事故责任人：谢远亮事故时间：2021-10-23 事故原因：1、商品端大量消息下发导致堆积，消费很慢 影响范围：门店无法正常同步商品数据 排查过程：1、2021-10-23 17：19 运营在小组群反馈：价格有异常 门店同步不了2、2021-10-23 18：04 前端张冬开始介入排查问题3、2021-10-23 18：54 前端未发现问题，转入后端开发谢远亮排查4、2021-10-23 18：54 远亮介入排查5、2021-10-18 19：30 后端定位到问题。由于商品在不停的重复发送商品变更消息，导致消息堆积6、2021-10-18 20：00 开发将所有消息重置，系统恢复正常7、2021-10-23 21: 15 商品收到远亮反馈，开始进行排查；8、2021-10-24 12: 00 排查发现是发送消息的线程池触发了拒绝策略，导致消息一直在被重复的发送，重启消息之后，解决问题； 解决方案：1、消除堆积消息 后续Action：1、堆积的消息不能由业务方反馈。增加消息堆积告警@远亮2、","categories":[],"tags":[]},{"title":"","slug":"阿里二面准备","date":"2021-10-21T21:25:34.440Z","updated":"2022-03-03T09:31:54.040Z","comments":true,"path":"2021/10/22/阿里二面准备/","link":"","permalink":"http://example.com/2021/10/22/%E9%98%BF%E9%87%8C%E4%BA%8C%E9%9D%A2%E5%87%86%E5%A4%87/","excerpt":"","text":"自我介绍技术分布式事务1. 什么是分布式事务答：为了操作不同数据库的不可分割的一系列操作“要么什么都不做，要么全套”的机制。 2. 几种常见的分布式事务答：看下分布式.md文件 3. 缓存和DB不一致（cache aside）答：Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，那么就去数据库读，然后取出数据后放入缓存，同时返回响应； 更新的时候，先删除缓存，然后再更新数据库； ![Cache Aside Pattern](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/Cache Aside Pattern.png) 三种常见的方法及问题： 先更新数据库，再更新缓存 ABBA问题：同时有A、B两个线程进行更新操作：1）线程A更新了数据库；2）线程B更新了数据库；3）线程B更新了缓存；4）线程A更新了缓存；线程B比线程A更早更新了缓存，导致脏数据的出现。 业务上：对于写多读少的场景，就会导致数据没有读请求，但是被频繁的更新，浪费性能；另一方面，缓存的计算比较复杂的话，也会导致性能浪费； 先更新缓存，再更新数据库：和上面是同样的问题； 先删除缓存，再更新数据库ABBBA问题会导致不一致的情况出现，没有过期时间的话，数据永远都是有问题的。可以采用延迟一段时间，再次删除解决； 先更新数据库，再删除缓存1）缓存刚好失效；2）请求A查询数据库，得到一个旧值；3）请求B将新值写入数据库；4）请求B删除缓存；5）请求A将查询到的旧值写入缓存；上面成立的前提是数据库写请求比读请求还要快，实际上，工程中数据库的读操作的速度要远快于写操作的。==实际项目中使用的== 双写一致性： 缓存不能读到脏数据； 缓存可能会读到过期数据，但要在可容忍的一段时间内实现最终一致性； 可容忍时间要尽可能小； 方案：采用读请求和写请求串行化，串到一个内存队列中去，这样就可以保证一定不会出现不一致的情况。但是串行化之后，系统的吞吐量就会下降，需要更多的机器去支撑； 4. MVCC 概念：MVCC(Multi Version Concurrency Control)被称为多版本控制，是指在数据库中为了实现高并发的 数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本。 多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据库的吞吐量及读写性能。如何生成的多版本?每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号， 该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。 MVCC只在 Read Commited 和 Repeatable Read 两种隔离级别下工作 原理：用排他锁锁定该行;记录 Redo log;把该行修改前的值复制到 Undo log，即图中下面的行;修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行。 5. 分布式锁的使用情况、和Redission的区别redis分布式锁： setNx命令+Lua脚本；使用Lua脚本保证原子性； 存在的问题： 单机无法保证高可用性； 主-从结构，无法保证数据的强一致性；在主机宕机时会造成锁的重复获得； 无法续租：超过expireTime以后，不能继续使用； redisson客户端： ​ 加锁：如果客户端面临的是一个redis cluster 集群，首先会根据hash节点选择一台机器； 发送lua脚本到redis服务器上； 使用exists myLock 命令判断一下，如果key不存在的话，就进行加锁，使用hset myLock命令，需要注意的是value是客户端的Id（UUID）+线程id,并设置过期时间； 如果了另一个客户端请求，会发现key已经存在，然后判断hash数据结构中是否包含客户端2的id，没有的话，返回key的剩余生存时间；这个时候，客户端2会继续尝试获取； 一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每个10s检查下，如果客户端1还持有锁，就会不断延长key的生存时间； 重入：如果客户端1再次加锁，就会将hash数据结构中的值加一； 解锁：每次对myLock数据结构中的那个加锁次数减1。如果发现是0了，说明这个客户端已经不再持有锁了，那么这个时候就可以删除这个key了，同时会发布一个redis解锁的消息给其他的客户端；如果不是0，就会继续延长这个锁的超时时间； zk与Etcd 分布式锁特性： 互斥性； 同一性； 可重入性； 容错性； 使用场景：数据的并发竞争、防止库存超卖（不适合秒杀，秒杀使用CAS和redis队列） 6.消息pulsar的架构？为什么使用pulsar？ pulsar的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息的复制； 极低的发布延迟和端到端延迟； 可无缝扩展超过100万个topic； 简单的API； 支持多种topic订阅模式 5.1 共享式：多个client可以订阅同一个topic。消息以轮训的方式分布在各个client之间，任何给定的消息仅传递给一个client。当client断开链接的时候，会将未消费的消息发送给其他的消费者。 5.2 独占式（exclusive）：近允许单个消费者订阅Topic； 5.3 故障转移模式:多个client可以订阅同一个topic。为主消费者选择非分区主题或分区主题的每个分区，并接受消息。当主使用者断开连接时，所有消息将被传递到排队的下一个使用者。对于分区主题，代理将按优先级和消费者的名字的字典顺序对消费者进行消费。然后，代理将尝试将主题平均分配给优先级最高的消费者；对于非分区主题，代理将按订阅非分区主题的顺序选择消费者； 使用Apache BookKeeper（又称 bookies）提供的持久化消息存储机制保证消息的传递； 组成部分： Broker： 负责处理和负载均衡 producer 发出的消息，并将这些消息分派给 consumer； Broker 与 Pulsar 配置存储交互来处理相应的任务，并将消息存储在 BookKeeper 实例中（又称 bookies）； Broker 依赖 ZooKeeper 集群处理特定的任务； Bookies：负责消息的存储，BookKeeper是一个分布式的预写日志（WAL）系统 ZK：用于集群级别的配置和协调; 架构说明 6.JVM 7.rpc8. 多线程 比较好的项目介绍titan项目注意：为什么离职千万不能说因为钱！","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/阿里二面准备","date":"2021-10-21T21:25:34.440Z","updated":"2022-03-03T09:31:54.040Z","comments":true,"path":"2021/10/22/typora文件集合/拉钩/阿里二面准备/","link":"","permalink":"http://example.com/2021/10/22/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E9%98%BF%E9%87%8C%E4%BA%8C%E9%9D%A2%E5%87%86%E5%A4%87/","excerpt":"","text":"自我介绍技术分布式事务1. 什么是分布式事务答：为了操作不同数据库的不可分割的一系列操作“要么什么都不做，要么全套”的机制。 2. 几种常见的分布式事务答：看下分布式.md文件 3. 缓存和DB不一致（cache aside）答：Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，那么就去数据库读，然后取出数据后放入缓存，同时返回响应； 更新的时候，先删除缓存，然后再更新数据库； ![Cache Aside Pattern](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/Cache Aside Pattern.png) 三种常见的方法及问题： 先更新数据库，再更新缓存 ABBA问题：同时有A、B两个线程进行更新操作：1）线程A更新了数据库；2）线程B更新了数据库；3）线程B更新了缓存；4）线程A更新了缓存；线程B比线程A更早更新了缓存，导致脏数据的出现。 业务上：对于写多读少的场景，就会导致数据没有读请求，但是被频繁的更新，浪费性能；另一方面，缓存的计算比较复杂的话，也会导致性能浪费； 先更新缓存，再更新数据库：和上面是同样的问题； 先删除缓存，再更新数据库ABBBA问题会导致不一致的情况出现，没有过期时间的话，数据永远都是有问题的。可以采用延迟一段时间，再次删除解决； 先更新数据库，再删除缓存1）缓存刚好失效；2）请求A查询数据库，得到一个旧值；3）请求B将新值写入数据库；4）请求B删除缓存；5）请求A将查询到的旧值写入缓存；上面成立的前提是数据库写请求比读请求还要快，实际上，工程中数据库的读操作的速度要远快于写操作的。==实际项目中使用的== 双写一致性： 缓存不能读到脏数据； 缓存可能会读到过期数据，但要在可容忍的一段时间内实现最终一致性； 可容忍时间要尽可能小； 方案：采用读请求和写请求串行化，串到一个内存队列中去，这样就可以保证一定不会出现不一致的情况。但是串行化之后，系统的吞吐量就会下降，需要更多的机器去支撑； 4. MVCC 概念：MVCC(Multi Version Concurrency Control)被称为多版本控制，是指在数据库中为了实现高并发的 数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本。 多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据库的吞吐量及读写性能。如何生成的多版本?每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号， 该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。 MVCC只在 Read Commited 和 Repeatable Read 两种隔离级别下工作 原理：用排他锁锁定该行;记录 Redo log;把该行修改前的值复制到 Undo log，即图中下面的行;修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行。 5. 分布式锁的使用情况、和Redission的区别redis分布式锁： setNx命令+Lua脚本；使用Lua脚本保证原子性； 存在的问题： 单机无法保证高可用性； 主-从结构，无法保证数据的强一致性；在主机宕机时会造成锁的重复获得； 无法续租：超过expireTime以后，不能继续使用； redisson客户端： ​ 加锁：如果客户端面临的是一个redis cluster 集群，首先会根据hash节点选择一台机器； 发送lua脚本到redis服务器上； 使用exists myLock 命令判断一下，如果key不存在的话，就进行加锁，使用hset myLock命令，需要注意的是value是客户端的Id（UUID）+线程id,并设置过期时间； 如果了另一个客户端请求，会发现key已经存在，然后判断hash数据结构中是否包含客户端2的id，没有的话，返回key的剩余生存时间；这个时候，客户端2会继续尝试获取； 一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每个10s检查下，如果客户端1还持有锁，就会不断延长key的生存时间； 重入：如果客户端1再次加锁，就会将hash数据结构中的值加一； 解锁：每次对myLock数据结构中的那个加锁次数减1。如果发现是0了，说明这个客户端已经不再持有锁了，那么这个时候就可以删除这个key了，同时会发布一个redis解锁的消息给其他的客户端；如果不是0，就会继续延长这个锁的超时时间； zk与Etcd 分布式锁特性： 互斥性； 同一性； 可重入性； 容错性； 使用场景：数据的并发竞争、防止库存超卖（不适合秒杀，秒杀使用CAS和redis队列） 6.消息pulsar的架构？为什么使用pulsar？ pulsar的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息的复制； 极低的发布延迟和端到端延迟； 可无缝扩展超过100万个topic； 简单的API； 支持多种topic订阅模式 5.1 共享式：多个client可以订阅同一个topic。消息以轮训的方式分布在各个client之间，任何给定的消息仅传递给一个client。当client断开链接的时候，会将未消费的消息发送给其他的消费者。 5.2 独占式（exclusive）：近允许单个消费者订阅Topic； 5.3 故障转移模式:多个client可以订阅同一个topic。为主消费者选择非分区主题或分区主题的每个分区，并接受消息。当主使用者断开连接时，所有消息将被传递到排队的下一个使用者。对于分区主题，代理将按优先级和消费者的名字的字典顺序对消费者进行消费。然后，代理将尝试将主题平均分配给优先级最高的消费者；对于非分区主题，代理将按订阅非分区主题的顺序选择消费者； 使用Apache BookKeeper（又称 bookies）提供的持久化消息存储机制保证消息的传递； 组成部分： Broker： 负责处理和负载均衡 producer 发出的消息，并将这些消息分派给 consumer； Broker 与 Pulsar 配置存储交互来处理相应的任务，并将消息存储在 BookKeeper 实例中（又称 bookies）； Broker 依赖 ZooKeeper 集群处理特定的任务； Bookies：负责消息的存储，BookKeeper是一个分布式的预写日志（WAL）系统 ZK：用于集群级别的配置和协调; 架构说明 6.JVM 7.rpc8. 多线程 比较好的项目介绍titan项目注意：为什么离职千万不能说因为钱！","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/复盘/面试复盘","date":"2021-10-21T02:34:14.301Z","updated":"2022-02-24T01:39:33.619Z","comments":true,"path":"2021/10/21/typora文件集合/拉钩/复盘/面试复盘/","link":"","permalink":"http://example.com/2021/10/21/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/","excerpt":"","text":"主要复习内容他好像比较喜欢问Redis，kafka，数据库索引什么的什么Redis数据结构，分布式锁，穿透、击穿，二级缓存什么的 Redis的数据结构：分布式锁、穿透、击穿、二级缓存 见Redis部分 乐其电商的面试复盘：乐观锁和悲观锁的区别以及使用场景； hashmap的插入过程； CMS以及G1的区别； logback与slf4j的关系：slf4j是一系列的日志接口，而logback是具体实现了的日志框架，和log4j一样，都是具体的实现层； The Simple Logging Facade for Java; Logback的优势：直接调用slf4j的接口，是不消耗内存和计算开销的。 log4j不是对slf4j的原生支持，所以slf4j api在调用log4j时需要一个适配层； Detail： 更快的执行速度； 充分的测试； Logback-classic 非常自然的实现了slf4j； 丰富的扩展文档； 可以使用XML配置文件或者Groovy； 自动重新载入配置文件； 优雅地从I/O错误中恢复； 自动清除旧的日志归档文件； 自动压缩归档日志文件； 滴滴面试复盘最近项目 QPS 降级 限流 redis hash扩容 跳表和红黑树 redis单线程 和多线程 TCP和HTTP Double和GRPC 消息队列 数据库 数据库引擎 间隙锁 B树和B+树 ZK 线上问题 多线程 sync 和 reentrantLock Wait 和 notifyall AQS 实现自己的锁 1月12号面试复盘： redis中list查询很慢，可能是什么原因？ 一方面有可能是大key导致的，写入的key比较大，redis在分配内存时就会比较耗时； 集中过期。这个就需要结合过期策略来讲； 使用了过度复杂的指令； 实例内存达到上限； Fork 耗时严重，开启了自动生成RDB和AOF重写功能； 绑定CPU（进程绑定CPU），为什么？redis在进行RDB和AOF时，会Fork子进程 开启AOF，因为这个功能会有刷盘机制，具体可参考Redis的AOF复制部分； 使用Swap，这个就需要我们最好内存和Swap的监控； 网卡负载过高，需要我们从运维层面，对机器的各项指标进行监控； 参考文档：https://cloud.tencent.com/developer/article/1683803 Spring中AOP用到了哪些设计模式？ 代理模式、AOP的增强或通知使用到了适配器模式； IOC容器中的存放context的名称是什么？ beanfactory和factorybean有什么不同？ 设计一个程序，统计一千万数据量的前10条记录，内存只有1G； mybatis中的#和$有什么区别？ shopLine面试复盘","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/助记码事故报告","date":"2021-10-19T05:24:15.203Z","updated":"2021-10-20T05:47:47.319Z","comments":true,"path":"2021/10/19/typora文件集合/事故/助记码事故报告/","link":"","permalink":"http://example.com/2021/10/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E5%8A%A9%E8%AE%B0%E7%A0%81%E4%BA%8B%E6%95%85%E6%8A%A5%E5%91%8A/","excerpt":"","text":"事故现象： 生鲜商品添加供应商超时； 批量分档报错； 事故定级：P4 事故责任人：孙彬 事故时间：2021-10-18 10左右 事故原因： 1. 第一个是因为助记码这个项目后端发布，前端没发，但是有其他人把沈洪杰的部分代码发上线了，导致生鲜商家添加供应商的时候，助记码那个字段的类型对不上，网关解析报错； 2. 事故二是因为之前的根据商品名称解析首字母拼音的时候，如果名称是以数字开头的，就直接返回null值，导致出现了NPE； 影响范围：商家编辑商品、批量分档； 排查过程： 1、2021-10-18 下午 10：16 产品（赵琼）说生鲜商家编辑商品，添加供应商报错，给了一个curl，开始排查； 2、2021-10-18 下午 11：36 开始和孙彬一起排查，发现是在添加供应商的时候，助记码那个字段前端送的类型不对，应该是个数组，前端传的是字符串； 3、2021-10-19 上午 00：20（凌晨） 开发（张帅）反馈批量分档报错，发现是解析数字开头的商品名称的拼音首字母时出现了NPE； 4、2021-10-19 上午 00：30 开发（夏振宇）修复了这个问题，并发到预发环境； 5、2021-10-19 上午 07: 34 前端（沈洪杰），把前端的完整代码发布上线； 6、2021-10-20 上午 10：21 开发（夏振宇）后端发布线上，问题修复； 后续Action： 后续要协调好发布时间； 然后我还想说一下，因为商品牵涉的域比较多，有时候一忙就忘记通知，所以大家最好都看下商品的发布群通知，一面双方都漏掉；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/DDD","date":"2021-10-18T07:39:20.093Z","updated":"2022-02-14T08:52:05.958Z","comments":true,"path":"2021/10/18/typora文件集合/拉钩/DDD/","link":"","permalink":"http://example.com/2021/10/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/DDD/","excerpt":"","text":"[TOC] DDD与微服务的关系各种域领域：限定业务边界和范围，然后在这个边界内解决业务问题； 子域：领域可以进一步划分为子领域，多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围； 核心域：决定产品和公司核心竞争力的子域是核心域； 通用域：没有太多个性化诉求，同时被多个子域使用的通用功能子域是通用域（权限、认证）； 支撑域：不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，就是支撑域； 商品的核心域：基础资料、商家商品、营业部商品；通用域：权限、认证；支撑域：品牌、类目、属性、BOM关系； 领域模型与服务微服务与模型什么是领域服务？当领域中的某个操作过程不是实体或值对象的职责时，此时我们便应该将该操作放在一个单独的接口中，即领域服务，然后它是无状态的。以下场景可以放到领域服务中： 执行一个显著的业务操作过程； 对领域对象进行转换； 以多个领域对象作为输入进行计算，结果产生一个值对象； Q：微服务的粒度？微服务如何拆分和设计？微服务的边界在哪里？ A：需要确定业务或者是微服务的边界。 DDD的核心：通过领域驱动设计方法定义领域模型，从而确定业务和应用边界，保证业务模型和代码模型的一致性。 Q：为什么DDD适合微服务？A：DDD是一种处理高度复杂领域的设计思想。它可以分离技术实现的复杂性，并围绕业务概念构建领域模型来控制业务的复杂性，以解决软件难以理解、难以演进的问题。DDD是一种架构设计方法论，它通过边界划分将业务领域简单化，以利于设计出清晰的领域和应用边界，可以很容易地实现架构的演进。 Q：如何划定领域模型和微服务的边界？A：第一步：在事件风暴中梳理业务过程中的==用户操作==、==事件以及外部依赖关系==，根据这些要素梳理出领域实体等领域对象；第二步：根据业务的关联性，将==业务紧密相关==的实体进行组合形成聚合，确定聚合中的==聚合根==、==值对象==和==实体==。所以说：这些聚合是在==同一个微服务实例==中运行；第三步：将一个或者多个聚合划定在一个界限上下文内，形成==领域模型==，用以划分微服务的边界，是物理隔离的。不同的界限上下文是在不同的微服务实例中运行的。界限上下文可以用来划分具体的领域边界。 PS：事件风暴：建立领域模型的主要方法。包括用例分析、场景分析、用户旅程分析，梳理领域对象之间的关系。建立实体、命令、事件 Q：DDD与微服务的关系？ A：DDD是一种架构设计方法，微服务是一种架构风格，两者都是为了追求高响应力，从业务视角去分离应用系统建设复杂度的手段； DDD主要关注：从业务领域视角划分领域边界，通过业务抽象，建立领域模型，维持业务和代码的逻辑一致性； 微服务主要关注：运行时的进程间通信、容错和故障隔离，实现去中心化数据管理和去中心化服务治理，关注的是开发、测试、构建、部署； 什么是界限上下文？用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。在这个边界内定义了==模型的适用范围==，使团队所有成员能够明确知道什么应该在模型中实现，什么不应该在模型中实现（本领域的职责，就比如商品中的销售商品、货品、主档等的关系。销售商品的界限上下文就可以理解为商家销售商品的领域边界，当然也可以理解为地点销售商品的子领域边界。货品的界限上下文也可以这么理解。这个东西划定了领域服务的边界）。 相爱相杀（聚合根-实体-值对象）实体和值对象是组成领域模型的基础单元。 什么是实体？A：实体是领域模型中的一个重要对象。领域模型中的实体是多个属性、操作或行为的载体。业务依存度高和业务关联紧密的多个实体对象和值对象进行聚合，形成聚合根。（类比商品，商家商品就是有商家商品基础信息+sku信息+图文描述信息等多个实体聚合而成的。它们对应的业务对象都是商家商品业务，相互之间有很强的依存关系。） 代码处理逻辑：在DDD中，这些实体类通常采用充血模型，与这个实体类相关的所有业务逻辑都在这个实体类中实现，跨多个实体类的领域逻辑在==领域服务==中实现。 Q：实体是怎么映射到数据库中的表的？都有哪些方式？ A：领域模型映射到数据模型，大多数情况下是一对一的，但是也会存在一对多、多对一等场景。举例：一对一：商家商品基础信息、sku信息等；一对多：权限实体对应用户user、角色role两个持久化对象；多对一：客户和账户两个实体对象有可能对应同一个数据持久化对象； 什么是值对象？这个是一个更为抽象的东西。通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体。在DDD中用来描述领域的特定方面，并且是一个没有标识符的对象，叫做值对象。值对象本质上就是一个集。是若干个用于描述目的、具有整体概念和不可修改的属性。在领域建模的过程中，值对象可以保证属性归类的清晰和概念的完整性，避免属性零碎。（就是一些列具有特殊语义的属性的集合，这些属性各自分开有可能比较的零碎，组合起来可能具有更为完整的概念。）值对象与实体一样，同样是从事件风暴中构建出来的。与实体对象的区别：值对象只有==数据初始化操作和有限的不涉及修改数据的行为==，基本不包含业务逻辑。（从业务实际上看，实体中的每一个属性都可以理解为是一个单一的属性值对象。只有多个属性集值对象的集合，我们可以把它们单独出来作为一个class来创建。这个可以类比商品图文实体中的图文描述字段–description，我们就可以把Description作为一个值对象来看待。对于一个description值对象而言，它是有几个属性的集合组成的，而且这个值对象是不需要用唯一的Id进行标识的）。 数据持久化设计？在领域建模的时候，我们可以将对象设计为值对象，保留对象的业务涵义，同时又减少了实体的数量；在数据建模时，我们可以将值对象嵌入实体，减少实体表的数量，简化数据库设计。（\u0010说白了就是作为领域对象，实体要和值对象分来，但是值对象是要有一个属性保存在实体中的，在数据库中，值对象是序列化为一个字段保存在实体对应的一个表中的）。 实体和值对象之间的关系？实体和值值对象是微服务底层的最基础的对象。实现了最核心的领域逻辑。 （具体的关系，可以参考前面的描述，简而言之，就是实体是有业务操作行为与逻辑的，而值对象只是一系列属性的集合，操作而言也大多是数据初始化与展示，没有复杂的修改）。 聚合与聚合根？聚合领域模型内的实体和值对象都是一个个体，是很基础的领域对象，实现了个体对应的业务操作。而能让实体和值对象协同工作的组织就是聚合，它用来确保这些领域对象在实现共同的业务逻辑的同时，能保证数据的一致性。是数据修改和持久化的基本单元。（白话，聚合定义了数据库事务操作的基本单元，比如操作商家商品的修改，这个大的事务中应该包含哪些操作呢？比如包括商家商品础信息的修改、图文的修改、sku的修改等，这些内容的修改需要在一个统一的事务中，确保是一个原子化的操作）。 高内聚和低耦合聚合在DDD分层架构中属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑。聚合内实体以充血模型实现个体业务能力，实体之间通过在领域服务中实现业务逻辑的高内聚。跨多个实体的业务逻辑通过领域服务来实现，跨多个聚合的业务逻辑通过应用服务（业务服务）来实现。（从上面的描述可以看出，聚合是一个动作，是对实体和对值对象的一种==组织==。） 聚合根如果把聚合比做组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅仅是实体，还是聚合的管理者——负责协调实体和值对象按照固定的业务规则协同完成共同的业务逻辑。==聚合之间，需要通过聚合根的ID来进行交互。== 如何设计聚合根？ 在一致性边界内建模真正的不变条件。（意思就是这个边界内的各个实体和值对象是按照统一的业务规则来运行的）； 设计小聚合。（一个聚合内不宜包含过多的实体和值对象）； 通过唯一的标识（ID）来引用其他的聚合。这样可以最大限度的降低聚合之间的耦合度； 在边界之外适用最终一致性；在一次事务中，只能修改一个聚合的状态。如果一次业务操作涉及多个聚合状态的修改，应该采用==领域事件==的方式异步修改相关的聚合，实现聚合之间的解耦（异步线程？MQ？）。 通过应用层实现跨聚合的服务调用。（\u0010在业务服务中调用各个聚合服务，也即领域服务）； 领域事件什么是领域事件？是一种架构风格或者是编程范式。解决了不同的聚合根之间的耦合的问题。在集合根完成更新操作以后会产生一个新的事件并广播出去，由其他订阅该事件的订阅者完成其他的聚合根的对应的操作。这样就实现了不同的聚合根之间的解耦。 领域事件怎么实现？ 建模。领域事件是一个对象，同样需要建模，定义它的数据结构。领域事件的名称的格式一般为产生这个事件的聚合根的名字+产生事件的动词的过去式。比如说MerchantItemCreated。 内部的数据结构。一般与产生它的聚合根的很相似。除此之外，还会多两个属性：事件的发生日期、事件的唯一编号。 处理时需要注意的几点： 领域事件是领域逻辑的一部分，所以在领域层不应该依赖某些底层的框架或是中间件， 事件的发送应该是异步非阻塞的，不应该阻塞当前处理的线程； 设计上避免事件链的产生，即一个事件被处理后又产生了另一个事件； 考虑最终一致性的解决方案，记录好日志，以及事件丢失的处理与排查方案； 框架的选择：可以选择使用Spring中的事件、订阅功能，或者是Guava中的EventBus； Q&amp;A DDD对微服务的改变？使用DDD以后，有什么好处呢？ 一方面是我们的开发由面向数据库设计改为面向领域驱动设计，这部分的好处可以参考上面的领域事件的实现；另一方面，由于领域模型的引入，导致我们出现了Facade-防腐层的出现，调用外域的接口会统一先转化为微服务内部的领域模型，然后再在内部进行流程处理。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/商品2.0接口梳理","date":"2021-10-18T02:21:09.716Z","updated":"2021-11-16T06:29:42.003Z","comments":true,"path":"2021/10/18/typora文件集合/商品2.0接口梳理/","link":"","permalink":"http://example.com/2021/10/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E5%95%86%E5%93%812.0%E6%8E%A5%E5%8F%A3%E6%A2%B3%E7%90%86/","excerpt":"","text":"自己负责的域履约： WMS： 仓店： 方法商品对价格的接口的依赖：priceRealTimeQueryServiceBlockingStub.queryPointTimePurchasePrice 60QPS～3000QPS 按照模型进行划分： 领域实体：价格：PriceInfoDTO 库存：InventoryDTO 销售范围： 供货范围：SupplyRelationDTO 规格： MerchantItemSKuDTO","categories":[],"tags":[]},{"title":"","slug":"ES","date":"2021-10-15T12:39:48.614Z","updated":"2022-03-12T16:06:53.395Z","comments":true,"path":"2021/10/15/ES/","link":"","permalink":"http://example.com/2021/10/15/ES/","excerpt":"","text":"[TOC] 正排索引与倒排索引ES的分片基本概念基本的存储单元是shard，一个index可能分为多个shard，每个shard可以分布在不同的机器上。然后一个shad是有多个Segment组成，每个Segment是一些倒排索引的集合。然后每次创建一个新的Document或更新一个Document，都会归属于一个新的Segment（同样会被记录到commit point里面），而不是去修改原来的Segment。每次文档的删除操作，会仅仅标记Segment中该文档为删除状态，而不是真正的立马删除。 几个重要的概念：Memory Buffer与Translog、commit point（记录着所有的segemnt信息，es在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片） 原因：每次commit操作意味着将Segment合并，并写入磁盘。但是这样做是很重的IO操作，所以为了提升机器性能和近实时搜索，新文档会被首先写入到内存Buffer和translog文件中，每个shard对应一个translog文件。translog的作用： 保证文件缓存中的文档不丢失； 系统重启时，从translog中年恢复； 新的segment收录到commit point中； ![ES Shard的组成部分](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES Shard的组成部分.png) *** write/refresh/flush过程*** ![ES write:refresh:flush总体流程图](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES write:refresh:flush总体流程图.png) write过程当写请求发送到es后，es将数据暂存写入memory buffer中，同时会写入到translog文件中；如下图：![ES write操作](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES write操作.png) refresh过程 将内存缓冲区的文档写入到新的Segment中，同时这个段被打开，使其可以被搜索到。这个时候Segment是存储在文件缓存系统中的。 内存缓冲区被清空，但translog没有被清空，是为了后面的flush操作； ![ES refresh操作](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES refresh操作.png) flush过程触发机制：translog变得越来越大、索引被刷新； 所有内存缓冲区的文档都会被写入一个新的段中； 缓冲区被清空； 一个提交点被写入硬盘（记录被flush到磁盘的段）； 文件系统缓存通过fsync被刷新到磁盘（flush）； 老的translog被删除； ![ES flush过程](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES flush过程.png) PS：当es重新启动的时候或索引重新打开的时候，他会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放translog中所有在最后一次提交后发生的变更操作。 merger过程 合并进程选择一小部分大小相似的段，并且在后台将他们合并到更大的段中。这并不会中断索引和搜索； 新的段被打开用来搜索； 老的段被删除； ![image-20211018065648999](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211018065648999.png) 常见问题排查高CPU场景 查看节点hot thread 12GET _nodes/hot_threadsGET _nodes/&lt;node_name&gt;/hot_threads 查看线程池 12GET _cat/thread_poolGET _cat/thread_pool/force_merge?v&amp;s=name 查看线程池使用的情况可快速定位当前集群线程池使用情况； 可查看具体节点的某个线程池的使用情况； 查看当前任务 123GET _cat/tasks?detailedGET _tasks?actions=*bulk&amp;detailedGET _tasks?actions=*search&amp;detailed 取消任务 1POST _tasks/&lt;taskId&gt;/_cancel 根据上一步拿到的任务id进行取消操作 查看索引的迁移进度 1GET _cat/recovery/&lt;index_name&gt;?v 高内存场景Es的高JVM内存压力可能是以下原因造成的： 集群的请求数量激增； 聚合、通配符以及在查询中选择了较宽的时间范围； 各节点间的分区分配不均衡或者一个集群中的分区太多； 字段数据或索引映射激增； 无法处理传入负载的实例类型； 查看缓存 123GET /_stats/query_cacheGET /_stats/fielddata_cacheGET /_stats/request_cache 清理缓存 1234POST /&lt;index_name&gt;/_cache/clearPOST /&lt;index_name&gt;/_cache/clear?fileddata=truePOST /&lt;index_name&gt;/_cache/clear?query=truePOST /&lt;index_name&gt;/_cache/clear?request=true 慢查询定位分页 分页方式 性能 优点 缺点 场景 from+size 低 灵活性好，实现简单 存在深度分页问题 数据量比较小，能容内深度分页的问题 Scroll 中 解决了深度分页问题 无法反映数据的实时性（快照版本），维护成本高，需要维护一个scroll_id 海量数据的导出 Search_after 高 性能最好，不存在深度分页问题，能够反映数据的实时性 实现比较复杂，每一次查询都需要上次查询的结果 海量数据的分页 集群规划 怎么规划？需要从以下两个方面考虑： 当前的数据量有多大？数据增长情况如何？ 机器规格，cpu、多大内存、多大硬盘容量？ es的JVM heap最大可以设置==32G==。如果机器的内存很大，可以考虑在一台机器上运行多个es节点实例。集群规划满足当前数据规模+适量增长规模即可，后续可按需扩展； 场景分析：A 对于业务搜索功能模块，且多是垂直领域的搜索。数据量级几千万到数十亿级别，一般是2-4台机器的规模。 B 大规模的OLAP，需要几十到几百的节点的规模。 节点角色ES节点有Master、DataNode（默认是数据节点）、Coordinate node三种。Coordinate Node: 协调节点，一个节点只接收请求、转发请求到其他节点、汇总各个节点返回数据等功能的节点。一个节点可以充当一个或者多个角色，默认三个都有。对于中大规模的集群，应当考虑角色分开。这样不会因为协调节点负载过高而影响数据节点的能力。 脑裂问题 6.x和之前版本： discovery.zen.minimum_master_nodes: (有master资格节点数/2) + 1 这个参数控制的是，选举主节点时需要看到最少多少个具有master资格的活节点，才能进行选举。官方 的推荐值是(N/2)+1，其中N是具有master资格的节点的数量。 7.x以后：集群自己控制，启动的一个新的集群的时候需要有cluster.inital_master_nodes初始化集群列表。 常用做法（中大规模集群）：： 12345671)Master 和 dataNode 角色分开，配置奇数个master，如3 2)单播发现机制，配置master资格节点(5.0之前): discovery.zen.ping.multicast.enabled: false —— 关闭多播发现机制，默认是关闭的 3)延长ping master的等待时长discovery.zen.ping_timeout: 30(默认值是3秒)——其他节点ping主节点多久时间没有响应就认为主节点不可用了。es7中换成了 discovery.request_peers_timeout 分片设置： ElasticSearch推荐的最大JVM堆空间是3032G, 所以把你的分片最大容量限制为30GB, 然后再对分片数量做合理估算. 例如, 你认为你的数据能达到200GB, 推荐你最多分配7到8个分片。在开始阶段, 一个好的方案是根据你的节点数量按照1.53倍的原则来创建分片. 例如,如果你有3个节点, 则推荐你创建的分片数最多不超过9(3x3)个。当性能下降时，增加节点，ES会平衡分片的放置。副本：为保证高可用性，副本数设置2即可。要求集群至少有3个节点，来分开存放主分片、副本。并发量大时，查询性能会下降，可增加副本数，来提升并发查询能力。 集群调优写: 首次向集群中灌入数据，可以将副本数设置为0，写入完再调整回去，这样副本分片只需要拷贝，节省了索引的过程； 1234PUT /&lt;index_name&gt;/_settings &#123;&quot;number_of_replicas&quot;: 0 &#125; 自动生成doc ID如果写入doc时指定了id，es会尝试读取原来的doc版本号，以判断是否需要更新。这回设计一次读取磁盘的操作。 设置合理的mapping 将不需要建立索引的字段index属性设置为not_analyzed或no； 减少字段内容长度； 使用不同的分词器； 调整_source字段 对analyzed的字段禁用norms; 调整索引的刷新间隔，如果对实时性要求不高的话； 批处理； Document的路由处理（设置合理的分片） ES默认的路由是根据id，也可以在发送请求时手动指定一个routing value，例如： 1PUT /index/doc/id?routing=user_id 读: 数据分组对数据进行基于天来建立索引，一个例子，日志系统； ID字段类型定义为keyword一般情况下，id字段不会被用作range类型搜索。keyword会被优化，以便进行terms查询。性能大约会提升30%。 限制用户的输入的条件；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/ES","date":"2021-10-15T12:39:48.614Z","updated":"2022-01-11T15:04:44.101Z","comments":true,"path":"2021/10/15/typora文件集合/拉钩/ES/","link":"","permalink":"http://example.com/2021/10/15/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/ES/","excerpt":"","text":"[TOC] 正排索引与倒排索引ES的分片基本概念基本的存储单元是shard，一个index可能分为多个shard，每个shard可以分布在不同的机器上。然后一个shad是有多个Segment组成，每个Segment是一些倒排索引的集合。然后每次创建一个新的Document或更新一个Document，都会归属于一个新的Segment（同样会被记录到commit point里面），而不是去修改原来的Segment。每次文档的删除操作，会仅仅标记Segment中该文档为删除状态，而不是真正的立马删除。 几个重要的概念：Memory Buffer与Translog、commit point（记录着所有的segemnt信息，es在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片） 原因：每次commit操作意味着将Segment合并，并写入磁盘。但是这样做是很重的IO操作，所以为了提升机器性能和近实时搜索，新文档会被首先写入到内存Buffer和translog文件中，每个shard对应一个translog文件。translog的作用： 保证文件缓存中的文档不丢失； 系统重启时，从translog中年恢复； 新的segment收录到commit point中； ![ES Shard的组成部分](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES Shard的组成部分.png) *** write/refresh/flush过程*** ![ES write:refresh:flush总体流程图](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES write:refresh:flush总体流程图.png) write过程当写请求发送到es后，es将数据暂存写入memory buffer中，同时会写入到translog文件中；如下图：![ES write操作](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES write操作.png) refresh过程 将内存缓冲区的文档写入到新的Segment中，同时这个段被打开，使其可以被搜索到。这个时候Segment是存储在文件缓存系统中的。 内存缓冲区被清空，但translog没有被清空，是为了后面的flush操作； ![ES refresh操作](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES refresh操作.png) flush过程触发机制：translog变得越来越大、索引被刷新； 所有内存缓冲区的文档都会被写入一个新的段中； 缓冲区被清空； 一个提交点被写入硬盘（记录被flush到磁盘的段）； 文件系统缓存通过fsync被刷新到磁盘（flush）； 老的translog被删除； ![ES flush过程](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/ES flush过程.png) PS：当es重新启动的时候或索引重新打开的时候，他会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放translog中所有在最后一次提交后发生的变更操作。 merger过程 合并进程选择一小部分大小相似的段，并且在后台将他们合并到更大的段中。这并不会中断索引和搜索； 新的段被打开用来搜索； 老的段被删除； ![image-20211018065648999](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20211018065648999.png) 常见问题排查高CPU场景 查看节点hot thread 12GET _nodes/hot_threadsGET _nodes/&lt;node_name&gt;/hot_threads 查看线程池 12GET _cat/thread_poolGET _cat/thread_pool/force_merge?v&amp;s=name 查看线程池使用的情况可快速定位当前集群线程池使用情况； 可查看具体节点的某个线程池的使用情况； 查看当前任务 123GET _cat/tasks?detailedGET _tasks?actions=*bulk&amp;detailedGET _tasks?actions=*search&amp;detailed 取消任务 1POST _tasks/&lt;taskId&gt;/_cancel 根据上一步拿到的任务id进行取消操作 查看索引的迁移进度 1GET _cat/recovery/&lt;index_name&gt;?v 高内存场景Es的高JVM内存压力可能是以下原因造成的： 集群的请求数量激增； 聚合、通配符以及在查询中选择了较宽的时间范围； 各节点间的分区分配不均衡或者一个集群中的分区太多； 字段数据或索引映射激增； 无法处理传入负载的实例类型； 查看缓存 123GET /_stats/query_cacheGET /_stats/fielddata_cacheGET /_stats/request_cache 清理缓存 1234POST /&lt;index_name&gt;/_cache/clearPOST /&lt;index_name&gt;/_cache/clear?fileddata=truePOST /&lt;index_name&gt;/_cache/clear?query=truePOST /&lt;index_name&gt;/_cache/clear?request=true 慢查询定位分页 分页方式 性能 优点 缺点 场景 from+size 低 灵活性好，实现简单 存在深度分页问题 数据量比较小，能容内深度分页的问题 Scroll 中 解决了深度分页问题 无法反映数据的实时性（快照版本），维护成本高，需要维护一个scroll_id 海量数据的导出 Search_after 高 性能最好，不存在深度分页问题，能够反映数据的实时性 实现比较复杂，每一次查询都需要上次查询的结果 海量数据的分页 集群规划 怎么规划？需要从以下两个方面考虑： 当前的数据量有多大？数据增长情况如何？ 机器规格，cpu、多大内存、多大硬盘容量？ es的JVM heap最大可以设置==32G==。如果机器的内存很大，可以考虑在一台机器上运行多个es节点实例。集群规划满足当前数据规模+适量增长规模即可，后续可按需扩展； 场景分析：A 对于业务搜索功能模块，且多是垂直领域的搜索。数据量级几千万到数十亿级别，一般是2-4台机器的规模。 B 大规模的OLAP，需要几十到几百的节点的规模。 节点角色ES节点有Master、DataNode（默认是数据节点）、Coordinate node三种。Coordinate Node: 协调节点，一个节点只接收请求、转发请求到其他节点、汇总各个节点返回数据等功能的节点。一个节点可以充当一个或者多个角色，默认三个都有。对于中大规模的集群，应当考虑角色分开。这样不会因为协调节点负载过高而影响数据节点的能力。 脑裂问题 6.x和之前版本： discovery.zen.minimum_master_nodes: (有master资格节点数/2) + 1 这个参数控制的是，选举主节点时需要看到最少多少个具有master资格的活节点，才能进行选举。官方 的推荐值是(N/2)+1，其中N是具有master资格的节点的数量。 7.x以后：集群自己控制，启动的一个新的集群的时候需要有cluster.inital_master_nodes初始化集群列表。 常用做法（中大规模集群）：： 12345671)Master 和 dataNode 角色分开，配置奇数个master，如3 2)单播发现机制，配置master资格节点(5.0之前): discovery.zen.ping.multicast.enabled: false —— 关闭多播发现机制，默认是关闭的 3)延长ping master的等待时长discovery.zen.ping_timeout: 30(默认值是3秒)——其他节点ping主节点多久时间没有响应就认为主节点不可用了。es7中换成了 discovery.request_peers_timeout 分片设置： ElasticSearch推荐的最大JVM堆空间是3032G, 所以把你的分片最大容量限制为30GB, 然后再对分片数量做合理估算. 例如, 你认为你的数据能达到200GB, 推荐你最多分配7到8个分片。在开始阶段, 一个好的方案是根据你的节点数量按照1.53倍的原则来创建分片. 例如,如果你有3个节点, 则推荐你创建的分片数最多不超过9(3x3)个。当性能下降时，增加节点，ES会平衡分片的放置。副本：为保证高可用性，副本数设置2即可。要求集群至少有3个节点，来分开存放主分片、副本。并发量大时，查询性能会下降，可增加副本数，来提升并发查询能力。 集群调优写: 首次向集群中灌入数据，可以将副本数设置为0，写入完再调整回去，这样副本分片只需要拷贝，节省了索引的过程； 1234PUT /&lt;index_name&gt;/_settings &#123;&quot;number_of_replicas&quot;: 0 &#125; 自动生成doc ID如果写入doc时指定了id，es会尝试读取原来的doc版本号，以判断是否需要更新。这回设计一次读取磁盘的操作。 设置合理的mapping 将不需要建立索引的字段index属性设置为not_analyzed或no； 减少字段内容长度； 使用不同的分词器； 调整_source字段 对analyzed的字段禁用norms; 调整索引的刷新间隔，如果对实时性要求不高的话； 批处理； Document的路由处理（设置合理的分片） ES默认的路由是根据id，也可以在发送请求时手动指定一个routing value，例如： 1PUT /index/doc/id?routing=user_id 读: 数据分组对数据进行基于天来建立索引，一个例子，日志系统； ID字段类型定义为keyword一般情况下，id字段不会被用作range类型搜索。keyword会被优化，以便进行terms查询。性能大约会提升30%。 限制用户的输入的条件；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/分享/mysql的存储引擎与索引结构","date":"2021-10-12T00:00:30.991Z","updated":"2022-02-24T01:44:39.878Z","comments":true,"path":"2021/10/12/typora文件集合/拉钩/分享/mysql的存储引擎与索引结构/","link":"","permalink":"http://example.com/2021/10/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%88%86%E4%BA%AB/mysql%E7%9A%84%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B8%8E%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84/","excerpt":"","text":"mysql的存储引擎与索引结构1、mysam和innodb2、哈希索引与b树索引3、各种索引的区别 MyISAM与InnoDB的区别哈希索引与B树索引各种索引的区别问题： like操作什么情况下走索引？ %在右边的时候是可以的。这个时候查询的类型为range； explain操作都需要关注哪些指标？ select_type:查询的类型；普通查询还是子查询等； type：存储引擎查询时采用的方式，可以看出是走全表扫描还是基于索引的部分扫描； possible_keys：可能使用到的索引； key：使用到的索引； rows：估算SQL要查询到结果需要扫描多少行记录； key_len：表示查询使用了索引的字节数量，可以判断是否全部使用了组合索引； Extra：其他的信息； MVCC在读已提交以及可重复读之间的实现的区别？读已提交是在每次读操作时创建一个一致性视图，而可重复读是事务开启时创建一致性视图。可重复读的关键点： 事务开启时创建一致性视图； 事务里如果不存在更新操作，则使用这个视图； 如果存在更新操作，则进行当前读（读取最新提交的数据）后更新； 更新操作后进行查询，会重新创建一致性事务（认可自己提交的数据）；","categories":[],"tags":[]},{"title":"","slug":"RPC","date":"2021-10-11T06:02:12.012Z","updated":"2021-11-08T05:26:40.891Z","comments":true,"path":"2021/10/11/RPC/","link":"","permalink":"http://example.com/2021/10/11/RPC/","excerpt":"","text":"[TOC] 了解rpc吗？RPC远程过程调用，借助RPC可以做到像本地调用一样调用远程服务，是一种进程间的通讯方式。 RPC的架构（组成部分）： 客户端（client），服务的调用方； 客户端存根（stub），存放服务端地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程调用发送给服务方； 服务端（server）：真正的服务提供者； 服务端存根（server stub）：解析客户端发送过来的数据包，调用本地方法；有哪些常见的rpc框架？ 如何自己设计一个rpc框架？ 服务注册与发现：注册中心只需要能存储服务信息即可，并且一定要保证高可用性；不要服务中心挂掉了，所有的服务都用不了了。常用的软件： zookeeper Etcd Consul Nacos（阿里的Nacos可以实现动态服务配置、服务发现、服务元数据以及流量管理等） 服务入口在Java中，远程调用，我们不可能把每个服务接口都暴露在外面，而是一个入口接受参数，再由这个入口分发到系统内部的某个服务，调用后返回结果。 序列化 grpc hession java自带的序列化 json/xml 负载均衡算法 轮训 随机 权重 最少连接 ip_hash Dubbo了解吗？Dubbo 提供了哪些负载均衡策略？ 基于hash一致性的ConsistentHashLoadBalance； 基于权重随机算法的RandomLoadBalance； 基于最少活跃调用算法的LeastActiveLoadBalance; 基于加权轮询算法的RoundRobinLoadBalance； 基于最短响应时间的ShortestResponseLoadBalance; 如何设计一个网关核心设计： 请求路由 服务注册 负责均衡 弹力设计： 增加异步、重试、幂等、流控、降级、熔断、监视等功能； 安全方面：权限控制、数据校验、SSL加密及证书管理 灰度发布：测试版本在某些服务器上进行发布； API聚合/API编排 重点： 高性能：使用异步非阻塞的通信框架Netty； 高可用：集群化设计，并且不同的节点之间需要同步数据； 服务化：提供一个Admin API来在运行时修改自己的配置； 高扩展性：网关或多或少会有一些业务逻辑，而业务是多变的，因此网关需要有扩展性； 运维方面： 业务送耦合、协议紧耦合； 应用监控，提供分析数据；分布式链路追踪 DevOps； 架构： 不要在网关中内置聚合后端服务的功能，采用plugin的方式； 网关应该靠近后端服务，并合后端服务使用同一个内网，这样可以保证通信的低延迟； 要支持容量扩展，所以需要成为一个集群来分担前端带来的流量； 服务发现可以有缓存； 校验用户请求：用户是否已经登陆，token验证； 监控，比如说检测异常访问； 谈谈对微服务的认识？网络http/http2","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/RPC","date":"2021-10-11T06:02:12.012Z","updated":"2021-11-08T05:26:40.891Z","comments":true,"path":"2021/10/11/typora文件集合/拉钩/RPC/","link":"","permalink":"http://example.com/2021/10/11/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/RPC/","excerpt":"","text":"[TOC] 了解rpc吗？RPC远程过程调用，借助RPC可以做到像本地调用一样调用远程服务，是一种进程间的通讯方式。 RPC的架构（组成部分）： 客户端（client），服务的调用方； 客户端存根（stub），存放服务端地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程调用发送给服务方； 服务端（server）：真正的服务提供者； 服务端存根（server stub）：解析客户端发送过来的数据包，调用本地方法；有哪些常见的rpc框架？ 如何自己设计一个rpc框架？ 服务注册与发现：注册中心只需要能存储服务信息即可，并且一定要保证高可用性；不要服务中心挂掉了，所有的服务都用不了了。常用的软件： zookeeper Etcd Consul Nacos（阿里的Nacos可以实现动态服务配置、服务发现、服务元数据以及流量管理等） 服务入口在Java中，远程调用，我们不可能把每个服务接口都暴露在外面，而是一个入口接受参数，再由这个入口分发到系统内部的某个服务，调用后返回结果。 序列化 grpc hession java自带的序列化 json/xml 负载均衡算法 轮训 随机 权重 最少连接 ip_hash Dubbo了解吗？Dubbo 提供了哪些负载均衡策略？ 基于hash一致性的ConsistentHashLoadBalance； 基于权重随机算法的RandomLoadBalance； 基于最少活跃调用算法的LeastActiveLoadBalance; 基于加权轮询算法的RoundRobinLoadBalance； 基于最短响应时间的ShortestResponseLoadBalance; 如何设计一个网关核心设计： 请求路由 服务注册 负责均衡 弹力设计： 增加异步、重试、幂等、流控、降级、熔断、监视等功能； 安全方面：权限控制、数据校验、SSL加密及证书管理 灰度发布：测试版本在某些服务器上进行发布； API聚合/API编排 重点： 高性能：使用异步非阻塞的通信框架Netty； 高可用：集群化设计，并且不同的节点之间需要同步数据； 服务化：提供一个Admin API来在运行时修改自己的配置； 高扩展性：网关或多或少会有一些业务逻辑，而业务是多变的，因此网关需要有扩展性； 运维方面： 业务送耦合、协议紧耦合； 应用监控，提供分析数据；分布式链路追踪 DevOps； 架构： 不要在网关中内置聚合后端服务的功能，采用plugin的方式； 网关应该靠近后端服务，并合后端服务使用同一个内网，这样可以保证通信的低延迟； 要支持容量扩展，所以需要成为一个集群来分担前端带来的流量； 服务发现可以有缓存； 校验用户请求：用户是否已经登陆，token验证； 监控，比如说检测异常访问； 谈谈对微服务的认识？网络http/http2","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/JVM/JVM","date":"2021-10-10T12:47:15.776Z","updated":"2022-02-14T01:48:28.661Z","comments":true,"path":"2021/10/10/typora文件集合/拉钩/JVM/JVM/","link":"","permalink":"http://example.com/2021/10/10/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/JVM/JVM/","excerpt":"","text":"[TOC] JVMJAVA 内存分布 区域 说明 是否线程共享 程序计数器 当前线程所执行的字节码的行号指示器（执行行数），用于CPU的线程切换定位上次执行的位置。 否 虚拟机栈 方法执行时的线程内存模型。每个方法被调用时，创建栈帧，用于存储方法元数据。 否 本地方法栈 用于执行本地方法（非Java方法），结构同上 否 堆 存放对象实例，常量池信息。涉及到内存的创建、回收。是GC操作的区域 是 方法区 类信息、常量、静态变量、运行时常量池 是 Java有个共享内存，存放了每个变量的值，但是每个线程也有自己的工作内存区域。每个线程对变量的读写都会事先加载到自己的工作内存，然后进行修改，再同步到共享内存。MESI协议； 垃圾收集器相关 2.1 有多少种垃圾回收器，他们的区别是什么？Serial收集器、ParNew收集器、Parallel Scavenge收集器、CMS收集器、G1收集器 2.2 CMS和G1的区别？ 类加载机制 都有哪些类加载器？自定义类加载器、bootStrap类加载器、extention加载器、app类加载器, 每个加载器的意思要能说出来。 双亲委派机制：思想是什么，要能说出来； SPI机制，是基于接口编程+策略模式+配置文件的一种动态加载机制，用到了ServiceLoader这个类进行动态装载。是java提供的一种启动框架和替换组件，用来被第三方实现或扩展的API； 类初始化过程3.1 加载class文件。从jar包或者war包中加载class文件到jvm中去；4.2 校验，对加载的class文件进行校验，看起是否符合字节码规范，这一步在整个初始化过程中占了很长的时间； 3.3 准备，给对应的类变量分配内存并初始化默认值。由于这个阶段，对象还没有分配内存，所以是在方法区中进行的。3.3 解析。把符号引用变为直接引用；包括类的解析、接口的解析、字段的解析、方法的解析；最终是构成一个可以相互引用的网络；3.4 初始化。对于成员变量的初始化操作。 JVM 内存模型相关4.1 JVM的组成部分有哪些？ 线程共享的： 堆；局部变量的引用以及方法中的基础数据类型，在栈上直接分配，其他情况（成员变量），常量池在堆上分配； 元空间区：可以解决之前JDK 8之前的永久带容易造成OOM的问题； 永久代是方法区的一个实现，之前是放置在堆中的，受限于堆的大小，也是会发生OOM的。 方法区：存放的是类信息、静态变量、编辑器生成的代码； 线程独占的： 栈，先进后出的数据结构，本地方法栈、java虚拟机栈。栈的结构：栈帧（局部变量表、操作数栈、动态链接、返回地址）； 程序计数器 ：字节码的行号指示器。作用，存放的是线程执行到方法的哪一行了，可以在线程切换的时候，快速的定位到具体的代码位置； 常量池结构： 参考博文：https://juejin.cn/post/6854573216824819719 直接内存： NIO类，引入了channel与buffer，它可以直接使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。避免了Java和Native堆之间来回复制。 4.2 JVM怎么划分分代的？ 4.3 什么是OOM怎么排查呢？出现OOM的8种情况 https://zhuanlan.zhihu.com/p/192839736 8种常见的OOM以及解决办法？ 堆溢出java.lang.OutOfMemoryError: Java heap space 原因：1、代码中可能存在大对象分配2、 可能存在内存泄漏，导致在多次GC以后，还是无法找到足够大的内存容纳当前对象； 解决办法：1、 检查是否存在大对象的分配，尤其是数组；2、通过jmap命令，把对内存dump下来，使用mat工具分析一下，是否存在内存泄漏；3、 使用-Xmx加大堆内存4、慎用Finalizable对象； 永久代/元空间溢出java.lang.OutOfMemoryError: PermGen spacejava.lang.OutOfMemoryError: Metaspace 原因：1、jdk7以前，由于存在永久代，频繁使用String.intern()方法，这个版本的字符串常量池在永久代中2、运行期间生成了大量的代理类，导致方法区被撑爆，无法卸载； 解决办法：jdk7以前，检查是否是永久代或者元空间设置的过小；2、代码中是否存在大量的反射操作；3、dump之后通过mat检查是否有很多的代理类； GC overhead limit exceededjava.lang.OutOfMemoryError：GC overhead limit exceeded 原因：堆太小导致的。解决办法：1、 代码中是否有死循环或有使用大内存的代码，优化代码；2、禁用 -XX: -UseGCOverheadLimit这个检查；3、dump内存，看看是否有内存泄漏； 方法栈溢出java.lang.OutOfMemoryError : unable to create new native Thread原因：创建了大量的线程；解决办法：1、通过-Xss降低每个线程栈的容量2、限制线程的总数； 分配超大数组：java.lang.OutOfMemoryError: Requested array size exceeds VM limit原因：数组太大；解决办法：检查代码中是否有超大数组创建的地方； swap溢出java.lang.OutOfMemoryError: Out of swap space原因：swap分区不足、其他进程消耗了所有的内存；解决办法：1、 把其他服务拆分出去2、 加大swap区大小，或者增加机器内存大小； 本地方法栈溢出java.lang.OutOfMemoryError: Out of swap space原因：本地方法在运行时出现了内存分配失败。注意本地方法栈溢出发生在JNI和本地方法处； 什么是内存泄露？内存泄漏是指无用对象（不再使用的对象）持续占有内存或无用对象的内存得不到及时释放，从而造成内存空间的浪费称为内存泄漏。内存泄漏会导致内存溢出。 原因：根本原因是长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄漏。常见的几个现象： 静态集合类引起内存泄漏。 这些静态变量的生命周期和应用程序一致（因为他们存放在方法区中）。 监听器对象对监听器监听，对象释放，监听器没有被删除。 各种连接数据库连接（datasource.getConnection()）、网络连接、io连接等；这些除非显示的调用其close()方法将其关闭，否则gc不会自动回收（gc只管理内存，各种连接、文件流、网络连接都是物理资源，需要用户手动关闭） 内部类和外部模块（方法）的引用外部模块的引用，指的是对象作为参数进行了传递。 单例模式单例模式在初始化后将在JVM的整个生命周期中存在（以静态变量的方式）。所以说在单例对象中不要引用其他对象。 怎么避免内存泄漏？ 良好的编码习惯这个就是要从上面引起内存泄漏的几个原因入手； 测试工具使用专业的工具，进行监控。JProfiler 特别注意HashMap、ArrayList的集合对象 注意监听事件和回调函数。 Java的对象头里面都有什么东西？ MarkWord和KclassPointer（指向类信息的指针，类信息存放在方法区中）。 Java对象的组成对象头、实例变量、填充数据 字节码文件问题1.元空间垃圾收集要满足那些条件2.MESI的一致性协议，JMM的8大原子操作步骤3.JVM优化思路，大促销的内存分配思路。 博文引用 对于操作数栈的介绍 Java内存泄漏","categories":[],"tags":[]},{"title":"","slug":"常见问题","date":"2021-10-09T04:25:17.645Z","updated":"2022-02-22T01:37:26.269Z","comments":true,"path":"2021/10/09/常见问题/","link":"","permalink":"http://example.com/2021/10/09/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"[TOC] 为什么需要网关？ 什么是服务网关？服务网关=路由转发+ 过滤器；路由转发：将外界请求，转发到后端的微服务上，这里面包含了负载均衡；过滤器：增加一系列的横切功能，例如权限校验、限流、以及监控，API日志统一收集； 为什么需要服务网关？将一系列的横切功能写在网关中，后端服务无须关注这些功能点，也不需要引入多余的jar包；如果想修改权限校验的逻辑等，只需要在网关中进行修改，而不需要升级所有已存在的微服务； 流程 网关、其他微服务启动时注册到注册中心上去； 用户直接请求网关，网关做智能路由转发； 微服务把结果返回给网关，网关再返回给用户； 注意点： 增加了网关，相当于多了一层转发，性能会下降一些（通常不大，网关机器很好，而且是和其他系统是在内网）； 网关的单点问题：建议将网关部署在一台性能非常好的机器上。 哪些常见的网关系统？ spring cloud gateway ZUUL KONG 限流的算法有哪些？固定窗口计数器、滑动窗口计数器、漏桶算法、令牌桶算法 为什么需要分布式id？ 随着数据量的增大，单表已经不能支撑数据的存储查询，需要进行分库分表，由于不同的表生成的id会有重复，就需要一个分布式id来生成器来生成全局的唯一的id。 分布式id生成策略有哪些？数据库自增主键id：优点：实现起来比较简单，id有序递增，存储空间消耗小；缺点： 支持的并发量不大，存在数据库单点问题，id没有具体的业务含义，安全问题（可推算出订单量）、每次都需要访问数据库（可通过提前生成一批id放到内存队列中解决）。 数据库号段模式：一个业务类型只需要表中的一行记录就可以了。 12345678CREATE TABLE `sequence_id_generator` ( `id` int(10) NOT NULL, `current_max_id` bigint(20) NOT NULL COMMENT &#x27;当前最大id&#x27;, `step` int(10) NOT NULL COMMENT &#x27;号段的长度&#x27;, `version` int(20) NOT NULL COMMENT &#x27;版本号&#x27;, `biz_type` int(20) NOT NULL COMMENT &#x27;业务类型&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; current_max_id 字段和step字段主要用于获取批量 ID，获取的批量 id 为： current_max_id ~ current_max_id+step。version 字段主要用于解决并发问题（乐观锁）,biz_type 主要用于表示业余类型。提前获取的current_max_id会在代码中有一个变量进行存储，一般是Automic类型的，获取的时候是对这个变量进行自增获取； 优点：id有序自增，存储消耗空间小；缺点：，存在数据库单点问题，id没有具体的业务含义，安全问题（可推算出订单量） NoSQL：Redis 的 incr 命令即可实现对 id 原子顺序递增。 优点： 性能不错，id有序缺点：同数据库自增主键方式类似； UUID优点：生成速度快，简单易用缺点：消耗空间大，不安全（MAC地址）、没有具体的业务含义，需要解决重复id的问题（时钟回拨）。 snowflake优点：生成速度比较快，生成的id有序递增，比较灵活（可以对算法改造加入业务id）缺点：需要解决重复id的问题（依赖时间，时钟回拨问题）。 Leaf提供了snowflake算法，同时还提供了数据库双号段的模式。双号段：一个号段还没有使用完之前，主动获取下一个号段。 怎么设计一个限流器？答：见分布式 怎么设计一个分布式ID生成器？答：参考数据库号段模式； 常用的序列化协议有哪些？dubbo的序列化协议是什么？答：grpc、hession、java自带的序列化、json/xml JVM优化做过吗？二阶段、三阶段提交要能说出来？答：见分布式 如何实现分布式锁？Redisson的使用？ MQ的作用，设计MQ，如何解决MQ与事务的关系？ Java中的句柄？ ES中的倒排索引与正排索引Es中的主从分片机制以及一个索引是怎么路由到具体的分片的？计数器如何实现？可以看下之前写的代码 分库分表系统的扩容实现？ES的写入/读取流程Redis的数据结构MySQL的MVCC","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/常见问题","date":"2021-10-09T04:25:17.645Z","updated":"2022-02-22T01:37:26.269Z","comments":true,"path":"2021/10/09/typora文件集合/拉钩/常见问题/","link":"","permalink":"http://example.com/2021/10/09/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"[TOC] 为什么需要网关？ 什么是服务网关？服务网关=路由转发+ 过滤器；路由转发：将外界请求，转发到后端的微服务上，这里面包含了负载均衡；过滤器：增加一系列的横切功能，例如权限校验、限流、以及监控，API日志统一收集； 为什么需要服务网关？将一系列的横切功能写在网关中，后端服务无须关注这些功能点，也不需要引入多余的jar包；如果想修改权限校验的逻辑等，只需要在网关中进行修改，而不需要升级所有已存在的微服务； 流程 网关、其他微服务启动时注册到注册中心上去； 用户直接请求网关，网关做智能路由转发； 微服务把结果返回给网关，网关再返回给用户； 注意点： 增加了网关，相当于多了一层转发，性能会下降一些（通常不大，网关机器很好，而且是和其他系统是在内网）； 网关的单点问题：建议将网关部署在一台性能非常好的机器上。 哪些常见的网关系统？ spring cloud gateway ZUUL KONG 限流的算法有哪些？固定窗口计数器、滑动窗口计数器、漏桶算法、令牌桶算法 为什么需要分布式id？ 随着数据量的增大，单表已经不能支撑数据的存储查询，需要进行分库分表，由于不同的表生成的id会有重复，就需要一个分布式id来生成器来生成全局的唯一的id。 分布式id生成策略有哪些？数据库自增主键id：优点：实现起来比较简单，id有序递增，存储空间消耗小；缺点： 支持的并发量不大，存在数据库单点问题，id没有具体的业务含义，安全问题（可推算出订单量）、每次都需要访问数据库（可通过提前生成一批id放到内存队列中解决）。 数据库号段模式：一个业务类型只需要表中的一行记录就可以了。 12345678CREATE TABLE `sequence_id_generator` ( `id` int(10) NOT NULL, `current_max_id` bigint(20) NOT NULL COMMENT &#x27;当前最大id&#x27;, `step` int(10) NOT NULL COMMENT &#x27;号段的长度&#x27;, `version` int(20) NOT NULL COMMENT &#x27;版本号&#x27;, `biz_type` int(20) NOT NULL COMMENT &#x27;业务类型&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; current_max_id 字段和step字段主要用于获取批量 ID，获取的批量 id 为： current_max_id ~ current_max_id+step。version 字段主要用于解决并发问题（乐观锁）,biz_type 主要用于表示业余类型。提前获取的current_max_id会在代码中有一个变量进行存储，一般是Automic类型的，获取的时候是对这个变量进行自增获取； 优点：id有序自增，存储消耗空间小；缺点：，存在数据库单点问题，id没有具体的业务含义，安全问题（可推算出订单量） NoSQL：Redis 的 incr 命令即可实现对 id 原子顺序递增。 优点： 性能不错，id有序缺点：同数据库自增主键方式类似； UUID优点：生成速度快，简单易用缺点：消耗空间大，不安全（MAC地址）、没有具体的业务含义，需要解决重复id的问题（时钟回拨）。 snowflake优点：生成速度比较快，生成的id有序递增，比较灵活（可以对算法改造加入业务id）缺点：需要解决重复id的问题（依赖时间，时钟回拨问题）。 Leaf提供了snowflake算法，同时还提供了数据库双号段的模式。双号段：一个号段还没有使用完之前，主动获取下一个号段。 怎么设计一个限流器？答：见分布式 怎么设计一个分布式ID生成器？答：参考数据库号段模式； 常用的序列化协议有哪些？dubbo的序列化协议是什么？答：grpc、hession、java自带的序列化、json/xml JVM优化做过吗？二阶段、三阶段提交要能说出来？答：见分布式 如何实现分布式锁？Redisson的使用？ MQ的作用，设计MQ，如何解决MQ与事务的关系？ Java中的句柄？ ES中的倒排索引与正排索引Es中的主从分片机制以及一个索引是怎么路由到具体的分片的？计数器如何实现？可以看下之前写的代码 分库分表系统的扩容实现？ES的写入/读取流程Redis的数据结构MySQL的MVCC","categories":[],"tags":[]},{"title":"","slug":"复盘","date":"2021-10-08T22:36:38.800Z","updated":"2022-02-22T01:33:30.992Z","comments":true,"path":"2021/10/09/复盘/","link":"","permalink":"http://example.com/2021/10/09/%E5%A4%8D%E7%9B%98/","excerpt":"","text":"上次技术摸底问道的问题： 怎么解决超卖问题？见 高并发下库存扣减问题解决方法 ThredLocal的结构？见多线程 商品的DDD模型 项目的介绍抓不住重点 阿里： 类加载器理解的不是很深？JVM是否会存在两个全限定名一样的类？是可以的，但是是有不同的类加载器加载的；参考的博客： 怎么解决线程的隔离问题； 得物： 二级缓存怎么设计？怎么保证一级缓存和二级缓存的一致性； 消息表怎么处理？ 微盟： 怎么解决分库分表导致的数据倾斜的问题？ 数据倾斜问题","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/复盘","date":"2021-10-08T22:36:38.800Z","updated":"2022-02-22T01:33:30.992Z","comments":true,"path":"2021/10/09/typora文件集合/拉钩/复盘/","link":"","permalink":"http://example.com/2021/10/09/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%8D%E7%9B%98/","excerpt":"","text":"上次技术摸底问道的问题： 怎么解决超卖问题？见 高并发下库存扣减问题解决方法 ThredLocal的结构？见多线程 商品的DDD模型 项目的介绍抓不住重点 阿里： 类加载器理解的不是很深？JVM是否会存在两个全限定名一样的类？是可以的，但是是有不同的类加载器加载的；参考的博客： 怎么解决线程的隔离问题； 得物： 二级缓存怎么设计？怎么保证一级缓存和二级缓存的一致性； 消息表怎么处理？ 微盟： 怎么解决分库分表导致的数据倾斜的问题？ 数据倾斜问题","categories":[],"tags":[]},{"title":"","slug":"项目","date":"2021-10-07T23:42:28.486Z","updated":"2021-10-23T11:10:23.674Z","comments":true,"path":"2021/10/08/项目/","link":"","permalink":"http://example.com/2021/10/08/%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"[TOC] 项目介绍一、总结商品项目的历次迭代 第一代 第二代 第三代 商品的领域模型是什么样子的？ 基数数据product（品牌、类目、属性、价签模版）+ 销售商品（item）（merchant_item） +供应领货品(goods) (merchant_goods) 每次迭代解决了什么问题？优点是什么？做的不好的地方是哪里？怎么解决不好的地方？ 二、说一个自己做的比较满意的项目（titan）要能知道自己这个项目不足的地方，怎么改进？ ypsx-titan 。这个项目是负责接受数据库的bing然后 同步数据到es的。 三、作为小组负责人，怎么担好这个职责？自研ERP项目项目的起因&amp;项目的背景？公司目前有两套ERP系统和一套自研中台，用以支持谊品生鲜和到家业务，其中ERP承载了： 供应链（采购、库存）业务； 总部经营管理（供应商、商品类、机构类基础数据管理和经营报表） 门店销售及经营报表 财务业务（富集） 但是，2套ERP存在下面的问题： 2套商品主数据、2套模型，通过中台商品映射erp商品编码完成；但是缺少有效的校验，导致毛利错误、仓库作业困难； 两套ERP未对谊品生鲜、到家业务进行隔离，无法相互兼容，影响业务深度展开； 业务需求响应慢，无法及时满足业务需求； 深度定制费用高； 涉及的工程：ypshop项目（门店端）、ypsx-matrix、ypsx-titan、 涉及的表： 达成了什么目标？重新设计了谊品自己的商品模型，其中包括基础资料（主档），完成了主档的创建、修改以及分档创建商家商品、地点商品，另外增加了对于生鲜商品的支持：PLU码的管理、价签模版管理、BOM物料管理、生鲜品调价、商品生命周期管理等功能。通过这些功能，可以实现自主商品建档、分档，商品售价/进价管理、商品生命周期管理、支持多形态商品销售（BOM）等，打通了主档、货品、销售商品的创建、维护，可以有效的支持谊品自己的进销存结（进货、销售、库存、结算）核心业务； 遇到了哪些困难？怎么克服的？最终取得了什么样的结果？ 为了更好的支持商品的创建，我们对部分商品的表进行了分库分表的设计，根据门店id和商品的编码； 各个业务的查询逻辑复杂，不能做到和模型相对应，对此，增加了多个ES索引，用以支持不同场景的查询； 针对上传、下载的场景比较多，比较消耗系统资源，开发出了独立的人task模块； 针对分库分表主键id需要全局唯一的问题，引入了分布式id的生成；（具体参考分布式id的生成）； 自己承担了什么职责？核心能力技术方案的输出与开发，包括分档、调价、BOM管理、ES等模块；协调商品接口与外域的联调等。对技术难点进行攻关与测试，以及项目的开发排期。收获： 对谊品的业务模式，尤其是生鲜中涉及的业务场景有了更加深入的了解； 增加了系统设计的能力，认识到技术方案的设计需要结合业务场景来看（可以举下调价单中sg_price_modify_docs这个索引设计中遇到的坑）； 大型项目中团队协作开发经验，系统之间的联调、沟通能力的都增强； 架构图（可以看下面试的时候）：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/项目","date":"2021-10-07T23:42:28.486Z","updated":"2021-10-23T11:10:23.674Z","comments":true,"path":"2021/10/08/typora文件集合/拉钩/项目/","link":"","permalink":"http://example.com/2021/10/08/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"[TOC] 项目介绍一、总结商品项目的历次迭代 第一代 第二代 第三代 商品的领域模型是什么样子的？ 基数数据product（品牌、类目、属性、价签模版）+ 销售商品（item）（merchant_item） +供应领货品(goods) (merchant_goods) 每次迭代解决了什么问题？优点是什么？做的不好的地方是哪里？怎么解决不好的地方？ 二、说一个自己做的比较满意的项目（titan）要能知道自己这个项目不足的地方，怎么改进？ ypsx-titan 。这个项目是负责接受数据库的bing然后 同步数据到es的。 三、作为小组负责人，怎么担好这个职责？自研ERP项目项目的起因&amp;项目的背景？公司目前有两套ERP系统和一套自研中台，用以支持谊品生鲜和到家业务，其中ERP承载了： 供应链（采购、库存）业务； 总部经营管理（供应商、商品类、机构类基础数据管理和经营报表） 门店销售及经营报表 财务业务（富集） 但是，2套ERP存在下面的问题： 2套商品主数据、2套模型，通过中台商品映射erp商品编码完成；但是缺少有效的校验，导致毛利错误、仓库作业困难； 两套ERP未对谊品生鲜、到家业务进行隔离，无法相互兼容，影响业务深度展开； 业务需求响应慢，无法及时满足业务需求； 深度定制费用高； 涉及的工程：ypshop项目（门店端）、ypsx-matrix、ypsx-titan、 涉及的表： 达成了什么目标？重新设计了谊品自己的商品模型，其中包括基础资料（主档），完成了主档的创建、修改以及分档创建商家商品、地点商品，另外增加了对于生鲜商品的支持：PLU码的管理、价签模版管理、BOM物料管理、生鲜品调价、商品生命周期管理等功能。通过这些功能，可以实现自主商品建档、分档，商品售价/进价管理、商品生命周期管理、支持多形态商品销售（BOM）等，打通了主档、货品、销售商品的创建、维护，可以有效的支持谊品自己的进销存结（进货、销售、库存、结算）核心业务； 遇到了哪些困难？怎么克服的？最终取得了什么样的结果？ 为了更好的支持商品的创建，我们对部分商品的表进行了分库分表的设计，根据门店id和商品的编码； 各个业务的查询逻辑复杂，不能做到和模型相对应，对此，增加了多个ES索引，用以支持不同场景的查询； 针对上传、下载的场景比较多，比较消耗系统资源，开发出了独立的人task模块； 针对分库分表主键id需要全局唯一的问题，引入了分布式id的生成；（具体参考分布式id的生成）； 自己承担了什么职责？核心能力技术方案的输出与开发，包括分档、调价、BOM管理、ES等模块；协调商品接口与外域的联调等。对技术难点进行攻关与测试，以及项目的开发排期。收获： 对谊品的业务模式，尤其是生鲜中涉及的业务场景有了更加深入的了解； 增加了系统设计的能力，认识到技术方案的设计需要结合业务场景来看（可以举下调价单中sg_price_modify_docs这个索引设计中遇到的坑）； 大型项目中团队协作开发经验，系统之间的联调、沟通能力的都增强； 架构图（可以看下面试的时候）：","categories":[],"tags":[]},{"title":"","slug":"高并发下库存扣减问题解决方法","date":"2021-10-07T04:36:14.245Z","updated":"2021-10-23T09:13:52.033Z","comments":true,"path":"2021/10/07/高并发下库存扣减问题解决方法/","link":"","permalink":"http://example.com/2021/10/07/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E5%BA%93%E5%AD%98%E6%89%A3%E5%87%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"[TOC] 库存扣减问题常见的库存扣减模式： 下单扣减库存（谊品模式）：优点：实时扣减库存，避免付款时因库存不足支付失败的问题； 缺点：恶意买家大量下单，讲库存用完，但是不付款，就会导致真正想买的人买不了。 支付扣减库存优点：防止恶意买家大量下单 缺点：容易出现下单数超过库存数，若支付的订单超过了库存数，则会出现支付失败。怎么解决呢？可以对商品增加备用库存，如果商品库存用完，还有用户支付，则直接扣减备用库存。 预扣库存：下单页面显示最新的库存，实时减库存，下单后保留这个库存一段时间，超过保留时间后， 库存释放。若超过保留时间内后再支付，如果没有库存，则失败！ 优点：兼容下单减库存的优点，且缓解了恶意买家大量下单的问题，保留支付时间内没有支付，则释放库存；缺点：保留时间内，恶意买家如果大量下单讲库存用完，并发量很高的时候，仍然会出现下单数超过库存数。 高并发下的库存扣减问题？UPDATE [库存表] SET 库存数 - 1 WHERE 库存数 - 1 &gt; 0 如果影响条数大于1，则表示扣减库存成功，否则扣减失败 如何解决秒杀场景下的库存扣减？ 采用下单扣减库存 Redis缓存将缓存存放在缓存中，直接在缓存中扣减库存。并发很高的时候，采用分布式锁。 限流增加限流之后（前端的限流和后端的令牌桶限流），真正扣减库存的时候，请求量比较少了。 谊品的库存模型参考文件：秒杀 如何设计秒杀系统","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/高并发下库存扣减问题解决方法","date":"2021-10-07T04:36:14.245Z","updated":"2021-10-23T09:13:52.033Z","comments":true,"path":"2021/10/07/typora文件集合/拉钩/高并发下库存扣减问题解决方法/","link":"","permalink":"http://example.com/2021/10/07/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E5%BA%93%E5%AD%98%E6%89%A3%E5%87%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"[TOC] 库存扣减问题常见的库存扣减模式： 下单扣减库存（谊品模式）：优点：实时扣减库存，避免付款时因库存不足支付失败的问题； 缺点：恶意买家大量下单，讲库存用完，但是不付款，就会导致真正想买的人买不了。 支付扣减库存优点：防止恶意买家大量下单 缺点：容易出现下单数超过库存数，若支付的订单超过了库存数，则会出现支付失败。怎么解决呢？可以对商品增加备用库存，如果商品库存用完，还有用户支付，则直接扣减备用库存。 预扣库存：下单页面显示最新的库存，实时减库存，下单后保留这个库存一段时间，超过保留时间后， 库存释放。若超过保留时间内后再支付，如果没有库存，则失败！ 优点：兼容下单减库存的优点，且缓解了恶意买家大量下单的问题，保留支付时间内没有支付，则释放库存；缺点：保留时间内，恶意买家如果大量下单讲库存用完，并发量很高的时候，仍然会出现下单数超过库存数。 高并发下的库存扣减问题？UPDATE [库存表] SET 库存数 - 1 WHERE 库存数 - 1 &gt; 0 如果影响条数大于1，则表示扣减库存成功，否则扣减失败 如何解决秒杀场景下的库存扣减？ 采用下单扣减库存 Redis缓存将缓存存放在缓存中，直接在缓存中扣减库存。并发很高的时候，采用分布式锁。 限流增加限流之后（前端的限流和后端的令牌桶限流），真正扣减库存的时候，请求量比较少了。 谊品的库存模型参考文件：秒杀 如何设计秒杀系统","categories":[],"tags":[]},{"title":"","slug":"分布式","date":"2021-10-05T21:43:12.778Z","updated":"2022-01-12T06:59:07.949Z","comments":true,"path":"2021/10/06/分布式/","link":"","permalink":"http://example.com/2021/10/06/%E5%88%86%E5%B8%83%E5%BC%8F/","excerpt":"","text":"[TOC] 分布式特性： 分布性，机器分布在不同的机房、城市、国家； 对等性：没有主从之分，所有节点都是对等的； 并发性：不同的节点可能会并发的访问相同的资源，如数据库； 缺乏全局时钟：很难定义两件事情的发生的先后顺序； 故障总会发生； 单点故障：如果一个服务只有一台机器提供服务，在这台机器上发上的故障就叫做单点故障； 面临的问题： 通信问题：不可避免的会发生通信故障； 数据一致性：备份数据和主数据不同步； 网络分区：也是由于网络不通导致的； 节点故障： 三态：成功、失败、超时； 重发：出现失败和超时，就需要重新发送； 幂等：多次请求，结果保持一致； CAP 一致性所有节点访问都是同一份最新的数据副本；一致性分类：1. 强一致性； 2. 弱一致性； 3. 最终一致性（弱一致性的一种）。 ![分布式系统一致性分类](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/分布式系统一致性分类.png) 可用性每次请求都能获取到不错的响应，但是不能保证获取的数据为最新的数据； 分区容错性分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障； CAP三者不能同时满足的论证AP满足的情况下，两个节点之间因为网路等原因断开了链接，就会导致不同的节点数据是不一致的。 BASE 基本可用假设系统出现了不可预知的故障，但是还可以使用。 软状态允许系统中的数据存在中间状态，并认为该状态不会影响系统的整体可用性。即允许系统在多个不同节点的数据副本存在数据延时； 最终一致性系统不可能是一直是软状态的，必须有个时间限制。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。 这个期限取决于网络延时、系统负载、数据复制方案设计等因素； 6种常见的分布式解决方案TCC补偿事务；-业务层面的分布式事务 Try- Confirm - Cancel Try： 预留，即资源的预留和锁定，注意的是预留； Confirm： 确认操作，这一步就是真正的执行了； Cancel： 撤销操作，可以理解为把预留阶段的动作撤销了； TCC有个事务管理者的角色，用来记录TCC全局事务状态并提交或者回滚事务； 缺点： 对于业务上的每个操作，都需要定义三个动作，分别对应Try-Confirm-Cancel。 对于业务的侵入较大和业务紧耦合，需要根据特定的场景和业务逻辑来设计相应的操作； 另外，撤销和确认操作的执行可能需要重试，因此需要保证幂等； 优点：可以跨数据库、跨不同的业务系统来实现事务； 本地消息表（异步确保）利用了各系统本地事务来实现分布式事务。将业务的执行和将消息放入消息表中的操作放在同一个事务中，这样就能保证消息放入本地消息表中的时候业务肯定是执行成功的。然后调用下一个操作，如果成功了，消息表的状态可以直接改为已成功；失败的话，定时任务定时读取本地消息表，筛选出还未成功的消息再调用对应的服务，服务更新成功了再变更消息的状态；（需要保证幂等）； 最终一致性 MQ事务第一步：发送给Broker事务消息即半消息，半消息不是说一半的消息，而是指这个消息对消费者来说不可见； 第二步：发送成功以后，执行本地的事务； 第三步：根据本地事务的执行结果向Broker发送Commit和RollBack命令； 同时：MQ的发送方需要提供一个反查事务状态的接口，如果一段时间内半消息没有收到任何操作请求，那么Broker会通过这个反查接口得知发送方事务是否执行成功，然后执行Commit或者RollBack命令；Commit命令：订阅方就能收到这个消息，然后执行对应的本地事务，然后ACK这个消息；RollBack：订阅方收不到这个消息，等于事务没有执行过； 最终一致性 最大努力通知最大努力通知其实只是表明了一种柔性事务的思想：我已经尽自己最大的努力想达成事务的最终一致性了。本地消息表和事务消息都是最大努力通知的一种。适用于对时间不敏感的业务，例如短信通知； 2PC 两阶段提交协议两阶段提交的问题： 同步阻塞参与者在提交过程中，一直处于阻塞状态，占用着系统资源，其他节点请求的时候就会阻塞； 单点问题过于依赖于事务协调者，如果事务协调者发生宕机或者超时。事务就没有办法继续执行下去。如果问题出现在阶段二，各个事务参与者将会一直处于锁定事务资源的过程中，从而无法继续完成事务。 数据不一致如果在事务协调者发送commit请求的过程中出现了宕机，就会导致一部分事务参与者执行了commit请求、一部分没有执行，就会导致数据在各个执行者是不一样的。 过于保守由于协调者是在接受到所有执行者的commit询问通知反馈之后，才发起的执行提交通知。当任意一个执行者失败或者等待超时之后。协调者就只能依靠自身的中断机制进行事务的中断。这样的策略过于保守，即没有完善的容错机制，任意节点的失败都会导致整个事务的失败。 3PC三阶段提交协议 三阶段提交协议的升级点（基于二阶段） 三阶段提交协议引入了超时机制；对于协调者和参与者都设置了超时机制（2PC中，只有协调者拥有超时机制），主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题。因为参与者自身拥有超时机制，会在超时之后，自动进行本地的commit从而释放资源。这种机制也侧面降低了整个事务的阻塞时间和范围。 在第一阶段和第二阶段，引入了一个缓冲阶段（PreCommit）。保证了在最后提交阶段之前各参与节点的状态是一致的。 PS：3PC协议并没有完全解决数据一致性问题。 XA(强一致性)X/Open组织提出的分布式事务规范，是基于两阶段提交协议。XA规范主要定义了全局事务管理器（TM）和局部资源管理器（RM）之间的接口。是目前主流的关系型数据库的实现方式。为什么需要TM？在分布式系统中，从理论上讲两台机器无法达到一致的状态，需要引入一个单点进行协调。由全局事务管理器管理和协调事务，可以跨越多个资源和进程。事务管理器用来保证所有的事务参与者都完成了准备工作（第一阶段)。如果事务管理器收到所有参与者都准备好的消息，会通知所有的事务都可以提交了（第二阶段)。 Sega模式NWR协议是一种在分布式存储系统中用于控制一致性级别的一种策略。 N： 在分布式存储中，有多少备份数据； W： 代表一次成功的更新操作要求至少有w份数据写入成功； R：代表一次成功的读数据操作要至少有R份数据成功读取； 当W+R&gt;N的时候，整个系统对于客户端来讲能保证强一致性； 当R+W&lt;=N时，无法保证数据的强一致性； 服务治理服务协调分布式锁： 基于缓存（Redis）实现分布式锁，扩展是使用Redisson； Zookeeper实现分布式锁；原理：全局临时顺序节点； 流量销峰方案： 消息队列削峰； 流量削峰漏斗：层层削峰，如下图 服务降级整个架构整体的负载超过了预设的上限阀值或即将到来的流量预计将会超过预设的阀值时，为了保证重要或基本的服务能正常运行，我们可以将一些不重要或不紧急的服务或任务进行延迟或暂停使用；策略： 页面降级； 延迟服务（MQ）； 写降级（限流）； 读降级（限流）； 缓存降级 后端代码： 抛异常； 返回NULL； 调用Mock数据； 调用Fallback处理逻辑； 服务限流限流的目的是通过对并发访问请求进行限速或者一个时间窗口内的请求数量进行限速来保护系统，一旦达到了限制速率则可以拒绝服务、排队或等待； 备注：tomcat的处理请求的参数设置：tomcat的并发数有以下两个参数控制：maxThreads：tomcat启动的最大线程数，即同时处理的任务个数，默认值是200；acceptCount：当tomcat启动的线程数达到最大时，接受排队的请求个数，默认值为100；另外还有支持的最大链接数：maxConnections：tomcat在任意时刻接受和处理的最大连接数。当接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomacat接收的连接数小于maxConnections。默认的最大连接数为10000。 参考博文：https://www.cnblogs.com/sunfie/p/12295945.html 限流算法 固定窗口计数器计数器限制每一分钟或者每一秒内请求不能超过一定的次数，在下一秒钟（下一分钟）计数器清零重新计算。 问题：容易形成流量突刺 滑动窗口计数器滑动窗口其实是细分后的计数器，它将每个时间窗口又细分成若干个时间片段，每过一个时间片段，整个时间窗口就会往右移动一格。 漏桶通过一个固定大小的FIFO队列+定时取队列元素的方式实现，请求进入队列后会被匀速的取出处理，当队列被占满后，后来的请求会被直接拒绝。优点：可以销峰填谷，不论请求多快多大，都只会匀速的发给后端，不会出现突刺现象，保证下游服务正常运行，缺点：队列中的请求会被排队，影响时间被拉长。 令牌桶算法令牌痛算法是以一个固定速率往桶中放置令牌（如果桶中的令牌满了就丢弃），每进来一个请求就去桶中找令牌，有的话就拿走令牌继续处理，没有的就拒绝请求。 优点：可以应对突发流量，当桶中有令牌时可以快速的响应，也不会产生漏桶算法中的等待时间；缺点：相比较漏桶算法，一定程度上减少了对下游服务的保护； 基于Guava的令牌桶算法的设计参考博文：https://juejin.cn/post/6961815018488725541 怎么实现一个限流器？基于Redis限流 基于Redis做限流操作，使用lua脚本保证命令原子性，比如qps设置为10，如果key不存在，就设置key过期时间1s，value=1；如果value小于10，则自增value；value达到10触发流控。示例lua代码如下： 123456789101112131415161718//获取令牌Token， 参数规则Id，获取令牌数，优先级 TokenResult requestToken(Long ruleId, int acquireCount, boolean prioritized); local key = &quot;rate.limit:&quot; .. KEYS[1]local limit = tonumber(ARGV[1])local expire_time = ARGV[2]local is_exists = redis.call(&quot;EXISTS&quot;, key)if is_exists == 1 then if redis.call(&quot;INCR&quot;, key) &gt; limit then return 0 else return 1 endelse redis.call(&quot;SET&quot;, key, 1) redis.call(&quot;EXPIRE&quot;, key, expire_time) return 1end 服务熔断当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护系统的整体可用性，可以暂时切断对下游服务的调用，这种牺牲局部，保全整体的措施叫做熔断。熔断机制： 开启熔断：在固定的时间窗口内，接口调用超时比率达到一个阀值，会开启熔断；进入熔断后，后续对该服务接口的调用不再经过网络，直接执行本地的默认方法，达到服务降级的效果。 熔断恢复：熔断不可能是永久的。当经过了规定时间以后，服务将从熔断状态恢复过来，再次调用下游服务。 实现： spring cloud hystrix 三种状态： 熔断关闭状态（Closed） 熔断开启状态（Open） 10秒中50%的出错比率 半熔断状态（Half-Open）","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/分布式","date":"2021-10-05T21:43:12.778Z","updated":"2022-01-12T06:59:07.949Z","comments":true,"path":"2021/10/06/typora文件集合/拉钩/分布式/","link":"","permalink":"http://example.com/2021/10/06/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%88%86%E5%B8%83%E5%BC%8F/","excerpt":"","text":"[TOC] 分布式特性： 分布性，机器分布在不同的机房、城市、国家； 对等性：没有主从之分，所有节点都是对等的； 并发性：不同的节点可能会并发的访问相同的资源，如数据库； 缺乏全局时钟：很难定义两件事情的发生的先后顺序； 故障总会发生； 单点故障：如果一个服务只有一台机器提供服务，在这台机器上发上的故障就叫做单点故障； 面临的问题： 通信问题：不可避免的会发生通信故障； 数据一致性：备份数据和主数据不同步； 网络分区：也是由于网络不通导致的； 节点故障： 三态：成功、失败、超时； 重发：出现失败和超时，就需要重新发送； 幂等：多次请求，结果保持一致； CAP 一致性所有节点访问都是同一份最新的数据副本；一致性分类：1. 强一致性； 2. 弱一致性； 3. 最终一致性（弱一致性的一种）。 ![分布式系统一致性分类](/Users/xiazhenyu/Desktop/typora文件集合/文档合集/分布式系统一致性分类.png) 可用性每次请求都能获取到不错的响应，但是不能保证获取的数据为最新的数据； 分区容错性分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障； CAP三者不能同时满足的论证AP满足的情况下，两个节点之间因为网路等原因断开了链接，就会导致不同的节点数据是不一致的。 BASE 基本可用假设系统出现了不可预知的故障，但是还可以使用。 软状态允许系统中的数据存在中间状态，并认为该状态不会影响系统的整体可用性。即允许系统在多个不同节点的数据副本存在数据延时； 最终一致性系统不可能是一直是软状态的，必须有个时间限制。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。 这个期限取决于网络延时、系统负载、数据复制方案设计等因素； 6种常见的分布式解决方案TCC补偿事务；-业务层面的分布式事务 Try- Confirm - Cancel Try： 预留，即资源的预留和锁定，注意的是预留； Confirm： 确认操作，这一步就是真正的执行了； Cancel： 撤销操作，可以理解为把预留阶段的动作撤销了； TCC有个事务管理者的角色，用来记录TCC全局事务状态并提交或者回滚事务； 缺点： 对于业务上的每个操作，都需要定义三个动作，分别对应Try-Confirm-Cancel。 对于业务的侵入较大和业务紧耦合，需要根据特定的场景和业务逻辑来设计相应的操作； 另外，撤销和确认操作的执行可能需要重试，因此需要保证幂等； 优点：可以跨数据库、跨不同的业务系统来实现事务； 本地消息表（异步确保）利用了各系统本地事务来实现分布式事务。将业务的执行和将消息放入消息表中的操作放在同一个事务中，这样就能保证消息放入本地消息表中的时候业务肯定是执行成功的。然后调用下一个操作，如果成功了，消息表的状态可以直接改为已成功；失败的话，定时任务定时读取本地消息表，筛选出还未成功的消息再调用对应的服务，服务更新成功了再变更消息的状态；（需要保证幂等）； 最终一致性 MQ事务第一步：发送给Broker事务消息即半消息，半消息不是说一半的消息，而是指这个消息对消费者来说不可见； 第二步：发送成功以后，执行本地的事务； 第三步：根据本地事务的执行结果向Broker发送Commit和RollBack命令； 同时：MQ的发送方需要提供一个反查事务状态的接口，如果一段时间内半消息没有收到任何操作请求，那么Broker会通过这个反查接口得知发送方事务是否执行成功，然后执行Commit或者RollBack命令；Commit命令：订阅方就能收到这个消息，然后执行对应的本地事务，然后ACK这个消息；RollBack：订阅方收不到这个消息，等于事务没有执行过； 最终一致性 最大努力通知最大努力通知其实只是表明了一种柔性事务的思想：我已经尽自己最大的努力想达成事务的最终一致性了。本地消息表和事务消息都是最大努力通知的一种。适用于对时间不敏感的业务，例如短信通知； 2PC 两阶段提交协议两阶段提交的问题： 同步阻塞参与者在提交过程中，一直处于阻塞状态，占用着系统资源，其他节点请求的时候就会阻塞； 单点问题过于依赖于事务协调者，如果事务协调者发生宕机或者超时。事务就没有办法继续执行下去。如果问题出现在阶段二，各个事务参与者将会一直处于锁定事务资源的过程中，从而无法继续完成事务。 数据不一致如果在事务协调者发送commit请求的过程中出现了宕机，就会导致一部分事务参与者执行了commit请求、一部分没有执行，就会导致数据在各个执行者是不一样的。 过于保守由于协调者是在接受到所有执行者的commit询问通知反馈之后，才发起的执行提交通知。当任意一个执行者失败或者等待超时之后。协调者就只能依靠自身的中断机制进行事务的中断。这样的策略过于保守，即没有完善的容错机制，任意节点的失败都会导致整个事务的失败。 3PC三阶段提交协议 三阶段提交协议的升级点（基于二阶段） 三阶段提交协议引入了超时机制；对于协调者和参与者都设置了超时机制（2PC中，只有协调者拥有超时机制），主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题。因为参与者自身拥有超时机制，会在超时之后，自动进行本地的commit从而释放资源。这种机制也侧面降低了整个事务的阻塞时间和范围。 在第一阶段和第二阶段，引入了一个缓冲阶段（PreCommit）。保证了在最后提交阶段之前各参与节点的状态是一致的。 PS：3PC协议并没有完全解决数据一致性问题。 XA(强一致性)X/Open组织提出的分布式事务规范，是基于两阶段提交协议。XA规范主要定义了全局事务管理器（TM）和局部资源管理器（RM）之间的接口。是目前主流的关系型数据库的实现方式。为什么需要TM？在分布式系统中，从理论上讲两台机器无法达到一致的状态，需要引入一个单点进行协调。由全局事务管理器管理和协调事务，可以跨越多个资源和进程。事务管理器用来保证所有的事务参与者都完成了准备工作（第一阶段)。如果事务管理器收到所有参与者都准备好的消息，会通知所有的事务都可以提交了（第二阶段)。 Sega模式NWR协议是一种在分布式存储系统中用于控制一致性级别的一种策略。 N： 在分布式存储中，有多少备份数据； W： 代表一次成功的更新操作要求至少有w份数据写入成功； R：代表一次成功的读数据操作要至少有R份数据成功读取； 当W+R&gt;N的时候，整个系统对于客户端来讲能保证强一致性； 当R+W&lt;=N时，无法保证数据的强一致性； 服务治理服务协调分布式锁： 基于缓存（Redis）实现分布式锁，扩展是使用Redisson； Zookeeper实现分布式锁；原理：全局临时顺序节点； 流量销峰方案： 消息队列削峰； 流量削峰漏斗：层层削峰，如下图 服务降级整个架构整体的负载超过了预设的上限阀值或即将到来的流量预计将会超过预设的阀值时，为了保证重要或基本的服务能正常运行，我们可以将一些不重要或不紧急的服务或任务进行延迟或暂停使用；策略： 页面降级； 延迟服务（MQ）； 写降级（限流）； 读降级（限流）； 缓存降级 后端代码： 抛异常； 返回NULL； 调用Mock数据； 调用Fallback处理逻辑； 服务限流限流的目的是通过对并发访问请求进行限速或者一个时间窗口内的请求数量进行限速来保护系统，一旦达到了限制速率则可以拒绝服务、排队或等待； 备注：tomcat的处理请求的参数设置：tomcat的并发数有以下两个参数控制：maxThreads：tomcat启动的最大线程数，即同时处理的任务个数，默认值是200；acceptCount：当tomcat启动的线程数达到最大时，接受排队的请求个数，默认值为100；另外还有支持的最大链接数：maxConnections：tomcat在任意时刻接受和处理的最大连接数。当接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomacat接收的连接数小于maxConnections。默认的最大连接数为10000。 参考博文：https://www.cnblogs.com/sunfie/p/12295945.html 限流算法 固定窗口计数器计数器限制每一分钟或者每一秒内请求不能超过一定的次数，在下一秒钟（下一分钟）计数器清零重新计算。 问题：容易形成流量突刺 滑动窗口计数器滑动窗口其实是细分后的计数器，它将每个时间窗口又细分成若干个时间片段，每过一个时间片段，整个时间窗口就会往右移动一格。 漏桶通过一个固定大小的FIFO队列+定时取队列元素的方式实现，请求进入队列后会被匀速的取出处理，当队列被占满后，后来的请求会被直接拒绝。优点：可以销峰填谷，不论请求多快多大，都只会匀速的发给后端，不会出现突刺现象，保证下游服务正常运行，缺点：队列中的请求会被排队，影响时间被拉长。 令牌桶算法令牌痛算法是以一个固定速率往桶中放置令牌（如果桶中的令牌满了就丢弃），每进来一个请求就去桶中找令牌，有的话就拿走令牌继续处理，没有的就拒绝请求。 优点：可以应对突发流量，当桶中有令牌时可以快速的响应，也不会产生漏桶算法中的等待时间；缺点：相比较漏桶算法，一定程度上减少了对下游服务的保护； 基于Guava的令牌桶算法的设计参考博文：https://juejin.cn/post/6961815018488725541 怎么实现一个限流器？基于Redis限流 基于Redis做限流操作，使用lua脚本保证命令原子性，比如qps设置为10，如果key不存在，就设置key过期时间1s，value=1；如果value小于10，则自增value；value达到10触发流控。示例lua代码如下： 123456789101112131415161718//获取令牌Token， 参数规则Id，获取令牌数，优先级 TokenResult requestToken(Long ruleId, int acquireCount, boolean prioritized); local key = &quot;rate.limit:&quot; .. KEYS[1]local limit = tonumber(ARGV[1])local expire_time = ARGV[2]local is_exists = redis.call(&quot;EXISTS&quot;, key)if is_exists == 1 then if redis.call(&quot;INCR&quot;, key) &gt; limit then return 0 else return 1 endelse redis.call(&quot;SET&quot;, key, 1) redis.call(&quot;EXPIRE&quot;, key, expire_time) return 1end 服务熔断当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护系统的整体可用性，可以暂时切断对下游服务的调用，这种牺牲局部，保全整体的措施叫做熔断。熔断机制： 开启熔断：在固定的时间窗口内，接口调用超时比率达到一个阀值，会开启熔断；进入熔断后，后续对该服务接口的调用不再经过网络，直接执行本地的默认方法，达到服务降级的效果。 熔断恢复：熔断不可能是永久的。当经过了规定时间以后，服务将从熔断状态恢复过来，再次调用下游服务。 实现： spring cloud hystrix 三种状态： 熔断关闭状态（Closed） 熔断开启状态（Open） 10秒中50%的出错比率 半熔断状态（Half-Open）","categories":[],"tags":[]},{"title":"","slug":"MQ","date":"2021-10-05T07:03:25.419Z","updated":"2021-11-04T11:54:49.875Z","comments":true,"path":"2021/10/05/MQ/","link":"","permalink":"http://example.com/2021/10/05/MQ/","excerpt":"","text":"[TOC] MQ什么是MQmq的作用？ 系统解耦 流量削峰填谷 异步处理 最终一致性 开启事务； 业务操作，比如说订单进行持久化等等操作； 生成消息，并存储，这个和业务操作在同一个事务中； 提交事务； 发送消息，发送成功则将消息表中的消息删除，发送失败则不删除。同时写一个定时任务查询消息表，查询没有被删除的消息并发送。 mq的幂等性保证消息表，什么是消息表 pulsar的架构？为什么使用pulsar？优势： pulsar的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息的复制； 极低的发布延迟和端到端延迟； 可无缝扩展超过100万个topic； 简单的API； 支持多种topic订阅模式； 使用Apache BookKeeper提供的持久化消息存储机制保证消息的传递； 组成部分： broker：负责分发消息； bookie：负责消息的存储 zk：负责节点的协调。 pulsar的三种消费模式： 共享式：多个client可以订阅同一个topic。消息以轮训的方式分布在各个client之间，任何给定的消息仅传递给一个client。当client断开链接的时候，会将未消费的消息发送给其他的消费者。 独占式（exclusive）：近允许单个消费者订阅Topic； 故障转移模式:多个client可以订阅同一个topic。为主消费者选择非分区主题或分区主题的每个分区，并接受消息。当主使用者断开连接时，所有消息将被传递到排队的下一个使用者。对于分区主题，代理将按优先级和消费者的名字的字典顺序对消费者进行消费。然后，代理将尝试将主题平均分配给优先级最高的消费者；对于非分区主题，代理将按订阅非分区主题的顺序选择消费者； 自己设计一个MQ需要考虑哪些点？ 队列的选择，可以考虑使用BlockingQueue 高可用选择： 队列的相关知识点","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/MQ","date":"2021-10-05T07:03:25.419Z","updated":"2021-11-04T11:54:49.875Z","comments":true,"path":"2021/10/05/typora文件集合/拉钩/MQ/","link":"","permalink":"http://example.com/2021/10/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/MQ/","excerpt":"","text":"[TOC] MQ什么是MQmq的作用？ 系统解耦 流量削峰填谷 异步处理 最终一致性 开启事务； 业务操作，比如说订单进行持久化等等操作； 生成消息，并存储，这个和业务操作在同一个事务中； 提交事务； 发送消息，发送成功则将消息表中的消息删除，发送失败则不删除。同时写一个定时任务查询消息表，查询没有被删除的消息并发送。 mq的幂等性保证消息表，什么是消息表 pulsar的架构？为什么使用pulsar？优势： pulsar的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息的复制； 极低的发布延迟和端到端延迟； 可无缝扩展超过100万个topic； 简单的API； 支持多种topic订阅模式； 使用Apache BookKeeper提供的持久化消息存储机制保证消息的传递； 组成部分： broker：负责分发消息； bookie：负责消息的存储 zk：负责节点的协调。 pulsar的三种消费模式： 共享式：多个client可以订阅同一个topic。消息以轮训的方式分布在各个client之间，任何给定的消息仅传递给一个client。当client断开链接的时候，会将未消费的消息发送给其他的消费者。 独占式（exclusive）：近允许单个消费者订阅Topic； 故障转移模式:多个client可以订阅同一个topic。为主消费者选择非分区主题或分区主题的每个分区，并接受消息。当主使用者断开连接时，所有消息将被传递到排队的下一个使用者。对于分区主题，代理将按优先级和消费者的名字的字典顺序对消费者进行消费。然后，代理将尝试将主题平均分配给优先级最高的消费者；对于非分区主题，代理将按订阅非分区主题的顺序选择消费者； 自己设计一个MQ需要考虑哪些点？ 队列的选择，可以考虑使用BlockingQueue 高可用选择： 队列的相关知识点","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/MQ/MQ","date":"2021-10-05T07:03:25.419Z","updated":"2022-02-24T01:46:41.362Z","comments":true,"path":"2021/10/05/typora文件集合/拉钩/中间件/MQ/MQ/","link":"","permalink":"http://example.com/2021/10/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ/","excerpt":"","text":"[TOC] MQ什么是MQmq的作用？ 系统解耦 流量削峰填谷 异步处理 最终一致性 开启事务； 业务操作，比如说订单进行持久化等等操作； 生成消息，并存储，这个和业务操作在同一个事务中； 提交事务； 发送消息，发送成功则将消息表中的消息删除，发送失败则不删除。同时写一个定时任务查询消息表，查询没有被删除的消息并发送。 mq的幂等性保证消息表，什么是消息表 pulsar的架构？为什么使用pulsar？优势： pulsar的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息的复制； 极低的发布延迟和端到端延迟； 可无缝扩展超过100万个topic； 简单的API； 支持多种topic订阅模式； 使用Apache BookKeeper提供的持久化消息存储机制保证消息的传递； 组成部分： broker：负责分发消息； bookie：负责消息的存储 zk：负责节点的协调。 pulsar的三种消费模式： 共享式：多个client可以订阅同一个topic。消息以轮训的方式分布在各个client之间，任何给定的消息仅传递给一个client。当client断开链接的时候，会将未消费的消息发送给其他的消费者。 独占式（exclusive）：近允许单个消费者订阅Topic； 故障转移模式:多个client可以订阅同一个topic。为主消费者选择非分区主题或分区主题的每个分区，并接受消息。当主使用者断开连接时，所有消息将被传递到排队的下一个使用者。对于分区主题，代理将按优先级和消费者的名字的字典顺序对消费者进行消费。然后，代理将尝试将主题平均分配给优先级最高的消费者；对于非分区主题，代理将按订阅非分区主题的顺序选择消费者； 自己设计一个MQ需要考虑哪些点？ 队列的选择，可以考虑使用BlockingQueue 高可用选择： 队列的相关知识点","categories":[],"tags":[]},{"title":"","slug":"Redis","date":"2021-10-04T06:06:28.739Z","updated":"2022-01-13T07:22:07.526Z","comments":true,"path":"2021/10/04/Redis/","link":"","permalink":"http://example.com/2021/10/04/Redis/","excerpt":"","text":"[TOC] Redis的基本数据结构 Hash、Set 、Sorted Set、List、Geo、String等数据类型 数据库由redis.h中的RedisDb定义，初始化的时候，会预先分配16个数据库；所有的数据库保存到结构RedisServer的一个成员RedisServer.db 数组中。redisClient中存在一个名叫db的指针指向当前使用的数据库。 RedisObject结构：value是一个对象，包含字符串、列表、哈希对象、集合对象和有序集合对象； 字符串：Redis使用SDS（Simple Dynamic String）用于存储字符串和整型数据； 优势： SDS在C语言字符串的基础上加入了free和len字段，获取字符串长度的时间复杂度是O(1)，C是O(n); SDS由于记录了长度，在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区的溢出； 可以存取二进制数据，以字符串长度len来作为结束标识； 使用场景：存储字符串和整型数据、存储key、AOF缓冲区和用户输入缓冲； 有序集合跳表 ： 将有序链表中的部分节点分层，每一层都是一个有序链表； 查找过程：在查找时优先从最高层开始向后查找，当达到某个节点时，如果next节点值大于要查找的值或next指针指向null，则从==当前节点==下降一层继续向后查找。 插入：通过抛硬币（概率1/2）的方式来决定新插入结点跨越的层数；正面：插入上层；背面：不插入 删除：找到指定元素并删除每层的该元素即可； 特点： 每层都是一个有序链表； 查找的次数近似等于层数（1/2）； 底层包含所有元素； 空间复杂度O(n)扩充了一倍； 实现：利用zskiplist实现； 优势： 可以快速查找需要的节点O(logn); 可以在O(1)的时间复杂度下，快速获得跳跃表的头节点、尾节点、长度和高度；（zskiplist存储了这些信息）； 字典（hash散列表）hash冲突：采用单链表在相同的下标位置存储原始的key和value； 实现：包括：字典（dict）、Hash表（dictht）、Hash表节点（dictEntry）； 用途：出了可以存储K-V数据以外，还可以用于：散列表对象、哨兵模式中的主从节点管理； 扩容：存储上限：阀值0.75，需要rehash（扩容） 说明： 初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍； rehashidx，rehash标识。=0表示要进行rehash操作； 新增加的数据在新的hash表h[1]； 修改、删除、查询都在老的hash表h[0]、新hash表h[1]中（reshash中）； 将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为rehash。 渐进式hash：服务器忙的时候，则只对一个节点进rehash，服务器闲，可批量rehash（100节点）； 压缩列表（ziplist）压缩列表(ziplist)是由一系列特殊编码的连续内存块组成的顺序型数据结构 快速列表快速列表（quicklist）是Redis底层重要的数据结构，是列表的底层实现；快速列表是一个双向链表，链表中的每个节点是一个ziplist结构。quicklist中的每个节点ziplist都能够存储多个数据元素；双向链表的优势: 双向:链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。 普通链表(单链表):节点类保留下一节点的引用。链表类只保留头节点的引用，只能从头节点插 入删除； 无环:表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结 束。环状:头的前一个节点指向尾节点 带链表长度计数器:通过 len 属性获取链表长度的时间复杂度为 O(1)。 多态:链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。 10中encodingencoding 表示对象的内部编码，占 4 位。Redis通过 encoding 属性为对象设置不同的编码。 String的有三个：int（int类型的整数）、embstr（编码的简单动态字符串，长度小于44字节）、raw（简单动态字符串，长度大于44字节）； list的是quicklist（快速列表）； hash的是字典和压缩列表；dict（字典，散列表元素个数比较多或元素不是小整数或短字符串时），ziplist（当散列表的元素个数比较少，且元素都是小整型或短字符串时） set的是整型集合（intSet 都是整数并且在64位有符号整数范围内）和字典（非整数或在64位有符号整数范围以外）； zset的是：压缩列表和跳表+字典； 和memcache的区别： Redis的淘汰策略LRU：最近最少使用方式； LFU：最不经常使用方式； LEU:当内存满的时候，直接丢弃新的key值的写入； Redis的过期策略：主动过期+惰性过期两种；主动过期：redis默认每隔100ms就随机抽取一些设置了过期的key，检查是否过期，如果过期了就删除。惰性过期：过期的key，没有及时删除，那么在查询的时候，redis才会删除。 Redis的高可用性为什么是高性能的？redis内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以redis是单线程模型。它采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器进行处理。文件事件处理器包含4个部分： 多个socket； IO多路复用程序； 文件事件派发器； 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个socket会产生不同的操作，每个操作对应不同的文件事件。但是IO多路复用程序会监听多个socket，并将这些事件放到一个队列中去。文件事件派发器会从队列中取出一个事件，派发给对应的事件处理器进行处理。 持久化方式RDB复制和AOF复制 RDB复制全量复制。 AOF复制增量同步复制。原理：AOF文件中存储的是redis的命令，同步命令到 AOF 文件的整个过程可以分为三个阶段: 命令传播:Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。 缓存追加:AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加 到服务器的 AOF 缓存中。* 文件写入和保存:AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。 AOF的3种刷盘机制： Appendfsync always:每次写入磁盘都刷盘，对性能影响最大，占用IO比较高，数据安全型最高； appendfsync everysec：1秒刷一次盘，对性能影响最小，数据安全性低，节点宕机时最多丢失1秒数据； appendfsync no：按照操作系统机制刷盘，对性能影响最小，但是数据安全性低； 主从同步性能指标Redis的常用问题DB和缓存数据的不一致性不一致一方面有可能是更新db和redis的时候失败了，导致不一致，还有一种情况就是两者更新的中间某一时刻，其他线程进行请求，这个时候就会请求到老的数据，造成数据的不一致。 优先采用：先更新数据库、再删除缓存的策略。 怎么解决不一致问题？延迟删除？答：强一致性很难，追求最终一致性（需要时间）； 利用Redis的缓存淘汰策略被动更新 LRU 、LFU； 利用TTL被动更新； 在更新数据库时主动更新 (先更数据库再删缓存—-延时双删)； 异步更新 定时任务 数据不保证时时一致 不穿DB； 缓存穿透、击穿、雪崩 缓存穿透：客户端发起了大量的不存在的key的请求，这个时候缓存查询不到，就去请求数据库。相当于直接穿透缓存打到DB。怎么解决： 布隆过滤器； 缓存无效的key，并设置过期时间。key值的设计 表明名:列名:主键值 缓存击穿 户端同一个key短时间内有大量的请求，然后恰好这个时候，这个key的缓存失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。 怎么解决： 对于热点key可以不用设置过期时间； 使用互斥锁。如果缓存失效，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库被打死。 缓存雪崩： redis大量的key失效，造成缓存功能失效，请求直接打到db，造成数据库压力增大。怎么解决： 事前：尽量保证整个redis集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略； 事中： 本地ehcache缓存+hystrix限流&amp;降级，避免MySQL崩掉； 事后：利用redis持久化机制保存的数据库尽恢复缓存。 怎么处理热点缓存提前预热：把热点数据提前加载到缓存中。 MySQL⾥有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据? 保留热点数据。淘汰策略使用allkeys-lru. 保证Redis中只存20W的数据。 分布式锁的使用情况、和Redission的区别redis分布式锁：setNx命令；Redission框架：参考地址 ​ 加锁：如果客户端面临的是一个redis cluster 集群，首先会根据hash节点选择一台机器； 发送lua脚本到redis服务器上； 使用exists myLock 命令判断一下，如果key不存在的话，就进行加锁，使用hset myLock命令，需要注意的是value是客户端的Id（UUID）+线程id,并设置过期时间； 如果了另一个客户端请求，会发现key已经存在，然后判断hash数据结构中是否包含客户端2的id，没有的话，返回key的剩余生存时间；这个时候，客户端2会继续尝试获取； 一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每个10s检查下，如果客户端1还持有锁，就会不断延长key的生存时间； 重入：如果客户端1再次加锁，就会将hash数据结构中的值加一； 解锁：每次对myLock数据结构中的那个加锁次数减1。如果发现是0了，说明这个客户端已经不再持有锁了，那么这个时候就可以删除这个key了，同时会发布一个redis解锁的消息给其他的客户端；如果不是0，就会继续延长这个锁的超时时间； 利用redis还可以实现哪些常用的功能？怎么解决库存超卖问题？答：见高并发下库存扣减； 大key问题 string类型的big key，不要放到redis中； 单个简单的key存储的value很大，可以尝试将对象拆分成几个key-value，使用mget的方式获取值，这样的话，分拆单次操作的压力，将整个压力平摊到多次操作中，降低对redis的IO影响。 hash、","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/Redis","date":"2021-10-04T06:06:28.739Z","updated":"2022-01-13T07:22:07.526Z","comments":true,"path":"2021/10/04/typora文件集合/拉钩/Redis/","link":"","permalink":"http://example.com/2021/10/04/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/Redis/","excerpt":"","text":"[TOC] Redis的基本数据结构 Hash、Set 、Sorted Set、List、Geo、String等数据类型 数据库由redis.h中的RedisDb定义，初始化的时候，会预先分配16个数据库；所有的数据库保存到结构RedisServer的一个成员RedisServer.db 数组中。redisClient中存在一个名叫db的指针指向当前使用的数据库。 RedisObject结构：value是一个对象，包含字符串、列表、哈希对象、集合对象和有序集合对象； 字符串：Redis使用SDS（Simple Dynamic String）用于存储字符串和整型数据； 优势： SDS在C语言字符串的基础上加入了free和len字段，获取字符串长度的时间复杂度是O(1)，C是O(n); SDS由于记录了长度，在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区的溢出； 可以存取二进制数据，以字符串长度len来作为结束标识； 使用场景：存储字符串和整型数据、存储key、AOF缓冲区和用户输入缓冲； 有序集合跳表 ： 将有序链表中的部分节点分层，每一层都是一个有序链表； 查找过程：在查找时优先从最高层开始向后查找，当达到某个节点时，如果next节点值大于要查找的值或next指针指向null，则从==当前节点==下降一层继续向后查找。 插入：通过抛硬币（概率1/2）的方式来决定新插入结点跨越的层数；正面：插入上层；背面：不插入 删除：找到指定元素并删除每层的该元素即可； 特点： 每层都是一个有序链表； 查找的次数近似等于层数（1/2）； 底层包含所有元素； 空间复杂度O(n)扩充了一倍； 实现：利用zskiplist实现； 优势： 可以快速查找需要的节点O(logn); 可以在O(1)的时间复杂度下，快速获得跳跃表的头节点、尾节点、长度和高度；（zskiplist存储了这些信息）； 字典（hash散列表）hash冲突：采用单链表在相同的下标位置存储原始的key和value； 实现：包括：字典（dict）、Hash表（dictht）、Hash表节点（dictEntry）； 用途：出了可以存储K-V数据以外，还可以用于：散列表对象、哨兵模式中的主从节点管理； 扩容：存储上限：阀值0.75，需要rehash（扩容） 说明： 初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍； rehashidx，rehash标识。=0表示要进行rehash操作； 新增加的数据在新的hash表h[1]； 修改、删除、查询都在老的hash表h[0]、新hash表h[1]中（reshash中）； 将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为rehash。 渐进式hash：服务器忙的时候，则只对一个节点进rehash，服务器闲，可批量rehash（100节点）； 压缩列表（ziplist）压缩列表(ziplist)是由一系列特殊编码的连续内存块组成的顺序型数据结构 快速列表快速列表（quicklist）是Redis底层重要的数据结构，是列表的底层实现；快速列表是一个双向链表，链表中的每个节点是一个ziplist结构。quicklist中的每个节点ziplist都能够存储多个数据元素；双向链表的优势: 双向:链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。 普通链表(单链表):节点类保留下一节点的引用。链表类只保留头节点的引用，只能从头节点插 入删除； 无环:表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结 束。环状:头的前一个节点指向尾节点 带链表长度计数器:通过 len 属性获取链表长度的时间复杂度为 O(1)。 多态:链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。 10中encodingencoding 表示对象的内部编码，占 4 位。Redis通过 encoding 属性为对象设置不同的编码。 String的有三个：int（int类型的整数）、embstr（编码的简单动态字符串，长度小于44字节）、raw（简单动态字符串，长度大于44字节）； list的是quicklist（快速列表）； hash的是字典和压缩列表；dict（字典，散列表元素个数比较多或元素不是小整数或短字符串时），ziplist（当散列表的元素个数比较少，且元素都是小整型或短字符串时） set的是整型集合（intSet 都是整数并且在64位有符号整数范围内）和字典（非整数或在64位有符号整数范围以外）； zset的是：压缩列表和跳表+字典； 和memcache的区别： Redis的淘汰策略LRU：最近最少使用方式； LFU：最不经常使用方式； LEU:当内存满的时候，直接丢弃新的key值的写入； Redis的过期策略：主动过期+惰性过期两种；主动过期：redis默认每隔100ms就随机抽取一些设置了过期的key，检查是否过期，如果过期了就删除。惰性过期：过期的key，没有及时删除，那么在查询的时候，redis才会删除。 Redis的高可用性为什么是高性能的？redis内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以redis是单线程模型。它采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器进行处理。文件事件处理器包含4个部分： 多个socket； IO多路复用程序； 文件事件派发器； 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个socket会产生不同的操作，每个操作对应不同的文件事件。但是IO多路复用程序会监听多个socket，并将这些事件放到一个队列中去。文件事件派发器会从队列中取出一个事件，派发给对应的事件处理器进行处理。 持久化方式RDB复制和AOF复制 RDB复制全量复制。 AOF复制增量同步复制。原理：AOF文件中存储的是redis的命令，同步命令到 AOF 文件的整个过程可以分为三个阶段: 命令传播:Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。 缓存追加:AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加 到服务器的 AOF 缓存中。* 文件写入和保存:AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。 AOF的3种刷盘机制： Appendfsync always:每次写入磁盘都刷盘，对性能影响最大，占用IO比较高，数据安全型最高； appendfsync everysec：1秒刷一次盘，对性能影响最小，数据安全性低，节点宕机时最多丢失1秒数据； appendfsync no：按照操作系统机制刷盘，对性能影响最小，但是数据安全性低； 主从同步性能指标Redis的常用问题DB和缓存数据的不一致性不一致一方面有可能是更新db和redis的时候失败了，导致不一致，还有一种情况就是两者更新的中间某一时刻，其他线程进行请求，这个时候就会请求到老的数据，造成数据的不一致。 优先采用：先更新数据库、再删除缓存的策略。 怎么解决不一致问题？延迟删除？答：强一致性很难，追求最终一致性（需要时间）； 利用Redis的缓存淘汰策略被动更新 LRU 、LFU； 利用TTL被动更新； 在更新数据库时主动更新 (先更数据库再删缓存—-延时双删)； 异步更新 定时任务 数据不保证时时一致 不穿DB； 缓存穿透、击穿、雪崩 缓存穿透：客户端发起了大量的不存在的key的请求，这个时候缓存查询不到，就去请求数据库。相当于直接穿透缓存打到DB。怎么解决： 布隆过滤器； 缓存无效的key，并设置过期时间。key值的设计 表明名:列名:主键值 缓存击穿 户端同一个key短时间内有大量的请求，然后恰好这个时候，这个key的缓存失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。 怎么解决： 对于热点key可以不用设置过期时间； 使用互斥锁。如果缓存失效，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库被打死。 缓存雪崩： redis大量的key失效，造成缓存功能失效，请求直接打到db，造成数据库压力增大。怎么解决： 事前：尽量保证整个redis集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略； 事中： 本地ehcache缓存+hystrix限流&amp;降级，避免MySQL崩掉； 事后：利用redis持久化机制保存的数据库尽恢复缓存。 怎么处理热点缓存提前预热：把热点数据提前加载到缓存中。 MySQL⾥有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据? 保留热点数据。淘汰策略使用allkeys-lru. 保证Redis中只存20W的数据。 分布式锁的使用情况、和Redission的区别redis分布式锁：setNx命令；Redission框架：参考地址 ​ 加锁：如果客户端面临的是一个redis cluster 集群，首先会根据hash节点选择一台机器； 发送lua脚本到redis服务器上； 使用exists myLock 命令判断一下，如果key不存在的话，就进行加锁，使用hset myLock命令，需要注意的是value是客户端的Id（UUID）+线程id,并设置过期时间； 如果了另一个客户端请求，会发现key已经存在，然后判断hash数据结构中是否包含客户端2的id，没有的话，返回key的剩余生存时间；这个时候，客户端2会继续尝试获取； 一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每个10s检查下，如果客户端1还持有锁，就会不断延长key的生存时间； 重入：如果客户端1再次加锁，就会将hash数据结构中的值加一； 解锁：每次对myLock数据结构中的那个加锁次数减1。如果发现是0了，说明这个客户端已经不再持有锁了，那么这个时候就可以删除这个key了，同时会发布一个redis解锁的消息给其他的客户端；如果不是0，就会继续延长这个锁的超时时间； 利用redis还可以实现哪些常用的功能？怎么解决库存超卖问题？答：见高并发下库存扣减； 大key问题 string类型的big key，不要放到redis中； 单个简单的key存储的value很大，可以尝试将对象拆分成几个key-value，使用mget的方式获取值，这样的话，分拆单次操作的压力，将整个压力平摊到多次操作中，降低对redis的IO影响。 hash、","categories":[],"tags":[]},{"title":"","slug":"MySQL","date":"2021-10-03T05:08:02.473Z","updated":"2022-02-24T01:45:33.929Z","comments":true,"path":"2021/10/03/MySQL/","link":"","permalink":"http://example.com/2021/10/03/MySQL/","excerpt":"","text":"短期学习计划： 1.目标必须是具体的（Specific）： 阅读Java多线程编程核心技术，深入掌握多线程中AQS的底层原理、锁与相关API工具类的应用； 2.目标必须是可以衡量的（Measurable）： 每周输出一个工具类的架构图，并练习相应的Demo； 3.目标必须是可以达到的（Attainable）： 画出AQS中底层的ReentrantLock与CountDownLatch等API工具类的源码调用关系图，并输出笔记； 4.目标必须是要与其他目标具有一定的相关性(Relevant)： 配合完成第二阶段模块三学习：并发编程与环境优化； 5.目标必须具有明确的截止期限（Time-bound）： 圣诞节前完成； MySQL[TOC] Mysql的架构Server层 链接层负责客户端和数据库的链接，权限验证； 语法分析层对要执行的sql语句进行分析，校验是否符合sql语法规范； 优化器层对要执行的sql，生成执行计划，索引选择； 执行层具体的sql查询执行部分，有InnoDB和MyISAM两个最常用的引擎。 引擎层（InnoDB和MyISAM） InnoDB和MyISAM的区别： InnoDB支持事务，而MyISAM不支持事务； MyISAM只支持表级锁，而InnoDB是支持行级锁（默认）； InnoDB的索引文件和数据文件是一起的，而MyISAM的索引文件和数据文件是分开的。MyISAM的索引的叶子节点存放的是数据的物理地址，这样的话，即便是根据主键进行查询我们仍然需要一次磁盘的IO操作才可以拿到数据。 MyISAM不支持外键，而InnoDB支持； 是否支持MVCC； MyISAM适用于读密集型场景，比如报表等业务； Mysql的索引索引的分类：哈希表、有序数组、BST； 索引的结构：B+树索引（平衡的N叉树）。 减少树的高度，可以有效的减少对磁盘的IO操作。 主键索引（聚簇索引）；父节点存放主键数据，叶子节点存放对应行的完整的数据。 二级索引（非聚簇索引）： 父节点存放的是索引数据，叶子节点存放的是主键索引数据。这样根据二级索引进行查询的时候，会有一次根据叶子节点的主键的值重新查询一边主键索引树的操作（回表操作）。 覆盖索引：索引的叶子节点存储的正是我们查询的结果； 索引能支持最左匹配原则，是和二叉查找树的索引结构有关的：从左到右是有序的，对于联合索引，是先按照第一个字段排序，再按照第二个字段排序，以此类推； PS：在表设计的时候，不建议使用过长的字段作为主键（这样容易造成二级索引叶子节点存储占用空间大），也不建议使用非单调的字段作为主键，这样会造成主键索引频繁的分裂。数据页： 页分裂： join的优化： 驱动表为小表； 对被驱动表添加索引（在关联的字段上），不好添加索引的，可以引入中间表； MRR优化； 索引失效的场景？ 使用了like操作，且%在字符串的右侧； 对于符合索引，不满足最左匹配原则，查询的字段没有从最左边的字段开始查起； mysql 的log日志分类 binlog作用： 记录的是数据库的写入操作。有server层进行开发，所以说任何存储引擎都支持。通过追加的方式来写入。 应用场景：主从复制/数据恢复。 binlog的刷盘时机：0：不去强制要求，由系统自行判断何时写入磁盘；1：每次 commit 的时候都要将 binlog 写入磁盘；N：每N个事务，才会将 binlog 写入磁盘 格式： 2.1 statementbinlog中存放的是原始的sql语句；优点是日志占用空间小，缺点是容易造成主从同步的不一致； 2.2 row格式binlog中存放的是每一行的数据，优点是可以保证主从同步的一致，另外也便于回滚操作，缺点是日志量大； 2.3 mixed格式mysql会根据sql的语句进行分析，如果不会造成主从同步的不一致，就采用statement格式，反之则采用row格式；举例：sql中带有条件的delete、update语句容易造成主从同步的不一致，因为主库和从库在执行的时候，又可能选择了不同的索引； redolog作用： 用于崩溃恢复数据的执行。对于DML语句，mysql首先是先写到redolog中，然后返回执行结果。后续在把redolog中的日志回放写入到磁盘中； 记录形式redo log 实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。 LSN：逻辑序列号。就是上面的write pos和check point的位置。 redo log binlog 文件大小 redo log 的大小是固定的。 binlog 可通过配置参数 max_binlog_size 设置每个binlog文件的大小。 实现方式 redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。 binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志 记录方式 redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 适用场景 redo log 适用于崩溃恢复(crash-safe) binlog 适用于主从复制和数据恢复 undolog作用： 用于数据的回滚。会根据undolog中的日志回滚数据。原子性的保证，MVCC中也使用到了 relaylog作用： 中转日志。主要用于主从同步。主库会在备库第一次连接的时候，生成一个relaylog日志传递给备库，备库会启动一个io_thread线程回放这个日志到本地。 mysql的主从同步，双M结构，数据库A和数据B互为主备关系。 mySql的事务隔离级别？ACID 脏读 读到了未提交的事务修改的数据； 不可重复读 事务A对某一行记录前后两次的读取的信息不一致。 幻读 事务A对根据条件查询数据库，第一次查询出两行记录；然后另一个事务插入了一行数据，当事务A再次查询的时候，发现读取到了三条记录，这个时候就发生了幻读。 事务的隔离级别：一、 读未提交。可造成脏读、幻读、不可重复读； 二、 读已提交。可解决脏读的问题，不能解决不可重复读和幻读的问题； 三、 可重复读。可解决脏读、不可重复读的问题。但仍有可能幻读发生；（默认的，利用MVCC实现）。 四、串行化读。可解决脏读、幻读、不可重复读； 锁乐观锁和悲观锁。 乐观锁认为数据会被多个线程同时修改的，在执行sql的时候，会先给这行数据加锁，执行完之后再把锁释放； 乐观锁认为数据是不会被修改的，只是在修改的时候，回去判断下要修改的数据的是否和期望的一致，一致则允许修改，不一致则拒绝。 间隙锁（Gap Lock）锁住行的间隙，防止对数据行之间进行插入操作。这个锁可以解决幻读问题。所以我们说InnoDB默认的REPEATABLE_READ这个事务隔离级别是完全保证了事务的隔离型要求。 间隙锁和next-key lock mysql的除了DB，还在哪些业务上会被使用到？分布式锁；发号服务； 优化方式？ExplainMySQL 提供了一个 EXPLAIN 命令，它可以对 SELECT 语句进行分析，并输出 SELECT 执行的详细信 息，供开发人员有针对性的优化。 select_type表示查询的类型，常用的有：SIMPLE : 表示查询语句不包含子查询或unionPRIMARY:表示此查询是最外层的查询UNION:表示此查询是UNION的第二个或后续的查询DEPENDENT UNION:UNION中的第二个或后续的查询语句，使用了外面查询结果UNION RESULT:UNION的结果SUBQUERY:SELECT子查询语句DEPENDENT SUBQUERY:SELECT子查询语句依赖外层查询的结果。 *** type***表示存储引擎查询数据时采用的方式。通过它可以判断出查询是全表扫描还是基于索引的部分扫描。ALL:表示全表扫描，性能最差。index:表示基于索引的全表扫描，先扫描索引再扫描全表数据。range:表示使用索引范围查询。使用&gt;、&gt;=、&lt;、&lt;=、in等等。ref:表示使用非唯一索引进行单值查询。eq_ref:一般情况下出现在多表join查询，表示前面表的每一个记录，都只能匹配后面表的一 行结果。 const:表示使用主键或唯一索引做等值查询，常量查询。 NULL:表示不用访问表，速度最快。 possible_keys 表示查询时能够使用到的索引。注意并不一定会真正使用到。显示的是索引名称； key表示查询时真正使用到的索引，显示的是索引名称； rows估算SQL要查询到结果需要扫描多少行记录。 key_len 表示查询使用了索引的字节数量，可以判断是否全部使用了组合索引。 Extra表示很多额外的信息，各种操作会在Extra中提示相关信息。Using where：表示查询需要通过索引回表查询数据；Using index：表示查询通过索引，索引就可以满足所需数据；Using filesort: 表示查询出来的结果需要额外排序，数据量小在内存，大的话在磁盘。Using temprorary： 查询使用到了临时表，一半出现于去重、分组操作。 MVCC 概念：MVCC(Multi Version Concurrency Control)被称为多版本控制，是指在数据库中为了实现高并发的 数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本。 多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据库的吞吐量及读写性能。如何生成的多版本?每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号， 该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。 MVCC只在 Read Commited 和 Repeatable Read 两种隔离级别下工作 原理：用排他锁锁定该行;记录 Redo log;把该行修改前的值复制到 Undo log，即图中下面的行;修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行。 一致性读：一种读取操作，该操作使用基于某个时间点的快照信息来显示查询结果，而不介意并发中其他事务对数据进行的修改。RR事务隔离级别的就是一致性读。 *** 当前读：***读取最新的数据。==更新数据时==，先读取数据，而这个数据是当前已经提交的数据（可理解为读已提交），然后在进行数据的写入。也就是说，在执行 1insert、update、delete 操作时，会先去取下最新的数据，然后在执行DML语句。另外，select xxx for update 也是当前读。 *** 快照读：***每次读取都是基于快照来读。使用RR隔离级别时，快照基于执行第一次读取操作的时间，在RC隔离级别下，快照将重置为每次一致性读取操作的时间。也就是说，RC下，每次读取都会取最新的快照。在RR级别下，开启事务并不会创建快照，而是在第一次读取数据时创建快照。所以从这里，我们可以看出MVCC在RR级别和RC级别下实现的区别。需要注意的是，这个快照是个逻辑结构，依托于已经存在的undolog日志+DB_TRX_ID+DB+ROLL+PT。具体可结合下面的一致性视图来理解。 *** 一致性视图***InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在活跃的所有事务ID。“活跃”指的就是，启动了但还没有提交。数组里面事务ID的最小值标记为低水位，当前系统里面已经创建过的事务ID的最大值加1标记为高水位。视图数组和高水位，构成了当前事务的一致性视图。 ShardingJDBCshardingJdbc的分库分表原理？shardingJdbc的分布式事务怎么实现？ShardingJDBC配置事务类型: 12TransactionTypeHolder.set(TransactionType.XA);TransactionTypeHolder.set(TransactionType.BASE); 参考文档数据页； https://juejin.cn/post/6944729863550926885； https://juejin.cn/post/6985751855426977800","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/MySQL","date":"2021-10-03T05:08:02.473Z","updated":"2022-02-24T01:45:33.929Z","comments":true,"path":"2021/10/03/typora文件集合/拉钩/MySQL/","link":"","permalink":"http://example.com/2021/10/03/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/MySQL/","excerpt":"","text":"短期学习计划： 1.目标必须是具体的（Specific）： 阅读Java多线程编程核心技术，深入掌握多线程中AQS的底层原理、锁与相关API工具类的应用； 2.目标必须是可以衡量的（Measurable）： 每周输出一个工具类的架构图，并练习相应的Demo； 3.目标必须是可以达到的（Attainable）： 画出AQS中底层的ReentrantLock与CountDownLatch等API工具类的源码调用关系图，并输出笔记； 4.目标必须是要与其他目标具有一定的相关性(Relevant)： 配合完成第二阶段模块三学习：并发编程与环境优化； 5.目标必须具有明确的截止期限（Time-bound）： 圣诞节前完成； MySQL[TOC] Mysql的架构Server层 链接层负责客户端和数据库的链接，权限验证； 语法分析层对要执行的sql语句进行分析，校验是否符合sql语法规范； 优化器层对要执行的sql，生成执行计划，索引选择； 执行层具体的sql查询执行部分，有InnoDB和MyISAM两个最常用的引擎。 引擎层（InnoDB和MyISAM） InnoDB和MyISAM的区别： InnoDB支持事务，而MyISAM不支持事务； MyISAM只支持表级锁，而InnoDB是支持行级锁（默认）； InnoDB的索引文件和数据文件是一起的，而MyISAM的索引文件和数据文件是分开的。MyISAM的索引的叶子节点存放的是数据的物理地址，这样的话，即便是根据主键进行查询我们仍然需要一次磁盘的IO操作才可以拿到数据。 MyISAM不支持外键，而InnoDB支持； 是否支持MVCC； MyISAM适用于读密集型场景，比如报表等业务； Mysql的索引索引的分类：哈希表、有序数组、BST； 索引的结构：B+树索引（平衡的N叉树）。 减少树的高度，可以有效的减少对磁盘的IO操作。 主键索引（聚簇索引）；父节点存放主键数据，叶子节点存放对应行的完整的数据。 二级索引（非聚簇索引）： 父节点存放的是索引数据，叶子节点存放的是主键索引数据。这样根据二级索引进行查询的时候，会有一次根据叶子节点的主键的值重新查询一边主键索引树的操作（回表操作）。 覆盖索引：索引的叶子节点存储的正是我们查询的结果； 索引能支持最左匹配原则，是和二叉查找树的索引结构有关的：从左到右是有序的，对于联合索引，是先按照第一个字段排序，再按照第二个字段排序，以此类推； PS：在表设计的时候，不建议使用过长的字段作为主键（这样容易造成二级索引叶子节点存储占用空间大），也不建议使用非单调的字段作为主键，这样会造成主键索引频繁的分裂。数据页： 页分裂： join的优化： 驱动表为小表； 对被驱动表添加索引（在关联的字段上），不好添加索引的，可以引入中间表； MRR优化； 索引失效的场景？ 使用了like操作，且%在字符串的右侧； 对于符合索引，不满足最左匹配原则，查询的字段没有从最左边的字段开始查起； mysql 的log日志分类 binlog作用： 记录的是数据库的写入操作。有server层进行开发，所以说任何存储引擎都支持。通过追加的方式来写入。 应用场景：主从复制/数据恢复。 binlog的刷盘时机：0：不去强制要求，由系统自行判断何时写入磁盘；1：每次 commit 的时候都要将 binlog 写入磁盘；N：每N个事务，才会将 binlog 写入磁盘 格式： 2.1 statementbinlog中存放的是原始的sql语句；优点是日志占用空间小，缺点是容易造成主从同步的不一致； 2.2 row格式binlog中存放的是每一行的数据，优点是可以保证主从同步的一致，另外也便于回滚操作，缺点是日志量大； 2.3 mixed格式mysql会根据sql的语句进行分析，如果不会造成主从同步的不一致，就采用statement格式，反之则采用row格式；举例：sql中带有条件的delete、update语句容易造成主从同步的不一致，因为主库和从库在执行的时候，又可能选择了不同的索引； redolog作用： 用于崩溃恢复数据的执行。对于DML语句，mysql首先是先写到redolog中，然后返回执行结果。后续在把redolog中的日志回放写入到磁盘中； 记录形式redo log 实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。 LSN：逻辑序列号。就是上面的write pos和check point的位置。 redo log binlog 文件大小 redo log 的大小是固定的。 binlog 可通过配置参数 max_binlog_size 设置每个binlog文件的大小。 实现方式 redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。 binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志 记录方式 redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 适用场景 redo log 适用于崩溃恢复(crash-safe) binlog 适用于主从复制和数据恢复 undolog作用： 用于数据的回滚。会根据undolog中的日志回滚数据。原子性的保证，MVCC中也使用到了 relaylog作用： 中转日志。主要用于主从同步。主库会在备库第一次连接的时候，生成一个relaylog日志传递给备库，备库会启动一个io_thread线程回放这个日志到本地。 mysql的主从同步，双M结构，数据库A和数据B互为主备关系。 mySql的事务隔离级别？ACID 脏读 读到了未提交的事务修改的数据； 不可重复读 事务A对某一行记录前后两次的读取的信息不一致。 幻读 事务A对根据条件查询数据库，第一次查询出两行记录；然后另一个事务插入了一行数据，当事务A再次查询的时候，发现读取到了三条记录，这个时候就发生了幻读。 事务的隔离级别：一、 读未提交。可造成脏读、幻读、不可重复读； 二、 读已提交。可解决脏读的问题，不能解决不可重复读和幻读的问题； 三、 可重复读。可解决脏读、不可重复读的问题。但仍有可能幻读发生；（默认的，利用MVCC实现）。 四、串行化读。可解决脏读、幻读、不可重复读； 锁乐观锁和悲观锁。 乐观锁认为数据会被多个线程同时修改的，在执行sql的时候，会先给这行数据加锁，执行完之后再把锁释放； 乐观锁认为数据是不会被修改的，只是在修改的时候，回去判断下要修改的数据的是否和期望的一致，一致则允许修改，不一致则拒绝。 间隙锁（Gap Lock）锁住行的间隙，防止对数据行之间进行插入操作。这个锁可以解决幻读问题。所以我们说InnoDB默认的REPEATABLE_READ这个事务隔离级别是完全保证了事务的隔离型要求。 间隙锁和next-key lock mysql的除了DB，还在哪些业务上会被使用到？分布式锁；发号服务； 优化方式？ExplainMySQL 提供了一个 EXPLAIN 命令，它可以对 SELECT 语句进行分析，并输出 SELECT 执行的详细信 息，供开发人员有针对性的优化。 select_type表示查询的类型，常用的有：SIMPLE : 表示查询语句不包含子查询或unionPRIMARY:表示此查询是最外层的查询UNION:表示此查询是UNION的第二个或后续的查询DEPENDENT UNION:UNION中的第二个或后续的查询语句，使用了外面查询结果UNION RESULT:UNION的结果SUBQUERY:SELECT子查询语句DEPENDENT SUBQUERY:SELECT子查询语句依赖外层查询的结果。 *** type***表示存储引擎查询数据时采用的方式。通过它可以判断出查询是全表扫描还是基于索引的部分扫描。ALL:表示全表扫描，性能最差。index:表示基于索引的全表扫描，先扫描索引再扫描全表数据。range:表示使用索引范围查询。使用&gt;、&gt;=、&lt;、&lt;=、in等等。ref:表示使用非唯一索引进行单值查询。eq_ref:一般情况下出现在多表join查询，表示前面表的每一个记录，都只能匹配后面表的一 行结果。 const:表示使用主键或唯一索引做等值查询，常量查询。 NULL:表示不用访问表，速度最快。 possible_keys 表示查询时能够使用到的索引。注意并不一定会真正使用到。显示的是索引名称； key表示查询时真正使用到的索引，显示的是索引名称； rows估算SQL要查询到结果需要扫描多少行记录。 key_len 表示查询使用了索引的字节数量，可以判断是否全部使用了组合索引。 Extra表示很多额外的信息，各种操作会在Extra中提示相关信息。Using where：表示查询需要通过索引回表查询数据；Using index：表示查询通过索引，索引就可以满足所需数据；Using filesort: 表示查询出来的结果需要额外排序，数据量小在内存，大的话在磁盘。Using temprorary： 查询使用到了临时表，一半出现于去重、分组操作。 MVCC 概念：MVCC(Multi Version Concurrency Control)被称为多版本控制，是指在数据库中为了实现高并发的 数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本。 多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据库的吞吐量及读写性能。如何生成的多版本?每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号， 该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。 MVCC只在 Read Commited 和 Repeatable Read 两种隔离级别下工作 原理：用排他锁锁定该行;记录 Redo log;把该行修改前的值复制到 Undo log，即图中下面的行;修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行。 一致性读：一种读取操作，该操作使用基于某个时间点的快照信息来显示查询结果，而不介意并发中其他事务对数据进行的修改。RR事务隔离级别的就是一致性读。 *** 当前读：***读取最新的数据。==更新数据时==，先读取数据，而这个数据是当前已经提交的数据（可理解为读已提交），然后在进行数据的写入。也就是说，在执行 1insert、update、delete 操作时，会先去取下最新的数据，然后在执行DML语句。另外，select xxx for update 也是当前读。 *** 快照读：***每次读取都是基于快照来读。使用RR隔离级别时，快照基于执行第一次读取操作的时间，在RC隔离级别下，快照将重置为每次一致性读取操作的时间。也就是说，RC下，每次读取都会取最新的快照。在RR级别下，开启事务并不会创建快照，而是在第一次读取数据时创建快照。所以从这里，我们可以看出MVCC在RR级别和RC级别下实现的区别。需要注意的是，这个快照是个逻辑结构，依托于已经存在的undolog日志+DB_TRX_ID+DB+ROLL+PT。具体可结合下面的一致性视图来理解。 *** 一致性视图***InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在活跃的所有事务ID。“活跃”指的就是，启动了但还没有提交。数组里面事务ID的最小值标记为低水位，当前系统里面已经创建过的事务ID的最大值加1标记为高水位。视图数组和高水位，构成了当前事务的一致性视图。 ShardingJDBCshardingJdbc的分库分表原理？shardingJdbc的分布式事务怎么实现？ShardingJDBC配置事务类型: 12TransactionTypeHolder.set(TransactionType.XA);TransactionTypeHolder.set(TransactionType.BASE); 参考文档数据页； https://juejin.cn/post/6944729863550926885； https://juejin.cn/post/6985751855426977800","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/中间件/MySQL/MySQL","date":"2021-10-03T05:08:02.473Z","updated":"2022-02-24T01:45:51.097Z","comments":true,"path":"2021/10/03/typora文件集合/拉钩/中间件/MySQL/MySQL/","link":"","permalink":"http://example.com/2021/10/03/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E4%B8%AD%E9%97%B4%E4%BB%B6/MySQL/MySQL/","excerpt":"","text":"MySQL[TOC] Mysql的架构Server层 链接层负责客户端和数据库的链接，权限验证； 语法分析层对要执行的sql语句进行分析，校验是否符合sql语法规范； 优化器层对要执行的sql，生成执行计划，索引选择； 执行层具体的sql查询执行部分，有InnoDB和MyISAM两个最常用的引擎。 引擎层（InnoDB和MyISAM） InnoDB和MyISAM的区别： InnoDB支持事务，而MyISAM不支持事务； MyISAM只支持表级锁，而InnoDB是支持行级锁（默认）； InnoDB的索引文件和数据文件是一起的，而MyISAM的索引文件和数据文件是分开的。MyISAM的索引的叶子节点存放的是数据的物理地址，这样的话，即便是根据主键进行查询我们仍然需要一次磁盘的IO操作才可以拿到数据。 MyISAM不支持外键，而InnoDB支持； 是否支持MVCC； MyISAM适用于读密集型场景，比如报表等业务； Mysql的索引索引的分类：哈希表、有序数组、BST； 索引的结构：B+树索引（平衡的N叉树）。 减少树的高度，可以有效的减少对磁盘的IO操作。 主键索引（聚簇索引）；父节点存放主键数据，叶子节点存放对应行的完整的数据。 二级索引（非聚簇索引）： 父节点存放的是索引数据，叶子节点存放的是主键索引数据。这样根据二级索引进行查询的时候，会有一次根据叶子节点的主键的值重新查询一边主键索引树的操作（回表操作）。 覆盖索引：索引的叶子节点存储的正是我们查询的结果； 索引能支持最左匹配原则，是和二叉查找树的索引结构有关的：从左到右是有序的，对于联合索引，是先按照第一个字段排序，再按照第二个字段排序，以此类推； PS：在表设计的时候，不建议使用过长的字段作为主键（这样容易造成二级索引叶子节点存储占用空间大），也不建议使用非单调的字段作为主键，这样会造成主键索引频繁的分裂。数据页： 页分裂： join的优化： 驱动表为小表； 对被驱动表添加索引（在关联的字段上），不好添加索引的，可以引入中间表； MRR优化； 索引失效的场景？ 使用了like操作，且%在字符串的右侧； 对于符合索引，不满足最左匹配原则，查询的字段没有从最左边的字段开始查起； mysql 的log日志分类 binlog作用： 记录的是数据库的写入操作。有server层进行开发，所以说任何存储引擎都支持。通过追加的方式来写入。 应用场景：主从复制/数据恢复。 binlog的刷盘时机：0：不去强制要求，由系统自行判断何时写入磁盘；1：每次 commit 的时候都要将 binlog 写入磁盘；N：每N个事务，才会将 binlog 写入磁盘 格式： 2.1 statementbinlog中存放的是原始的sql语句；优点是日志占用空间小，缺点是容易造成主从同步的不一致； 2.2 row格式binlog中存放的是每一行的数据，优点是可以保证主从同步的一致，另外也便于回滚操作，缺点是日志量大； 2.3 mixed格式mysql会根据sql的语句进行分析，如果不会造成主从同步的不一致，就采用statement格式，反之则采用row格式；举例：sql中带有条件的delete、update语句容易造成主从同步的不一致，因为主库和从库在执行的时候，又可能选择了不同的索引； redolog作用： 用于崩溃恢复数据的执行。对于DML语句，mysql首先是先写到redolog中，然后返回执行结果。后续在把redolog中的日志回放写入到磁盘中； 记录形式redo log 实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。 LSN：逻辑序列号。就是上面的write pos和check point的位置。 redo log binlog 文件大小 redo log 的大小是固定的。 binlog 可通过配置参数 max_binlog_size 设置每个binlog文件的大小。 实现方式 redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。 binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志 记录方式 redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 适用场景 redo log 适用于崩溃恢复(crash-safe) binlog 适用于主从复制和数据恢复 undolog作用： 用于数据的回滚。会根据undolog中的日志回滚数据。原子性的保证，MVCC中也使用到了 relaylog作用： 中转日志。主要用于主从同步。主库会在备库第一次连接的时候，生成一个relaylog日志传递给备库，备库会启动一个io_thread线程回放这个日志到本地。 mysql的主从同步，双M结构，数据库A和数据B互为主备关系。 mySql的事务隔离级别？ACID 脏读 读到了未提交的事务修改的数据； 不可重复读 事务A对某一行记录前后两次的读取的信息不一致。 幻读 事务A对根据条件查询数据库，第一次查询出两行记录；然后另一个事务插入了一行数据，当事务A再次查询的时候，发现读取到了三条记录，这个时候就发生了幻读。 事务的隔离级别：一、 读未提交。可造成脏读、幻读、不可重复读； 二、 读已提交。可解决脏读的问题，不能解决不可重复读和幻读的问题； 三、 可重复读。可解决脏读、不可重复读的问题。但仍有可能幻读发生；（默认的，利用MVCC实现）。 四、串行化读。可解决脏读、幻读、不可重复读； 锁乐观锁和悲观锁。 乐观锁认为数据会被多个线程同时修改的，在执行sql的时候，会先给这行数据加锁，执行完之后再把锁释放； 乐观锁认为数据是不会被修改的，只是在修改的时候，回去判断下要修改的数据的是否和期望的一致，一致则允许修改，不一致则拒绝。 间隙锁（Gap Lock）锁住行的间隙，防止对数据行之间进行插入操作。这个锁可以解决幻读问题。所以我们说InnoDB默认的REPEATABLE_READ这个事务隔离级别是完全保证了事务的隔离型要求。 间隙锁和next-key lock mysql的除了DB，还在哪些业务上会被使用到？分布式锁；发号服务； 优化方式？ExplainMySQL 提供了一个 EXPLAIN 命令，它可以对 SELECT 语句进行分析，并输出 SELECT 执行的详细信 息，供开发人员有针对性的优化。 select_type表示查询的类型，常用的有：SIMPLE : 表示查询语句不包含子查询或unionPRIMARY:表示此查询是最外层的查询UNION:表示此查询是UNION的第二个或后续的查询DEPENDENT UNION:UNION中的第二个或后续的查询语句，使用了外面查询结果UNION RESULT:UNION的结果SUBQUERY:SELECT子查询语句DEPENDENT SUBQUERY:SELECT子查询语句依赖外层查询的结果。 *** type***表示存储引擎查询数据时采用的方式。通过它可以判断出查询是全表扫描还是基于索引的部分扫描。ALL:表示全表扫描，性能最差。index:表示基于索引的全表扫描，先扫描索引再扫描全表数据。range:表示使用索引范围查询。使用&gt;、&gt;=、&lt;、&lt;=、in等等。ref:表示使用非唯一索引进行单值查询。eq_ref:一般情况下出现在多表join查询，表示前面表的每一个记录，都只能匹配后面表的一 行结果。 const:表示使用主键或唯一索引做等值查询，常量查询。 NULL:表示不用访问表，速度最快。 possible_keys 表示查询时能够使用到的索引。注意并不一定会真正使用到。显示的是索引名称； key表示查询时真正使用到的索引，显示的是索引名称； rows估算SQL要查询到结果需要扫描多少行记录。 key_len 表示查询使用了索引的字节数量，可以判断是否全部使用了组合索引。 Extra表示很多额外的信息，各种操作会在Extra中提示相关信息。Using where：表示查询需要通过索引回表查询数据；Using index：表示查询通过索引，索引就可以满足所需数据；Using filesort: 表示查询出来的结果需要额外排序，数据量小在内存，大的话在磁盘。Using temprorary： 查询使用到了临时表，一半出现于去重、分组操作。 MVCC 概念：MVCC(Multi Version Concurrency Control)被称为多版本控制，是指在数据库中为了实现高并发的 数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本。 多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据库的吞吐量及读写性能。如何生成的多版本?每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号， 该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。 MVCC只在 Read Commited 和 Repeatable Read 两种隔离级别下工作 原理：用排他锁锁定该行;记录 Redo log;把该行修改前的值复制到 Undo log，即图中下面的行;修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行。 一致性读：一种读取操作，该操作使用基于某个时间点的快照信息来显示查询结果，而不介意并发中其他事务对数据进行的修改。RR事务隔离级别的就是一致性读。 *** 当前读：***读取最新的数据。==更新数据时==，先读取数据，而这个数据是当前已经提交的数据（可理解为读已提交），然后在进行数据的写入。也就是说，在执行 1insert、update、delete 操作时，会先去取下最新的数据，然后在执行DML语句。另外，select xxx for update 也是当前读。 *** 快照读：***每次读取都是基于快照来读。使用RR隔离级别时，快照基于执行第一次读取操作的时间，在RC隔离级别下，快照将重置为每次一致性读取操作的时间。也就是说，RC下，每次读取都会取最新的快照。在RR级别下，开启事务并不会创建快照，而是在第一次读取数据时创建快照。所以从这里，我们可以看出MVCC在RR级别和RC级别下实现的区别。需要注意的是，这个快照是个逻辑结构，依托于已经存在的undolog日志+DB_TRX_ID+DB+ROLL+PT。具体可结合下面的一致性视图来理解。 *** 一致性视图***InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在活跃的所有事务ID。“活跃”指的就是，启动了但还没有提交。数组里面事务ID的最小值标记为低水位，当前系统里面已经创建过的事务ID的最大值加1标记为高水位。视图数组和高水位，构成了当前事务的一致性视图。 ShardingJDBCshardingJdbc的分库分表原理？shardingJdbc的分布式事务怎么实现？ShardingJDBC配置事务类型: 12TransactionTypeHolder.set(TransactionType.XA);TransactionTypeHolder.set(TransactionType.BASE); 参考文档数据页； https://juejin.cn/post/6944729863550926885； https://juejin.cn/post/6985751855426977800","categories":[],"tags":[]},{"title":"","slug":"假期作业","date":"2021-10-02T09:50:47.688Z","updated":"2022-02-20T10:36:23.466Z","comments":true,"path":"2021/10/02/假期作业/","link":"","permalink":"http://example.com/2021/10/02/%E5%81%87%E6%9C%9F%E4%BD%9C%E4%B8%9A/","excerpt":"","text":"对于一个问题，加入依赖的下游服务出现大面积的超时，报错，这个时候我们要保持自己的系统的高可用性该怎么做呢？这个问题应该从服务的降级和熔断去思考，当依赖的下游服务不可用的时候，连续几次调用都出现失败或者超时，就启动熔断机制，后续的请求走本地的默认逻辑，不再调用下游的服务。 算法： B+树的叶子节点链表结构相比于B-树便于扫库和范围查找； B+树支持range-query（区间查询）非常方便，而B树不支持。这个是数据库选用B+树的最主要原因； B*树是B+树的变体， B * 树分配新节点的概率比B+树要低，空间使用率更高； B+适用于读多写少的场景，而LSM（日志结构合并树）更适合用写多读少的场景。B+树最大的性能问题是会产生大量的随机IO。 B树相关介绍 JVM我觉得，可以从编写一行代码，到这行代码最终被执行出来的过程说。写代码、编译成字节码、编译成指令、运行期间（运行时内存划分、线程模型划分）。 不用说1 2 3 4点这样的细节。比如你说gcRoots时候，为了解决gcRoots性能问题，引用了缓存，并且是在写屏障里去维护gcRoots缓存。 首先整个JVM的内存分配可以分堆（元空间）和非堆\u0010。非堆是线程相隔离的，堆（元空间）是线程共享的。堆中存放着实际运行中的对象的数据，方法区（元空间）则是存放class文件、静态变量、运行时常量池信息等。然后其他的部分（栈、程序计数器）则是具体的指令的运行的地方，不同的线程对应的栈桢和计数器都是不一样的。然后堆内部细分为Eden区、from/to区、old区（需要具体到垃圾回收器）。 我们写的代码最终都会被JIT编译为class文件。这个文件是按照一定的格式来输出的，比如魔数、大小版本号、常量池信息等，然后JVM通过字节码指令（比如加载存储指令、运行指令）来执行生成的class文件，把这个class文件生成对应的二进制流，调用底层的OS指令集来运行。这个过程非常的复杂，我们可以想象大致牵涉到class文件的加载、内存分配、执行、垃圾回收（因为JVM是自动进行垃圾回收的）。整个类加载过程涉及加载（加载二进制流进内存，最终的目的是生成对应的class对象）、验证（验证class文件是否合法，确保后续的操作没有问题）、准备（给静态变量赋初始值）、解析（把==常量池中的符号引用==替换为直接引用）、初始化（对成员变量和静态语句块中的变量进行初始化操作），加载是有对应的类加载器完成的，Java的加载机制是双亲委派模型（也会被打破）。内存分配部分就是根据代码划分具体的内存用以存储对class文件对应的对象的信息。具体的内存分配是和线程相关的，会伴随着GC的运行。常用的内存分配策略由指针碰撞、空闲列表两种方式。JAVA中生成的对象主要由对象头（Mark World+KClassPointer+数组长度）、实例数据和对象填充三部分组成。其中KClassPointer会利用到指针压缩功能以最大化的利用内存。具体的分配会先判断是不是可以在栈上分配，不行的话再判断是不是大对象，是大对象就会优先在老年代中进行分配。分配好以后，通过字节码执行引擎进行执行，然后JVM是一个基于栈指令集的执行引擎。线程的执行都是在栈上进行执行的，栈上的局部变量表中的变量会引用堆上的对象地址。在栈中分配的内存会随栈出栈而自行的销毁。但是引用的堆上的数据就不一定了。执行的过程中JVM会通过可达性分析算法，监控可以被回收的内存区域（堆上）。统计GCRoot，然后根据GCRoot找到引用的对象，进而确定不能被销毁的对象。实现方式OopMap+卡表。回收是通过垃圾回收器进行回收的，常用的垃圾收集算法有：标记清除算法、标记复制算法、标记整理算法。常用的垃圾收集器有CMS、Serial、Serial Old、ParNew、G1等，不同的收集器的区别在于采用了不同的垃圾收集算法与内存分配策略。 请你描述什么是垃圾回收？ 由于Java程序是一款不需要程序员手动进行内存管理的语言，所以需要自动进行内存的管理，这个操作是有JDK中的垃圾收集器完成的。JVM的内存区域大致可以划分为堆、方法区、虚拟机栈、本地方法栈、程序计数器几个部分，其中堆和方法区是线程共享的区域，栈和程序计数器是线程隔离的区域。 我们常说的垃圾回收通常意义上是指对堆内存的回收。Java中几乎所有的对象的实例都在堆上进行分配的。现代垃圾回收器大部分是基于分代收集理论的。即弱分代假说：绝大多数对象都是朝生夕灭的；强分代假说：熬过越多次垃圾回收过程的对象就越难以消亡。 基于上述的假说，多款垃圾收集器（Serial、CMS等）将Java堆划分为不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储。比如，G1收集器之前，垃圾收集器都是按照新生代、老年代细分的。但是这个仅是部分垃圾收集器的一种设计风格，而非Java虚拟机具体实现的固有内存布局。 常用的垃圾收集算法有标记-清除、标记-复制、标记-整理。这三个算法各有自己的优点， 标记-清除算法是最基础的算法，其余的算法都是基于这个算法并对这个算法的优化。标记清除算法实现简单，但是容易产生内存碎片。 标记-复制算法是将内存划分为大小相等的两块，每次只使用其中的一块，当这块的内存使用完了，就讲还存活的对象复制到另外一块上面，然后再把使用的内存清理掉。这个策略的使用的背景是，绝大多数对象都是朝生夕灭的。所以在Serial、ParNew等新生代垃圾收集器均采用了这种策略来设计新生代的内存布局：把新生代划分为Eden区+两个比较小的Survivor空间。 标记过程和“标记-清除”算法一样，但是不是直接对可回收的对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。这个可以提高系统的吞吐量。 标记-清除算法和标记-整理算法各有各的优点。关注吞吐量的一般使用标记-整理算法，比如Parallel Scavenge收集器；关注延迟的使用标记-清除算法，比如CMS收集器。而新生代使用的一般是标记-复制算法。 垃圾回收算法本质上是找到存活的对象，这个有两种方式，一种是引用计数方式，一种是可达性分析。现代垃圾收集器采用的是第二种。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/假期作业","date":"2021-10-02T09:50:47.688Z","updated":"2022-02-20T10:36:23.466Z","comments":true,"path":"2021/10/02/typora文件集合/拉钩/假期作业/","link":"","permalink":"http://example.com/2021/10/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%81%87%E6%9C%9F%E4%BD%9C%E4%B8%9A/","excerpt":"","text":"对于一个问题，加入依赖的下游服务出现大面积的超时，报错，这个时候我们要保持自己的系统的高可用性该怎么做呢？这个问题应该从服务的降级和熔断去思考，当依赖的下游服务不可用的时候，连续几次调用都出现失败或者超时，就启动熔断机制，后续的请求走本地的默认逻辑，不再调用下游的服务。 算法： B+树的叶子节点链表结构相比于B-树便于扫库和范围查找； B+树支持range-query（区间查询）非常方便，而B树不支持。这个是数据库选用B+树的最主要原因； B*树是B+树的变体， B * 树分配新节点的概率比B+树要低，空间使用率更高； B+适用于读多写少的场景，而LSM（日志结构合并树）更适合用写多读少的场景。B+树最大的性能问题是会产生大量的随机IO。 B树相关介绍 JVM我觉得，可以从编写一行代码，到这行代码最终被执行出来的过程说。写代码、编译成字节码、编译成指令、运行期间（运行时内存划分、线程模型划分）。 不用说1 2 3 4点这样的细节。比如你说gcRoots时候，为了解决gcRoots性能问题，引用了缓存，并且是在写屏障里去维护gcRoots缓存。 首先整个JVM的内存分配可以分堆（元空间）和非堆\u0010。非堆是线程相隔离的，堆（元空间）是线程共享的。堆中存放着实际运行中的对象的数据，方法区（元空间）则是存放class文件、静态变量、运行时常量池信息等。然后其他的部分（栈、程序计数器）则是具体的指令的运行的地方，不同的线程对应的栈桢和计数器都是不一样的。然后堆内部细分为Eden区、from/to区、old区（需要具体到垃圾回收器）。 我们写的代码最终都会被JIT编译为class文件。这个文件是按照一定的格式来输出的，比如魔数、大小版本号、常量池信息等，然后JVM通过字节码指令（比如加载存储指令、运行指令）来执行生成的class文件，把这个class文件生成对应的二进制流，调用底层的OS指令集来运行。这个过程非常的复杂，我们可以想象大致牵涉到class文件的加载、内存分配、执行、垃圾回收（因为JVM是自动进行垃圾回收的）。整个类加载过程涉及加载（加载二进制流进内存，最终的目的是生成对应的class对象）、验证（验证class文件是否合法，确保后续的操作没有问题）、准备（给静态变量赋初始值）、解析（把==常量池中的符号引用==替换为直接引用）、初始化（对成员变量和静态语句块中的变量进行初始化操作），加载是有对应的类加载器完成的，Java的加载机制是双亲委派模型（也会被打破）。内存分配部分就是根据代码划分具体的内存用以存储对class文件对应的对象的信息。具体的内存分配是和线程相关的，会伴随着GC的运行。常用的内存分配策略由指针碰撞、空闲列表两种方式。JAVA中生成的对象主要由对象头（Mark World+KClassPointer+数组长度）、实例数据和对象填充三部分组成。其中KClassPointer会利用到指针压缩功能以最大化的利用内存。具体的分配会先判断是不是可以在栈上分配，不行的话再判断是不是大对象，是大对象就会优先在老年代中进行分配。分配好以后，通过字节码执行引擎进行执行，然后JVM是一个基于栈指令集的执行引擎。线程的执行都是在栈上进行执行的，栈上的局部变量表中的变量会引用堆上的对象地址。在栈中分配的内存会随栈出栈而自行的销毁。但是引用的堆上的数据就不一定了。执行的过程中JVM会通过可达性分析算法，监控可以被回收的内存区域（堆上）。统计GCRoot，然后根据GCRoot找到引用的对象，进而确定不能被销毁的对象。实现方式OopMap+卡表。回收是通过垃圾回收器进行回收的，常用的垃圾收集算法有：标记清除算法、标记复制算法、标记整理算法。常用的垃圾收集器有CMS、Serial、Serial Old、ParNew、G1等，不同的收集器的区别在于采用了不同的垃圾收集算法与内存分配策略。 请你描述什么是垃圾回收？ 由于Java程序是一款不需要程序员手动进行内存管理的语言，所以需要自动进行内存的管理，这个操作是有JDK中的垃圾收集器完成的。JVM的内存区域大致可以划分为堆、方法区、虚拟机栈、本地方法栈、程序计数器几个部分，其中堆和方法区是线程共享的区域，栈和程序计数器是线程隔离的区域。 我们常说的垃圾回收通常意义上是指对堆内存的回收。Java中几乎所有的对象的实例都在堆上进行分配的。现代垃圾回收器大部分是基于分代收集理论的。即弱分代假说：绝大多数对象都是朝生夕灭的；强分代假说：熬过越多次垃圾回收过程的对象就越难以消亡。 基于上述的假说，多款垃圾收集器（Serial、CMS等）将Java堆划分为不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储。比如，G1收集器之前，垃圾收集器都是按照新生代、老年代细分的。但是这个仅是部分垃圾收集器的一种设计风格，而非Java虚拟机具体实现的固有内存布局。 常用的垃圾收集算法有标记-清除、标记-复制、标记-整理。这三个算法各有自己的优点， 标记-清除算法是最基础的算法，其余的算法都是基于这个算法并对这个算法的优化。标记清除算法实现简单，但是容易产生内存碎片。 标记-复制算法是将内存划分为大小相等的两块，每次只使用其中的一块，当这块的内存使用完了，就讲还存活的对象复制到另外一块上面，然后再把使用的内存清理掉。这个策略的使用的背景是，绝大多数对象都是朝生夕灭的。所以在Serial、ParNew等新生代垃圾收集器均采用了这种策略来设计新生代的内存布局：把新生代划分为Eden区+两个比较小的Survivor空间。 标记过程和“标记-清除”算法一样，但是不是直接对可回收的对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。这个可以提高系统的吞吐量。 标记-清除算法和标记-整理算法各有各的优点。关注吞吐量的一般使用标记-整理算法，比如Parallel Scavenge收集器；关注延迟的使用标记-清除算法，比如CMS收集器。而新生代使用的一般是标记-复制算法。 垃圾回收算法本质上是找到存活的对象，这个有两种方式，一种是引用计数方式，一种是可达性分析。现代垃圾收集器采用的是第二种。","categories":[],"tags":[]},{"title":"","slug":"多线程","date":"2021-10-01T22:08:17.376Z","updated":"2021-12-12T09:48:40.458Z","comments":true,"path":"2021/10/02/多线程/","link":"","permalink":"http://example.com/2021/10/02/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"[TOC] 多线程和锁多线程的目的：充分利用多核CPU的并行处理的能力，加快程序的处理速度； 锁的存在的意义：控制资源的并发访问，使操作串行话； JUC相关的（AQS）AQS是一个用来构建锁合同步器的框架。 原理：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占有，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列实现的，即将暂时获取不到锁的线程加入到队列中。 CLH队列：是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点来实现锁的分配。 两种资源共享方式： Exclusive：公平锁和非公平锁。 Share： 锁相关 锁（Synchronized、ReentrantLock的区别）、MarkWord Synchronized、ReentrantLock的区别 两者都是可重入锁，什么是可重入锁？已获得锁的对象，可以再次获取锁； Synchronized是JVM实现的，使用起来简单；ReentrantLock是一个Java提供的API，比较灵活； Synchronized是非公平锁，ReentrantLock可以提供非公平锁和公平锁两种，利用fair参数可以控制； 都提供了等待、通知机制； Synchronized是利用了Obejct对象的notify和wait方法； ReentrantLock需要借助于condition、newCondition方法 ReentrantLock提供了中断等待机制；lock.lockInterruptibly() Java对象头的结构： MarkWord ：存储对象的hashcode、分代年龄、gc标记、同步状态、锁标志位等 kClassPointer：对象的类型指针，指向类元数据（类class文件信息，metaspace空间的方法区） Synchronized的优化&amp;Mark word 的结构 2.1 无锁（01），所有线程均可以修改某一个资源的值，但同时只能由一个线程修改成功，其他会循环尝试；2.2 偏向锁（01）：在对象头MarkWord中存放有对应的线程的id，如果发现请求线程是同一个的话，再次请求的时候，直接获取锁；偏向锁的一个撤销 ：全局安全点（没有字节码在执行），暂停拥有偏向锁的线程，并判断对象是否处于被锁定的状态，如果没有的话，则把对象置为无锁状态，并撤销偏向锁，恢复到无锁或者轻量级锁状态；2.3 轻量级锁（00）：如果在偏向锁的过程中，有其他的线程进行请求的话，就会转化为轻量级锁，或者是关闭偏向锁功能的时候（即2.2种描述的）。线程的栈帧中有一个Lock record的区域，拷贝一份Mark word到这个区域。线程会通过CAS操作，尝试讲Mark word 更新为这个栈帧中锁记录的指针，同时，LockRecord 中的owner指针也会指向Mark word。更新成功，线程就拥有对象的锁。如果CAS失败，判断Mark word是否指向当前线程的指针，是的话，就直接进入同步代码块继续执行。 另一个线程会自旋，当自旋超过一定次数之后，会膨胀为重量级锁。（自适应自旋）；另一个升级为重量级锁的原因是这个时候有另外的线程来争抢对象的锁；2.4 重量级锁（10）：每一个对象都有一个ObjectMonitor锁对象。重量级锁的时候，mark word中存储的是这个monitor锁的指针，另外monitor中，有一个owner指针，指向拥有锁的线程。ObjectMonitor对象内部结构：entryList： 在进入或者重新进入时被阻塞的线程；waitSet：在改Monitor上等待的线程；owner： monitor的所有者（线程）；这个monitor里面表示count（计数器），用于CAS操作。一次CAS操作成功，owner就会置换为指向对应最线程的指针；利用Mutex Lock这个系统提供的来实现，来进行加锁，缺点：需要从内核态切换到用户态，比较消耗性能； 同时，每一个线程都有一个monitor record列表。 2.5 GC标记（11） 如何避免线程死锁？ 线程死锁的四个条件： 互斥条件： 改资源任一时刻只能由一个线程占有； 请求与保持条件： 一个线程因请求资源而阻塞时，对已获得资源保持不放； 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕之后才能释放资源； 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系； 破坏死锁的话，需要从2至4三个点来进行考虑。 一次申请所有资源； 占用部分资源的线程进一步申请其他资源失败时，可以主动释放掉自己占有的资源； 按照某一个顺序申请资源，释放的时候，反序释放； 线程池：常用的线程池；优缺点；常用参数 常用线程池： 12345678910111213//创建一个固定大小（核心线程数、最大线程数）的线程池，队列是LinkedBlockingQueue。缺点：容易造成OOM；ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);//核心线程数是0，最大线程数是Integer.MAX_VALUE，队列是SynchronousQueue的线程池。SynchronousQueue不进行线程的保存，直接进行转发。容易造成OOM；ExecutorService cachedThreadPool = Executors.newCachedThreadPool();//核心线程是是1个、最大线程是1个，队列是LinkedBlockingQueue（无限大）的线程池，容易造成OOM；ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor();//核心线程数固定大小的延迟执行的一个线程池，最大线程池大小是Integer.MAX_VALUE,队列是延迟队列：DelayedWorkQueue。缺点：容易造成OOM；Executors.newScheduledThreadPool(5);//自定义线程池,IO密集型和CPU密集型的区别int coreThreads = 10;int maxThreads = 100;ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(coreThreads, maxThreads,0L, TimeUnit.MILLISECONDS,new ArrayBlockingQueue(500)); 建议的方法：自定义一个线程池: 线程池的执行流程 其他什么事OOM？如何理解？怎么排查OOM？内存泄漏和OOM的区别？见JVM。 队列&amp;常用多线程工具 ForkJoin 队列 上下文切换，Linux操作系统的上下文切换时间为什么很少？零拷贝。 零拷贝技术，sendfile！只需要2次切换、2次拷贝 mmap技术： 4次切换、3次拷贝 ThreadLocal ThreadLocalMap是ThreadLocal的静态内部类 内存泄漏： ThreadLocalMap中key为ThreadLocal的弱引用，而value是强引用。所以，如果ThreadLocal没有被引用的话，在gc时，key会被清理掉，而value不会。 那么这个时候，就会出现key为null的entry，发生内存泄漏。解决方法：手动调用remove方法，看源码可以发现，在执行set、get方法之后，顺便把路上无效的entry用线性清扫清除掉，也可以起到一定的解决内存泄漏的问题。但是get、set方法发起无效key的清理都是有触发条件的，一般都是发现key匹配不到， set方法： 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&#x27;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; get 方法： 12345678910111213141516171819202122232425262728293031323334private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;/** * Version of getEntry method for use when key is not found in * its direct hash slot. * * @param key the thread local object * @param i the table index for key&#x27;s hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; get、set方法是否确定可以解决内存泄漏问题？，这个看了，感觉因该是可以的，只不过是在特定的条件下。 JMM 内存模型JMM与happen-beforeL1、L2、L3和主内存之间是同步的，有缓存一致性MESI协议的保证，但是Store Buffer、Load Buffer和L1之间却是异步的。内存中写入一个变量，这个变量会保存在Store Buffer中，稍后才异步的写入L1中，同时同步写入主内存中。 重排序与内存可见性的关系：Store Buffer的延迟写入是重排序的一种，我们称之为内存重排序（Memory Ordering）。除此之外，还有编译器和CPU指令的重排序。 重排序类型： 编译器重排序：对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序； CPU指令重排序：在指令级别，让没有依赖关系的多条执行并行； CPU内存重排序：CPU有自己的缓存，指令的执行顺序和写入主内存的顺序不完全一致。 PS：第三种重排序是造成内存可见性问题的主因； 内存屏障：为了禁止编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令，也就是内存屏障（Memory Barrier）。这也正是JMM和happen-before规则的底层实现原理。 四种CPU内存屏障： LoadLoad：禁止读和读的重排序； StoreStore：禁止写和写的重排序； LoadStore：禁止读和写的重排序； StoreLoad：禁止写和读的重排序； As-if-serial语义： 只要操作之间没有数据的依赖性，编译器和CPU都可以任意重排序，因为执行结果不会改变，代码看起来像是完全串行地一行一行从头执行到尾，这也就是as-if-serial语义。 编译器和CPU只能保证每一个线程的as-if-serial语义。线程之间的数据依赖和影响，需要编译器和CPU的上层来确定。 happen-before定义：描述了两个操作之间的内存可见性。 如果A happen before B，意味着A的执行结果必须对B可见，也就是保证跨线程的内存可见性。 A happen before B不代表A一定能在B之前执行，只确保如果A在B之前执行，则A的执行结果必须对B可见。JMM对开发者作出的一系列的承诺： 单线程中的每个操作，happen-before 对应线程中任意后续的操作（as-if-serial语义保证）； 对volatile变量的写入，happen-before对应后续对这个变量的读取； 对synchronized的解锁，happen-before对应后续对这个锁的加锁； 对final变量的写，happen-before于final域对象的读，happen-before于后续对final变量的读； volatilevolatile的三重功效：64位写入的原子性保障、内存可见性、禁止重排序； 实现原理：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/多线程","date":"2021-10-01T22:08:17.376Z","updated":"2021-12-12T09:48:40.458Z","comments":true,"path":"2021/10/02/typora文件集合/拉钩/多线程/","link":"","permalink":"http://example.com/2021/10/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"[TOC] 多线程和锁多线程的目的：充分利用多核CPU的并行处理的能力，加快程序的处理速度； 锁的存在的意义：控制资源的并发访问，使操作串行话； JUC相关的（AQS）AQS是一个用来构建锁合同步器的框架。 原理：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占有，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列实现的，即将暂时获取不到锁的线程加入到队列中。 CLH队列：是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点来实现锁的分配。 两种资源共享方式： Exclusive：公平锁和非公平锁。 Share： 锁相关 锁（Synchronized、ReentrantLock的区别）、MarkWord Synchronized、ReentrantLock的区别 两者都是可重入锁，什么是可重入锁？已获得锁的对象，可以再次获取锁； Synchronized是JVM实现的，使用起来简单；ReentrantLock是一个Java提供的API，比较灵活； Synchronized是非公平锁，ReentrantLock可以提供非公平锁和公平锁两种，利用fair参数可以控制； 都提供了等待、通知机制； Synchronized是利用了Obejct对象的notify和wait方法； ReentrantLock需要借助于condition、newCondition方法 ReentrantLock提供了中断等待机制；lock.lockInterruptibly() Java对象头的结构： MarkWord ：存储对象的hashcode、分代年龄、gc标记、同步状态、锁标志位等 kClassPointer：对象的类型指针，指向类元数据（类class文件信息，metaspace空间的方法区） Synchronized的优化&amp;Mark word 的结构 2.1 无锁（01），所有线程均可以修改某一个资源的值，但同时只能由一个线程修改成功，其他会循环尝试；2.2 偏向锁（01）：在对象头MarkWord中存放有对应的线程的id，如果发现请求线程是同一个的话，再次请求的时候，直接获取锁；偏向锁的一个撤销 ：全局安全点（没有字节码在执行），暂停拥有偏向锁的线程，并判断对象是否处于被锁定的状态，如果没有的话，则把对象置为无锁状态，并撤销偏向锁，恢复到无锁或者轻量级锁状态；2.3 轻量级锁（00）：如果在偏向锁的过程中，有其他的线程进行请求的话，就会转化为轻量级锁，或者是关闭偏向锁功能的时候（即2.2种描述的）。线程的栈帧中有一个Lock record的区域，拷贝一份Mark word到这个区域。线程会通过CAS操作，尝试讲Mark word 更新为这个栈帧中锁记录的指针，同时，LockRecord 中的owner指针也会指向Mark word。更新成功，线程就拥有对象的锁。如果CAS失败，判断Mark word是否指向当前线程的指针，是的话，就直接进入同步代码块继续执行。 另一个线程会自旋，当自旋超过一定次数之后，会膨胀为重量级锁。（自适应自旋）；另一个升级为重量级锁的原因是这个时候有另外的线程来争抢对象的锁；2.4 重量级锁（10）：每一个对象都有一个ObjectMonitor锁对象。重量级锁的时候，mark word中存储的是这个monitor锁的指针，另外monitor中，有一个owner指针，指向拥有锁的线程。ObjectMonitor对象内部结构：entryList： 在进入或者重新进入时被阻塞的线程；waitSet：在改Monitor上等待的线程；owner： monitor的所有者（线程）；这个monitor里面表示count（计数器），用于CAS操作。一次CAS操作成功，owner就会置换为指向对应最线程的指针；利用Mutex Lock这个系统提供的来实现，来进行加锁，缺点：需要从内核态切换到用户态，比较消耗性能； 同时，每一个线程都有一个monitor record列表。 2.5 GC标记（11） 如何避免线程死锁？ 线程死锁的四个条件： 互斥条件： 改资源任一时刻只能由一个线程占有； 请求与保持条件： 一个线程因请求资源而阻塞时，对已获得资源保持不放； 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕之后才能释放资源； 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系； 破坏死锁的话，需要从2至4三个点来进行考虑。 一次申请所有资源； 占用部分资源的线程进一步申请其他资源失败时，可以主动释放掉自己占有的资源； 按照某一个顺序申请资源，释放的时候，反序释放； 线程池：常用的线程池；优缺点；常用参数 常用线程池： 12345678910111213//创建一个固定大小（核心线程数、最大线程数）的线程池，队列是LinkedBlockingQueue。缺点：容易造成OOM；ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);//核心线程数是0，最大线程数是Integer.MAX_VALUE，队列是SynchronousQueue的线程池。SynchronousQueue不进行线程的保存，直接进行转发。容易造成OOM；ExecutorService cachedThreadPool = Executors.newCachedThreadPool();//核心线程是是1个、最大线程是1个，队列是LinkedBlockingQueue（无限大）的线程池，容易造成OOM；ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor();//核心线程数固定大小的延迟执行的一个线程池，最大线程池大小是Integer.MAX_VALUE,队列是延迟队列：DelayedWorkQueue。缺点：容易造成OOM；Executors.newScheduledThreadPool(5);//自定义线程池,IO密集型和CPU密集型的区别int coreThreads = 10;int maxThreads = 100;ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(coreThreads, maxThreads,0L, TimeUnit.MILLISECONDS,new ArrayBlockingQueue(500)); 建议的方法：自定义一个线程池: 线程池的执行流程 其他什么事OOM？如何理解？怎么排查OOM？内存泄漏和OOM的区别？见JVM。 队列&amp;常用多线程工具 ForkJoin 队列 上下文切换，Linux操作系统的上下文切换时间为什么很少？零拷贝。 零拷贝技术，sendfile！只需要2次切换、2次拷贝 mmap技术： 4次切换、3次拷贝 ThreadLocal ThreadLocalMap是ThreadLocal的静态内部类 内存泄漏： ThreadLocalMap中key为ThreadLocal的弱引用，而value是强引用。所以，如果ThreadLocal没有被引用的话，在gc时，key会被清理掉，而value不会。 那么这个时候，就会出现key为null的entry，发生内存泄漏。解决方法：手动调用remove方法，看源码可以发现，在执行set、get方法之后，顺便把路上无效的entry用线性清扫清除掉，也可以起到一定的解决内存泄漏的问题。但是get、set方法发起无效key的清理都是有触发条件的，一般都是发现key匹配不到， set方法： 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&#x27;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; get 方法： 12345678910111213141516171819202122232425262728293031323334private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;/** * Version of getEntry method for use when key is not found in * its direct hash slot. * * @param key the thread local object * @param i the table index for key&#x27;s hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; get、set方法是否确定可以解决内存泄漏问题？，这个看了，感觉因该是可以的，只不过是在特定的条件下。 JMM 内存模型JMM与happen-beforeL1、L2、L3和主内存之间是同步的，有缓存一致性MESI协议的保证，但是Store Buffer、Load Buffer和L1之间却是异步的。内存中写入一个变量，这个变量会保存在Store Buffer中，稍后才异步的写入L1中，同时同步写入主内存中。 重排序与内存可见性的关系：Store Buffer的延迟写入是重排序的一种，我们称之为内存重排序（Memory Ordering）。除此之外，还有编译器和CPU指令的重排序。 重排序类型： 编译器重排序：对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序； CPU指令重排序：在指令级别，让没有依赖关系的多条执行并行； CPU内存重排序：CPU有自己的缓存，指令的执行顺序和写入主内存的顺序不完全一致。 PS：第三种重排序是造成内存可见性问题的主因； 内存屏障：为了禁止编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令，也就是内存屏障（Memory Barrier）。这也正是JMM和happen-before规则的底层实现原理。 四种CPU内存屏障： LoadLoad：禁止读和读的重排序； StoreStore：禁止写和写的重排序； LoadStore：禁止读和写的重排序； StoreLoad：禁止写和读的重排序； As-if-serial语义： 只要操作之间没有数据的依赖性，编译器和CPU都可以任意重排序，因为执行结果不会改变，代码看起来像是完全串行地一行一行从头执行到尾，这也就是as-if-serial语义。 编译器和CPU只能保证每一个线程的as-if-serial语义。线程之间的数据依赖和影响，需要编译器和CPU的上层来确定。 happen-before定义：描述了两个操作之间的内存可见性。 如果A happen before B，意味着A的执行结果必须对B可见，也就是保证跨线程的内存可见性。 A happen before B不代表A一定能在B之前执行，只确保如果A在B之前执行，则A的执行结果必须对B可见。JMM对开发者作出的一系列的承诺： 单线程中的每个操作，happen-before 对应线程中任意后续的操作（as-if-serial语义保证）； 对volatile变量的写入，happen-before对应后续对这个变量的读取； 对synchronized的解锁，happen-before对应后续对这个锁的加锁； 对final变量的写，happen-before于final域对象的读，happen-before于后续对final变量的读； volatilevolatile的三重功效：64位写入的原子性保障、内存可见性、禁止重排序； 实现原理：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/BST","date":"2021-10-01T13:42:20.500Z","updated":"2022-01-07T06:55:04.092Z","comments":true,"path":"2021/10/01/typora文件集合/技术/技术笔记/源码/BST/","link":"","permalink":"http://example.com/2021/10/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/BST/","excerpt":"","text":"[TOC] 什么是BST？1. BST（Binary Search Tree ）二叉查找树。特性: 左子树上所有节点的值均小于或等于它的根节点的值 右子树上所有节点的值均大于或等于它的根节点的值； 左、右子树也分别为二叉排序树； 缺点：在插入某些数据的时候，会变成一个线性的结构； 2. 红黑树（Red Black Tree）是一种自平衡的二叉查找树。除了符合二叉查找树的基本特征外，他还具有以下的特性： 节点是红色或黑色； 根节点是黑色； 每个叶子节点都是黑色的空节点（NIL节点）； 每个红色节点的两个子节点都是黑色。（从每个叶子到根的所有路径上不能有两个连续的红色节点）； 从任一节点到其每个叶子节点的所有路径都包含相同数目的黑色节点(每个节点到其的所有叶子节点经过相同数目的黑色节点)：这个数量被称为这个节点的==黑高== 红黑树保证了从根节点到叶子节点的最长路径不会超过最短路径的2倍； 删除或插入节点的时候，红黑树的规则有可能被打破，这个时候就需要做出一些调整，来维持这些规则； 常规操作旋转 什么是左旋？左旋是将某个节点旋转为其右节点的左孩子； 什么是右旋？右旋是将某个节点旋转为其左节点的右孩子；我们以一个例子来进行说明： 插入由红黑树的性质5可知，插入的节点需要是==红色==的。但是这样的话有可能会出现两个连续的红色节点的情况，这时就需要通过变色和旋转来进行调整。 删除参考博文 https://juejin.cn/post/6844903519632228365 https://www.tianxiaobo.com/2018/01/11/红黑树详细分析/ PS： 3.红黑树（对称二叉B树，B-树），B+树的区别：\u0010区别： 左侧是B树（又称B-树），右侧是B+树。 B+ 树中只有叶子结点会带有指向记录的指针，而B树中则所有结点都带有，在内部结点出现的索引项不会再出现在叶子结点中，而B+树则是叶子结点含有所有索引项； B+树中所有叶子结点都是通过指针连接在一起，而B树不会。 B+树的优点： 非叶子结点不会带上指向记录的指针，一个块中可以容纳更多的索引项：一是可以降低树的高度，二是内部结点可以定位更多的叶子结点； 叶子结点之间通过指针来连接，范围查询十分简单。而对于B树来说，则需要在叶子结点和内部结点之间不停的往返移动，需要进行中序遍历； B树的优点：对于在内部结点的数据，可以直接得到，不必根据叶子结点来定位。B树结构： AVL树（平衡二叉树）定义： 左右子树的高度差小于等于1； 其每一个子树均为平衡二叉树； 时间复杂度为O(log n),空间复杂度为O(n)。 红黑树和B+树的区别？ 红黑树多用在内部排序上，即全放在内存中，java中的HashMap与Set等； B+树多用于外存上，比如数据库索引。是一个磁盘友好的数据结构。 为什么B+树对磁盘友好呢？ 磁盘读写代价更低。树的非叶子结点里面没有数据，这样索引比较小，可以放在一个block里面。避免了树形结构不断的向下查找，然后磁盘不停的寻道，读数据。这样的设计，可以降低io的次数。 查询效率更加稳定非终点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以关键字的查找必须走一条从根结点到叶子结点的路。所有关键字的查询的路径长度相同（应该是大体），导致每一个数据的查询效率相当。 遍历所有的数据更加的方便B+树只要遍历叶子结点就可以实现整个树的遍历，而其他的树形结构，需要中序遍历才可以访问所有的数据。 https://www.jianshu.com/p/86a1fd2d7406","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/Spring/IOC","date":"2021-09-29T21:57:24.894Z","updated":"2021-09-29T22:01:58.151Z","comments":true,"path":"2021/09/30/typora文件集合/技术/技术笔记/Spring/IOC/","link":"","permalink":"http://example.com/2021/09/30/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Spring/IOC/","excerpt":"","text":"IOCBeanFactory与ApplicationContext的区别BeanFactory时Spring的IoC容器的顶级接口，用来定义一些基础的功能，定义一些基础的规范。ApplicationContext是它的一个子接口，所以ApplicationContext是具备BeanFactory提供的全部功能的。另外它还具备更多的功能，比如国际化支持和资源访问","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/答疑/答疑","date":"2021-09-29T11:44:56.118Z","updated":"2021-10-27T11:36:02.791Z","comments":true,"path":"2021/09/29/typora文件集合/拉钩/答疑/答疑/","link":"","permalink":"http://example.com/2021/09/29/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E7%AD%94%E7%96%91/%E7%AD%94%E7%96%91/","excerpt":"","text":"9月29号CAS的单点登录时保障客户端的用户资源的安全 。 OAuth2则是保障服务端的用户资源的安全 。 线程的中断： 什么是线程中断“ 为什么会有线程的中断？ 请问教练，每一个Java对象关联的ObjectMonitor是什么时候创建的，这个monitor锁和对象的关系是什么？我看有些博客上说Monitor是线程私有的数据结构，我理解Monitor应该只有一个，和对象是一一对应的。 10月27号答疑： 间隙锁、记录锁； Record Lock 锁：锁定单个行记录的锁；（记录锁，RC、RR隔离级别都支持）； GapLock 锁：间隙锁，锁定索引记录间隙，确保索引记录的间隙不变（范围锁，RR隔离级别支持）； 间隙锁是共享锁吗？ Next-key Lock： 记录锁和间隙锁组合，同时锁住数据，并且锁住数据前后范围； 共享锁（S 锁）： 排他锁（X 锁）：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/腾讯云切换遇到的问题","date":"2021-09-18T15:55:41.379Z","updated":"2021-09-19T09:08:59.935Z","comments":true,"path":"2021/09/18/typora文件集合/事故/腾讯云切换遇到的问题/","link":"","permalink":"http://example.com/2021/09/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E8%85%BE%E8%AE%AF%E4%BA%91%E5%88%87%E6%8D%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"[TOC] 切腾讯云系统背景由于公司战略需要，需要把之前架设在阿里云基础设施之上的应用全部迁移至腾讯云； 遇到的问题​ 慢查询日志：文档链接 暴露的问题： 事先没有对ES的迁移做充分的准备，只考虑了迁移的步骤和配置，但是对于现存的ES的实例的空间使用情况并没有做仔细统计，只是根据第一次的迁移的情况，感觉数据的同步很快，就忽视了第二次的同步中，老的ES实例的空间使用很大。事先应该根据这个空间的使用情况，粗略大致的估算出应该迁移的时间。 由于不仅仅是ES实例的迁移，还有的就是这两个实例是分别架设在不同的公有云设施上的。包括基础架构组同学在内都没有考虑到两者的实例的配置的问题。最致命的是腾讯云的分词库中的数据没有阿里云的全面，或者压根就没有这个词库。全量迁移的时候，是把老的es的索引的全部配置同步过去了，但是除了这之外的其他的就没有考虑到，上面的词库就是一个例子。这个导致的一个现象就是，在ES同步完成之后到我找架构组的同学把阿里云的词库复制一份到腾讯云的这段时间内的变动的数据（包括新增的和更新的），在ES中的分词的效果是不理想的，根据之前的查询语句又可能就是查询不出来的。 管理后台的权限查询，出现超时。这个一部分是和机器的性能出现剧烈下降有关系，但是另一方面，通过查询语句，也反映出接口的设计也是有问题的： 商家商品列表查询缓慢问题 工程信息：ypsx-kernel-item 环境：prod 类路径：com.ypshengxian.kernel.item.server.infrastructure.external.MatrixClientFacade 方法名：pageQueryMerchantSaleScopeItemFromEs 参数信息：queryMerchantScopeItemListCondition { businessType: 1 merchantId: 200016367 merchantId: 200114158 merchantId: 200111593 merchantId: 200114923 merchantId: 200052452 merchantId: 200037351 merchantId: 200079847 merchantId: 200006887 merchantId: 200040956 merchantId: 200084990 merchantId: 200107262 merchantId: 200071930 merchantId: 200115701 merchantId: 200059894 merchantId: 200052983 merchantId: 200056048 merchantId: 200057584 merchantId: 200114675 merchantId: 200055795 merchantId: 200069619 merchantId: 200073418 merchantId: 200004812 merchantId: 200048587 merchantId: 200050374 merchantId: 200054470 merchantId: 200100039 merchantId: 200082118 merchantId: 200041666 merchantId: 200025308 merchantId: 200071132 merchantId: 200016863 merchantId: 200113112 merchantId: 200071892 merchantId: 200037845 merchantId: 200115671 merchantId: 200060882 merchantId: 200110803 merchantId: 200079827 merchantId: 200108717 merchantId: 200004515 merchantId: 200069286 merchantId: 200115872 merchantId: 200107965 merchantId: 200044990 merchantId: 200083897 merchantId: 200104632 merchantId: 200037307 merchantId: 200115637 merchantId: 200019639 merchantId: 200055991 merchantId: 200037296 merchantId: 200111536 merchantId: 200047026 merchantId: 200109747 merchantId: 200039304 merchantId: 200044676 merchantId: 200069764 merchantId: 200097924 merchantId: 200049798 merchantId: 200040071 merchantId: 200061827 merchantId: 200103581 merchantId: 200115604 merchantId: 200056726 merchantId: 200014484 merchantId: 200051558 merchantId: 200019811 merchantId: 200075619 merchantId: 200115298 merchantId: 200053373 merchantId: 200037242 merchantId: 200052347 merchantId: 200058996 merchantId: 200039024 merchantId: 200051568 merchantId: 200114033 merchantId: 200054129 merchantId: 200055665 merchantId: 200058701 merchantId: 200069454 merchantId: 200099407 merchantId: 200047695 merchantId: 200007758 merchantId: 200042564 merchantId: 200055876 merchantId: 200069445 merchantId: 200114246 merchantId: 200110144 merchantId: 200115776 merchantId: 200069443 merchantId: 200074587 merchantId: 200067412 merchantId: 200058709 merchantId: 200084822 merchantId: 200110166 merchantId: 200078418 merchantId: 200039251 merchantId: 200110162 merchantId: 200115026 merchantId: 200054574 merchantId: 200060206 merchantId: 200098606 merchantId: 200114734 merchantId: 200099370 merchantId: 200034853 merchantId: 200042535 merchantId: 200057378 merchantId: 200054077 merchantId: 200113205 merchantId: 200047920 merchantId: 200075568 merchantId: 200111153 merchantId: 200038193 merchantId: 200052017 merchantId: 200000778 merchantId: 200061453 merchantId: 200061454 merchantId: 200115726 merchantId: 200004623 merchantId: 200064776 merchantId: 200105737 merchantId: 200114185 merchantId: 200115465 merchantId: 200051460 merchantId: 200069125 merchantId: 200072197 merchantId: 200052231 merchantId: 200059138 merchantId: 200101405 merchantId: 200037150 merchantId: 200079898 merchantId: 200067611 merchantId: 200115477 merchantId: 200115732 merchantId: 200062231 organizationId: 100002 categoryId2: 60153012 categoryId2: 2001 categoryId2: 2002 categoryId2: 2003 categoryId2: 2004 categoryId2: 2005 categoryId2: 2006 categoryId2: 2007 categoryId2: 2008 categoryId2: 2009 categoryId2: 2010 categoryId2: 2080 categoryId2: 4001 categoryId2: 1001 categoryId2: 1002 categoryId2: 1003 categoryId2: 1004 categoryId2: 1005 categoryId2: 1006 categoryId2: 3001 categoryId2: 3002 categoryId2: 3003 categoryId2: 3004 categoryId2: 3005 categoryId2: 3006 } pageInfo { page: 1 size: 20 } 异常信息：io.grpc.StatusRuntimeException: UNAVAILABLE: upstream connect error or disconnect/reset before headers. reset reason: connection failure 异常追踪： com.ypshengxian.kernel.item.server.infrastructure.external.MatrixClientFacade.pageQueryMerchantSaleScopeItemFromEs(MatrixClientFacade.java:168) com.ypshengxian.kernel.item.server.application.query.service.MerchantScopeQueryService.queryMerchantScopeItemListCondition(MerchantScopeQueryService.java:81) com.ypshengxian.kernel.item.server.interfaces.grpc.merchantitem.MerchantScopeItemManageGrpcService.pageQueryMerchantScopeItemList(MerchantScopeItemManageGrpcService.java:91) com.ypshengxian.kernel.item.server.infrastructure.interceptor.AuthorityInterceptor.around(AuthorityInterceptor.java:60) com.ypshengxian.kernel.item.server.interfaces.grpc.merchantitem.MerchantScopeItemManageGrpcServiceGrpcImpl.pageQueryMerchantScopeItemList(MerchantScopeItemManageGrpcServiceGrpcImpl.java:22) 最后一次出现时间：2021-09-19 10:34:22 出现次数：4 可以看到，这个 Redis实例的迁移问题。这个归根结底也是两边的配置不一致导致的。迁移的第二天，有部分问题是由于腾讯云的redis配置的淘汰策略有问题导致的，Redis 内存满了，导致查询redis 异常。满了的原因是淘汰策略是不过期就不驱逐，实际的内存应该是够的。已经让他调整成lru的了。 内部有一个服务：ypsx-matrix，这个项目中的数据库大数据组需要往里面写数据，但是商品迁移之后实例发生改变，导致大数据之前用的实例已经不能读写据（阿里云的实例停止写操作了）。这个也是内部评估的不到位，没有考虑到商品与外域共用一个实例的情况； 部分项目的Redis的掩码被基础架构组的同学修改了两次，导致重新部署的时候报Invalid Password。还有就是有些项目（ypsx-matrix）的白名单配置的有问题，导致item调用matrix的接口的时候报错。如下图所示： MySQL整体的迁移还是顺利的。但是迁移之后，老的DMS不能使用，只能使用自研的DMS，这个DMS没有逻辑库，导致查询、导致会麻烦些； 一次ES查询缓慢处理的例子现象：ES的QPS和CPU使用率居高不下 通过Kibana控制台，看到ES集群的QPS高达1w，导致机器性能下降。 另外，还观察到product_docs这个索引的请求速率和请求时间，都明显飙升！，所以，初步怀疑是这个索引的QPS太高导致的。 所以，首先想到的就是重启这个ES实例，毕竟之前切换的第二天，也遇到过这个问题，当时是商户的索引merchant_info这个索引的QPS也是很高，当时就是重启集群解决了这个问题。但是，当时准备重启的时候，系统提示这个： 集群中很多的索引的状态都是Yellow，而不是Green。 所以，就准备看看是不是系统那个接口调用太频繁了。但是发现，对查询product_docs这个索引的接口加了限流并没有什么作用，打了日志，但是却没有在kibana上找到对应的调用记录！！！说明这个QPS高不是接口造成的。 于是，就想着把这个索引给关闭掉看看系统报不报错，如下图所示，把product_docs这个索引给关闭了。 关闭之后，系统没有异常告警，再一次验证了之前的猜想。同时观察资源负载监控，发现集群的QPS出现大幅度的下降，说明关闭product_docs索引有效果了。 但是如上图所示，节点的CPU使用率，并没有出现明显的下降，这样的话，集群的性能还是没有出现提升。 最终的原因把这个现象反馈给腾讯云团队，反馈说是因为查询队列有堆积，内存有熔断，cpu和load打满；从日志上看是有批量拉数据导致的系统资源消耗过大 导致的。所以说，应该还是最初的那个wildcard查询导致的:因为里面terms了很多的productId（个人猜想） 后续的优化 重新刷新切换完腾讯云ES实例之后到杨航复制阿里云分词库数据到腾讯云实例之间，所有变动的数据（包括新增的和编辑的），已解决这部分时间段内，ES分词不理想的问题； 优化查询的搜索语句，梳理出所有使用wildcard查询语句，尽量替换成其他的查询语句； 参考技术博文：腾讯万亿级 Elasticsearch 技术解密","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/item主要性能指标","date":"2021-09-13T00:04:36.642Z","updated":"2021-09-13T00:05:12.965Z","comments":true,"path":"2021/09/13/typora文件集合/经验/item主要性能指标/","link":"","permalink":"http://example.com/2021/09/13/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/item%E4%B8%BB%E8%A6%81%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/","excerpt":"","text":"商品服务的主要指标","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/拉钩/阶段一/模块一/Mybatis学习笔记","date":"2021-09-12T22:36:11.597Z","updated":"2021-09-12T22:38:58.262Z","comments":true,"path":"2021/09/13/typora文件集合/拉钩/阶段一/模块一/Mybatis学习笔记/","link":"","permalink":"http://example.com/2021/09/13/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8B%89%E9%92%A9/%E9%98%B6%E6%AE%B5%E4%B8%80/%E6%A8%A1%E5%9D%97%E4%B8%80/Mybatis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"可以参考的链接： https://codeleading.com/article/51144594426/ https://zhuanlan.zhihu.com/p/300735740 Type接口：https://www.cnblogs.com/baiqiantao/p/7460580.html","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/Docker/新建MySQL","date":"2021-09-11T18:35:01.046Z","updated":"2022-01-19T18:07:01.998Z","comments":true,"path":"2021/09/12/typora文件集合/技术/Docker/新建MySQL/","link":"","permalink":"http://example.com/2021/09/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/Docker/%E6%96%B0%E5%BB%BAMySQL/","excerpt":"","text":"利用Docker新建MySQL服务第一步在zsh客户端执行以下代码： ​ docker pull mysql:latest ​ 拉取mysql镜像； 第二步创建并启动一个MySQL容器： ​ docker run --name myMysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql PS:注意，此处需要指定Docker容器映射到宿主机上的端口，不然的话，无法本地连接MySQL服务； 如果使用Navicate等工具连接的时候，报异常，需要执行第三步 第三步 3.1 进入MySQL容器，docker exec -it myMysql /bin/bash 3.2 连接MySQL服务：mysql -u root -p 3.3 创建一个用户： CREATE USER &#39;xiazhenyu&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; 3.4 赋予权限：GRANT ALL ON *.* TO &#39;xiazhenyu&#39;@&#39;%&#39; 3.5 刷新权限： flush privileges ![image-20210913065142244](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210913065142244.png) 关于这个GRANT的介绍，可以参考这个博文：https://www.yiibai.com/mysql/grant.html","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/Docker/Docker","date":"2021-09-11T17:46:51.456Z","updated":"2021-09-12T22:40:48.636Z","comments":true,"path":"2021/09/12/typora文件集合/技术/Docker/Docker/","link":"","permalink":"http://example.com/2021/09/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/Docker/Docker/","excerpt":"","text":"![image-20210912014659897](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210912014659897.png) docker desktop客户端不用配置代理 Docker info 信息 ![image-20210912014940205](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210912014940205.png)","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/新老系统商品同步踩坑经历","date":"2021-09-05T22:22:49.033Z","updated":"2021-09-20T08:12:11.212Z","comments":true,"path":"2021/09/06/typora文件集合/事故/新老系统商品同步踩坑经历/","link":"","permalink":"http://example.com/2021/09/06/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E6%96%B0%E8%80%81%E7%B3%BB%E7%BB%9F%E5%95%86%E5%93%81%E5%90%8C%E6%AD%A5%E8%B8%A9%E5%9D%91%E7%BB%8F%E5%8E%86/","excerpt":"","text":"[TOC] 问题背景商品在2021年的5、6月份进行了一次重构，新建了全新的项目以及数据库，但是对接外域的接口没有切，这个是为了减少重构的实施的难度。那么这样的话，就需要把新系统的数据同步给老系统，采用的是通过MQ来做的。 出现的问题以及解决的方法 阶段1在上线之后，出现的最多的问题就是老系统的历史数据。新系统中的数据，不论是通过脚本初始化进去的，还是通过MQ同步的，下发地点的时候，都是先查了一遍最新的商户的数据（获取商家在对应的渠道以及运营组下面的最新的覆盖营业部列表），然后再批量的下发。这个地方就会存在一个问题，就是同一个商品，之前在老系统下发的时候，假如当时商家覆盖了100个营业部，但是当在新系统创建的时候呢，商户那边只返回了90个（不排除商户接口的问题，事实上确实遇到过这个情况），这样就会导致新老系统的数据不一致的问题。这样当业务在新系统对营业部商品进行上下架操作的时候，老系统接收到消息的时候就会匹配不到对应的商品，无法进行上下架状态的同步修改，导致早APP端售罄的问题；解决方案：这个情况没有做过多的处理，毕竟这样的数据并不多，就是商家减少覆盖营业部的情况并不频繁，遇到的时候，就是通过sql或者脚本，把老系统中不覆盖的营业部的商品给下架并软删除掉。 阶段2针对阶段1，同期还出现了另外一个情况，就是新系统的对应的覆盖营业部数据多了，但是老系统中少了。这个是因为，之前老系统中下发不是自动下发的，是需要业务自己勾选对应的营业部下发的。对于合肥的POP商家而言，营业部一般都在500个以上，那么多的营业部，业务勾选的时候，难免会出现遗漏，而业务又不会去APP端看下每个自提点的商品是不是都有（自提点太多）。这个的解决方案：老系统在消费消息时，会去先查询下对应的营业部有没有商品，如果没有的话，再判断下商品的编码是不是以16开头的（只有新系统创建的商品），如果不是的话，说明是通过脚本初始化进去的，那么这个时候就会去新建对应的营业部的商品，这个是在接营业部商品更新的时候做的； 阶段3这个阶段出现的问题，一般是新系统的代码bug导致的。![image-20210906070604276](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210906070604276.png) 上面的这个代码，看起来并没有什么不同，只不过就是把ArrayList换成了CopyOnWriteArrayList。这两个本质上都是List，但是他们的实现方式是不同的。具体的可以参考https://www.jianshu.com/p/c34c39590620这片博文；为什么会出现并发的问题呢，是因为代码中使用了parallel()方法，这个是个多线程的操作。解决方案：如图的右边，我们是吧ArrayList换成了CopyOnWriteArrayList。 阶段3这一阶段的问题就是2021年8月30号，出现了一次引擎（分布式一致性组件）的大面积的超时。背景是重庆的一个商家添加了一个运营组，这个运营组大概有700个营业部。之前商品2.0有接商户新开营业部的消息，然后回去创建商品。但是这个创建商品的流程是一个营业部商品点火一次引擎，当时这个商家大概有1000个有效的商品，所以就有大概70w个引擎的任务。对应的事故报告：（临时）解决方案：其实这个地方会牵涉到一直以来都存在的一个问题，就是一致性组件存在的异步执行带来的乱序的问题：由于新系统调用了一致性组件，一致性组件是异步执行的，那么当并发量大的时候，就会有后发先至的问题，新系统通过版本号解决了这个问题，但是发送给老系统的消息还存在这个问题，这就需要老系统也要对此有响应的处理方案（初步的是用版本号来做，通过把版本号缓存再redis中）。由于历次的数据同步，导致新老系统数据出现了很多的不一致，如果用脚本一一比对更新成本很大。那么为了一次性解决这个问题，我们就全量读取新系统中所有地点商品，重新发一次地点商品状态变更的消息给老系统。让老系统重新消费一遍，以此老保证新老系统数据的一致性。同时老系统的es也进行了同步的更新。 1234567891011121314151617供应链业务反馈的相关问题问题现象：供应链采购、调拨、批发、补货集单业务提交订单提示“系统异常”问题原因：下午商品侧业务反馈有一个商家挂错了运营组，需要做调整；该商家下游700+商品，重新分发到新的运营组下面有1000+地点，商品系统针对一个商品一个地点的维度调用引擎系统做商品地点的分档，由于瞬间的请求把引擎底层的DRDS数据库负载打满了，引擎内部在扫描任务的时候没有使用到DRDS的分片索引，使得扫描了所有的8库8表；引起了慢查，导致引擎几乎不可用进一步影响供应链侧的相关功能。问题解决：1、临时调整DRDS的分库分表策略，从8库8表调整为8库一表，降低扫描表的数量，临时降低负载；并修改表名，让新的任务直接写入新表；再把老表的数据做同步，降低表里的数据量级。2、优先重试影响供应链侧生产数据的任务，优先下发。后续优化：【商品侧的优化】1、商品分档的消息改变目前的笛卡尔积的方式下发到引擎；优化为单条消息+地点列表的方式下发到引擎，在引擎任务内部做商品+地点维度的消息分发；【引擎侧的优化】2、引擎的内部优化，替换底层的DRDS为mysql分库+Es的方案；任务的下发改为推拉结合的方式，拉的方式用于解决引擎某一业务积压导致的其他业务数据下发堵塞的问题。 ​ 感悟","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/到家/商家中心/商家中心文档","date":"2021-09-04T06:33:04.800Z","updated":"2021-09-04T06:35:55.091Z","comments":true,"path":"2021/09/04/typora文件集合/产品/到家/商家中心/商家中心文档/","link":"","permalink":"http://example.com/2021/09/04/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%88%B0%E5%AE%B6/%E5%95%86%E5%AE%B6%E4%B8%AD%E5%BF%83/%E5%95%86%E5%AE%B6%E4%B8%AD%E5%BF%83%E6%96%87%E6%A1%A3/","excerpt":"","text":"总体架构图","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/报告/引擎回执超时事故报告","date":"2021-09-01T07:37:45.160Z","updated":"2021-09-06T00:08:37.972Z","comments":true,"path":"2021/09/01/typora文件集合/事故/报告/引擎回执超时事故报告/","link":"","permalink":"http://example.com/2021/09/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E6%8A%A5%E5%91%8A/%E5%BC%95%E6%93%8E%E5%9B%9E%E6%89%A7%E8%B6%85%E6%97%B6%E4%BA%8B%E6%95%85%E6%8A%A5%E5%91%8A/","excerpt":"","text":"事故现象： 新商品中心，商品提报、上下架提示系统异常 事故定级：P4事故责任人：孙彬事故时间：2021-08-23事故原因：由于重庆一个商家重新挂了新的运营组，导致商户那边发了700个左右的营业部消息，商品这进行了大概1000*700=700000个地点商品的创建，创建了大量的引擎任务，引擎处理缓慢。 影响范围： 新商品系统的商家商品的提报、编辑、地点商品的上下架操作等 排查过程：1、8月30日 中午的时候 产品（石一峰）反馈新商品中心，地点商品查询报超时；2、8月30日 15:00 左右夏振宇看到kernel-item线上告警群里面有异常告警，查询日志发现是地点商品的创建流程中回执引擎报错，并开始给小黄人反馈问题；3、8月30号 16:00 左右，小黄人定位到问题：引擎补偿任务没有走分片建 导致很多慢SQL，rdrs CPU满了；4、8月30日 22:00 左右，小黄人重跑了商品积压的所有的引擎任务；5、8月31日 00:17 夏振宇发现还有一些处于代执行的任务，重启了商品的服务并重新执行了这些任务； 解决方案：1、修改drds数据库分库策略，由原来的88改为812、rename原来的task、task_callback、wate_task表为备份表，新建一张空表，迁移当天数据3、engine-core的实例降低为2台(降低数据库的QPS)4、提高任务补偿的频率和数据量（提高积压任务处理的速度） 后续Action：引擎侧：1、弃用drds数据库，使用MySQL2、通过binlog方式同步ES数据，补偿任务扫描es商品测：地点商品的创建流程修改，改为一个营业部商品的创建在一个流程中，减少对引擎的回调的次数@刘旺杰","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/0821晚商品同步未成功","date":"2021-08-21T13:53:04.289Z","updated":"2021-08-21T13:54:25.891Z","comments":true,"path":"2021/08/21/typora文件集合/事故/0821晚商品同步未成功/","link":"","permalink":"http://example.com/2021/08/21/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/0821%E6%99%9A%E5%95%86%E5%93%81%E5%90%8C%E6%AD%A5%E6%9C%AA%E6%88%90%E5%8A%9F/","excerpt":"","text":"![image-20210821215331388](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210821215331388.png) ![image-20210821215401077](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210821215401077.png)","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/分布式/Zookeeper","date":"2021-08-21T07:24:02.188Z","updated":"2022-03-19T18:22:29.754Z","comments":true,"path":"2021/08/21/typora文件集合/技术/LandScape/分布式/Zookeeper/","link":"","permalink":"http://example.com/2021/08/21/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/%E5%88%86%E5%B8%83%E5%BC%8F/Zookeeper/","excerpt":"","text":"zookeeper架构图 ZAB协议协议的本质而言，划分集群角色：主从架构：Leader和Follower角色； 只有Leader可以接受写操作，Leader和Follower都可以读。Leader收到事务请求以后，转换为Proposal（提议）同步给所有的Follower，超过半数的Follower都收到事务Proposal了，Leader再给所有的Follower发一个Commit消息，让所有的Follower提交一个事务。 而且如果Leader崩溃了，要重新选举出Leader保证继续运行； 角色划分，2PC（两阶段），过半写机制","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/商品/外卖","date":"2021-08-20T03:08:47.907Z","updated":"2021-08-21T06:57:49.361Z","comments":true,"path":"2021/08/20/typora文件集合/产品/商品/外卖/","link":"","permalink":"http://example.com/2021/08/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%95%86%E5%93%81/%E5%A4%96%E5%8D%96/","excerpt":"","text":"外卖平台背景：门店差异化运营，不同的门店的价格是不一样的。 [{ 你好}] 反向更新？ 减少写操作，更具下层聚合进行展示。 商家商品层的默认售价不进行存储，直接更新营业部的层面的售价，统一管理，差异化运营另走方法，比如到表修改、批量修改； 价格中心：支持门店运营差异化，生鲜的售价、销售的售价都支持到门店维度","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/商户接口替换","date":"2021-08-19T22:53:25.426Z","updated":"2021-08-23T22:29:03.941Z","comments":true,"path":"2021/08/20/typora文件集合/产品/商户接口替换/","link":"","permalink":"http://example.com/2021/08/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%95%86%E6%88%B7%E6%8E%A5%E5%8F%A3%E6%9B%BF%E6%8D%A2/","excerpt":"","text":"一，多业态商家的查询 1listRetailersByMerchantIds 二、流式接口怎么办？ 1merchantExternalService.queryMerchantsWithStream() 三、citycode获取 ![image-20210820071814553](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210820071814553.png) 四、和前端对下，看看getPopMerchantManageScope 这个接口是不是还在使用 五、看下queryMerchantList这个接口是不是可以替换掉，都有哪些场景在使用","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/商品/业务需求梳理","date":"2021-08-18T08:24:52.374Z","updated":"2021-09-20T08:13:35.931Z","comments":true,"path":"2021/08/18/typora文件集合/产品/商品/业务需求梳理/","link":"","permalink":"http://example.com/2021/08/18/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%95%86%E5%93%81/%E4%B8%9A%E5%8A%A1%E9%9C%80%E6%B1%82%E6%A2%B3%E7%90%86/","excerpt":"","text":"[TOC] 需求一、生鲜门店复制1、新商品中心，商品的复制（同步），接受的是商户的消息，营业部开业的消息，然后同步下来； 方案： 、接受消息， 、 自己触发； 老的：分批查询，然后复制，写入新的门店商品中； 新的： 查询商家商品，然后组装写入到新的门店中； 二、助记码2、 助记码主记码方案 通用的商品校验商家+品牌+渠道+商品名称唯一 商家+渠道+销售商品条码唯一 商家+渠道+货品编码+转换比例唯一 货品相关到家会员是什么渠道？是不是就是生鲜线上？ 到家自营、谊批宝、POP商家的货品是单规格的 生鲜门店、到家会员（门店线上）是需要货品支持多规格的 ![image-20210830064249770](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210830064249770.png)这个地方为什么是在到家下面添加一个门店门店线上的渠道 POP商家也是可以有货品的，现在谊品生鲜渠道的商家都是自营的，这个切换需要到明年的3月份。简而言之，POP商家、自营商家都是可以有销售商品和货品的。只不过就生鲜的话，现在的都是自营的。谊批宝也是一样的，也有货品和销售商品，和生鲜一样，谊批宝现在的商家都是自营的； Q： 线上线下融合新增的渠道是什么业态下的？","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/商品/搜索相关","date":"2021-08-17T07:07:12.588Z","updated":"2021-08-18T08:24:15.858Z","comments":true,"path":"2021/08/17/typora文件集合/产品/商品/搜索相关/","link":"","permalink":"http://example.com/2021/08/17/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%95%86%E5%93%81/%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3/","excerpt":"","text":"一、怎么设计合理的搜索条件，以满足复杂的业务需求？ 二、 助记码搜索相关的，比如输入拼音搜索对应的中文怎么做？","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/网络IO/网络零拷贝相关","date":"2021-08-13T23:40:49.665Z","updated":"2022-03-19T18:21:49.358Z","comments":true,"path":"2021/08/14/typora文件集合/技术/LandScape/网络IO/网络零拷贝相关/","link":"","permalink":"http://example.com/2021/08/14/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/%E7%BD%91%E7%BB%9CIO/%E7%BD%91%E7%BB%9C%E9%9B%B6%E6%8B%B7%E8%B4%9D%E7%9B%B8%E5%85%B3/","excerpt":"","text":"[TOC] 参考文档：https://www.jianshu.com/p/7863667d5fa7 普通的IO操作在OS层面的执行流程： 4次切换、4次拷贝 使用read读取文件的时候，会有一次用户态到内核态的切换，也就是说从用户角度切换到了内核角度去执行，这个时候基于DMA引擎把磁盘上的数据拷贝到内核缓冲区；接着会从内核态切换到用户态，基于CPU把内核缓冲区的数据拷贝到用户缓冲区。 接着我们调用了socket的输出流的write方法，此时会从用户态切换到内核态，同时基于CPU把用户缓冲区的数据拷贝到Socket缓冲区，接着会有一个异步化的过程，基于DMA引擎从Socket缓冲区把数据拷贝到网络协议引擎里发送出去。都完成之后，从内核态切换回用户态。 基于sendfile技术的零拷贝技术![image-20210814080020507](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210814080020507.png) 2次切换、2次拷贝 首先从用户态切换到内核态，在内核态状态下，把磁盘上的数据拷贝到内核缓冲区，同时从内核缓冲区拷贝一些offset和length到socket缓冲区；接着从内核态切换到用户态，从内核缓冲区直接把数据拷贝到网络协议引擎中区（图中的DMA拷贝），同时从Socket缓冲区拷贝一些offset和length到网络协议引擎中区，但是这个offset和length的量很少，几乎可以忽略不计。 应用的地方： kafka、tomcat中都使用到了零拷贝技术，rocketmq中使用的mmap技术。 mmap技术![image-20210814081625708](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210814081625708.png) 4次切换、3次拷贝","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/网络IO/堆外内存于堆内内存","date":"2021-08-13T23:06:00.124Z","updated":"2022-03-19T18:21:54.252Z","comments":true,"path":"2021/08/14/typora文件集合/技术/LandScape/网络IO/堆外内存于堆内内存/","link":"","permalink":"http://example.com/2021/08/14/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/%E7%BD%91%E7%BB%9CIO/%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E4%BA%8E%E5%A0%86%E5%86%85%E5%86%85%E5%AD%98/","excerpt":"","text":"[TOC] 架构图： 相关概念： 堆内内存、 heap、off-heap堆外内存的优势？堆内内存的数据，要网络IO写出去，要先拷贝到堆外内存中去，再写入到socket中发送出去，如果直接数据分配在堆外内存，是不需要一次额外的拷贝的，性能是比较高的。 优化： 如果堆外内存足够，就直接预留一部分内存； 如果堆外内存不足，则将已经被JVM垃圾回收的DirectBuffer堆外对象内存释放； 如果进行一次堆外内存资源的回收后，还不够进行本次堆外内存分配的话，则进行system.gc(); 如果9次尝试后依旧没有足够的可用堆外内存，则抛出异常。 实际分配内存 堆完内存出现OOM的场景：JVM一般分为young gc和full gc，如论发生哪种gc，都可能会回收掉一些没有GC roots变量引用的DirectByteBuffer对象，回收掉了之后，会主动释放他们引用的那些堆外内存，或者其内部有一个cleaner对象，可以反射获取它，然后调用它的clean方法来主动释放内存； 依靠jvm.gc机制，可能DirectByteBuffer躲过了N次的minor gc从而进入了老年代，然后老年代迟迟没有放满，没有被full gc，此时有可能导致DirectByteBuffer对象一直在引用堆外内存。这样当要分配更多的堆外内存时，无法腾出更多的内存，就会有堆外内存溢出了。 –XX:MaxDirectMemorySize","categories":[],"tags":[]},{"title":"计划事项","slug":"typora文件集合/计划事项","date":"2021-08-13T09:53:48.017Z","updated":"2022-03-19T18:29:32.409Z","comments":true,"path":"2021/08/13/typora文件集合/计划事项/","link":"","permalink":"http://example.com/2021/08/13/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E8%AE%A1%E5%88%92%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"申请item、pms等相关的数据库的权限； 新的系统item中rpc接口的梳理； 梳理商品领域近期的需求以及对应的开发人员； 跟进最近的提测事项； Q3的规划； 商品2.0中es搜索怎么解决，模糊搜索的问题，举个例子，如果用户输入了1，这个是会影响es搜索性能的； 看下这个pulsar的消息日志中，为什么这个topicName十四null的.","categories":[{"name":"typora","slug":"typora","permalink":"http://example.com/categories/typora/"}],"tags":[{"name":"工作安排","slug":"工作安排","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92/"}]},{"title":"","slug":"typora文件集合/事故/报告/故障报告模版","date":"2021-08-12T02:58:08.769Z","updated":"2021-08-12T02:58:28.431Z","comments":true,"path":"2021/08/12/typora文件集合/事故/报告/故障报告模版/","link":"","permalink":"http://example.com/2021/08/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E6%8A%A5%E5%91%8A/%E6%95%85%E9%9A%9C%E6%8A%A5%E5%91%8A%E6%A8%A1%E7%89%88/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/C端商品售罄的常见原因","date":"2021-08-12T02:13:57.059Z","updated":"2022-03-18T17:45:57.927Z","comments":true,"path":"2021/08/12/typora文件集合/产品/C端商品售罄的常见原因/","link":"","permalink":"http://example.com/2021/08/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/C%E7%AB%AF%E5%95%86%E5%93%81%E5%94%AE%E7%BD%84%E7%9A%84%E5%B8%B8%E8%A7%81%E5%8E%9F%E5%9B%A0/","excerpt":"","text":"C端商品售罄的原因列表 商家是否切库存中心。新的商品中心查询的是库存中心的库存，但是库存中心有一个白名单配置，根据这个白名单，到家会去判断商品的库存是去查询库存中心还是查询老的商品中心的接口。如果没有配置白名单，但是商家切了新的商品中心的话，就会出现商品售罄的情况。 商品的状态没有同步到导购。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/商品/需要了解的业务","date":"2021-08-10T12:38:00.790Z","updated":"2021-09-01T02:27:06.202Z","comments":true,"path":"2021/08/10/typora文件集合/产品/商品/需要了解的业务/","link":"","permalink":"http://example.com/2021/08/10/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%95%86%E5%93%81/%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E4%B8%9A%E5%8A%A1/","excerpt":"","text":"几个大模块1、品类箱子数 一个类目下面会挂一个品类箱子数，箱子数总共有A、B、C、D四个类型，然后会定义每个箱子里面可以存放多少商品。这个是给门店用的，门店会去修改自己门店的实际的品类箱子里面可以存放的商品数量。设置的品类箱子数&gt;=门店实际的品类箱子数。然后转类的时候，比如说商品A对应的类目有C变动到D，那么原先门店在类目C下面的品类箱子数里面实际可用的商品就是减去1，在类目D下面的品类箱子数里面实际可以存放的商品就加1； 2、一品一仓；3、关联推荐4、去富集的校验；5、 下掉erp-gateway系统6、 商品的聚合根到底是什么？7、货品是线上的还是线下的？线上的配送中心（大仓）怎么理解其职能？8、谊品火拼业务；9、谊商宝业务；10、全国包邮的业务怎么整合进现在的商品系统；11、 外卖业务； pop没有入仓的能力，pop商家（到家）都是用的新的商品中心； 生鲜切商品新中心怎么做？还有谊批宝 第一阶段： 基于富集/康铭系统构建自己的商品系统； 第二阶段：平台化：支持POP商家，入驻创建商品。 第三阶段：自研ERP，plu：称重码（pcs/称重） 老的商品中心的菜单要整理下 13位称码解析规则：24+5位PLU码+5位重量+1位校验位 夏老师你知道这个1位校验位是咋生成的吗？ 商户接口2.0替换？ 线上线下融合中，根据查询货品信息的接口的兼容；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/解决线上问题的步骤","date":"2021-08-09T05:42:56.067Z","updated":"2021-08-09T06:09:59.359Z","comments":true,"path":"2021/08/09/typora文件集合/经验/解决线上问题的步骤/","link":"","permalink":"http://example.com/2021/08/09/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/%E8%A7%A3%E5%86%B3%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E7%9A%84%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"基本步骤 看日志； 看服务； 是否有缓存； 外部服务 脚本混乱问题","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/Spring/Spring IoC容器初始化过程","date":"2021-08-08T21:31:34.237Z","updated":"2021-08-08T23:39:05.035Z","comments":true,"path":"2021/08/09/typora文件集合/技术/LandScape/Spring/Spring IoC容器初始化过程/","link":"","permalink":"http://example.com/2021/08/09/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/Spring/Spring%20IoC%E5%AE%B9%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/","excerpt":"","text":"Spring IoC容器初始化过程Spring 容器初始化的过程包括下面几个部分： Ioc是如何工作的； Resource定位 载入BeanDefinition 将BeanDefinition注册到容器 一、 Ioc是如何工作的关键子：通过ApplicationContext创建Spring容器，该容器会读取配置文件”beans.xml”（？但是基于注解的怎么弄？），并统一管理由该文件定义好的bean实例对象，如果要获取某个bean实例，使用getBean方法就好了，假如将User配置在beans.xml文件中，之后不需要使用new User() 的方式创建实例，而是通过ApplicationContext容器来获取User实例。 ApplicationContext appContext=new ClassPathXmlApplicationContext(/beans.xml); User p=(User)appContext.getBean(&quot;user&quot;) 二、Resource定位Resource是Spring中用于封装I/O操作的接口。在创建Spring容器的时候，会去访问XML配置文件，还可以通过文件类型、二进制流、URL等方式访问资源。这些都可以理解为Resource，其体系接口如下图所示： FileSystemResource: 以文件绝对路径进行资源的访问； ClassPathResource: 以类路径的方式访问资源； ServletContextResource: web应用根目录的方式访问资源； UrlResource: 访问网络资源的实现类； ByteArrayResource: 访问字节数组资源的实现类。 那么这些类型在Spring中是如何访问的呢？Spring提供了ResourceLoader接口实现不同的Resource加载策略，该接口的实例对象中可以获取一个Resource对象，在ResourceLoader接口中只定义了两个方法： Resource getResource(String location);//通过提供的资源location获取Resource实例 ClassLoader getClassLoder();//获取ClassLoader，通过ClassLoader可讲资源载入JVM 注：ApplicationContext的所有实现类都实现RecourceLoader接口，因此可以直接调用getResource（参数）获取Resoure对象。不同的ApplicatonContext实现类使用getResource方法取得的资源类型不同，例如：FileSystemXmlApplicationContext.getResource获取的就是FileSystemResource实例；ClassPathXmlApplicationContext.getResource获取的就是ClassPathResource实例；XmlWebApplicationContext.getResource获取的就是ServletContextResource实例，另外像不需要通过xml直接使用注解@Configuation方式加载资源的AnnotationConfigApplicationContext等等。在资源定位过程完成以后，就为资源文件中的bean的载入创造了I/O操作的条件，如何读取资源中的数据将会在下一步介绍的BeanDefinition的载入过程中描述。 三、载入BeanDifinitionBeanDefinition是一个数据结构，BeanDefinition是根据resources对象中的bean来生成的。bean会在Spring Ioc容器内部以BeanDefinition的形式存在，Ioc容器对bean的管理和依赖注入是实现原理是通过操作BeanDefinition来完成的。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/Idea使用过程中的疑难杂症","date":"2021-08-08T21:22:50.509Z","updated":"2022-03-15T07:20:40.248Z","comments":true,"path":"2021/08/09/typora文件集合/经验/Idea使用过程中的疑难杂症/","link":"","permalink":"http://example.com/2021/08/09/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/Idea%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/","excerpt":"","text":"IDEA 生活小提示 提示 Cannot resolve symbol &#39;FileSystemResource&#39;处理方法： 删除本地仓库中对应的包，这个是spring-core的，然后重新刷新maven的依赖。打开对应的类——FileSystemResource,然后点击Download Source。 Private field is never assigne 提示，解决方法。参考文章：https://intellij-support.jetbrains.com/hc/en-us/community/posts/206200799-Private-field-is-never-assigned-but-it-is- Boolean method ‘isBizModeMatch’ is always inverted ，对Boolean类型的返回值进行取非操作，因为IDEA进行语句了简洁性检查。 对于Idea类似的提示，总是可以这么做： &lt;video id=”video” controls=””src=”/Users/xiazhenyu/Pictures/Photos Library.photoslibrary/originals/c/C91B04F1-1BFA-43E6-8F78-D9735E788117.mov” preload=”none”&gt; 进入到Inspections的设置界面以后，在对应的dialog（对话窗口）中，我们可以找到Idea给出的这样警告的原因。在对话窗的右侧的下面，我们可以设置这个告警的一个级别以及域。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/面试/面试","date":"2021-08-07T21:27:06.312Z","updated":"2021-10-10T01:40:25.453Z","comments":true,"path":"2021/08/08/typora文件集合/产品/面试/面试/","link":"","permalink":"http://example.com/2021/08/08/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E9%9D%A2%E8%AF%95/%E9%9D%A2%E8%AF%95/","excerpt":"","text":"/Users/xiazhenyu/Desktop/typora文件集合/技术/LandScape/高并发/队列.md分布式锁的使用场景； redis的阻塞的实现原理； redis的主从同步； redis的淘汰策略； mysql的行级锁； mysql的索引覆盖； 商品的模型自己要讲出来，很详细，能解答面试官的提问； ypsx-titan项目要能很好的讲出来； xxl-excel的使用注意事项： mapper接口泛滥问题 怎么排查项目的整体的接口相应很慢的情况； 如何排查OOM情况； dubbo使用 有赞面试心得： 商品的架构模型要讲的清楚，不能光画的清楚，更重要的是要给面试的人讲清楚； 简历上写的分布式事务、缓存，都要再详细的了解下，重点关注TCC、缓存击穿等常见场景的解决方案，看下guava中对于本地缓存失效的解决方案； 发号服务的设计要了解下； AQS中，要知道底层的原理，synchronized和reentrantLock的区别？两者都是可重入的吗？ 对于flow，一定要讲清楚他的存在的意义，以及工作原理； 编码规范（不是性能），命名、包结构、项目层次、是否使用了设计模式等 8月5号面试心得： 如果要做到p7的薪资定位，需要充分思考自己的业务流程中存在的问题，痛点， 对DDD的认识需要加强，CQRS 流程编排服务怎么解决流程的动态可配置，比如流程顺序变动了，流程之间传递的报文怎么做到不需要改动； 流程编排的意义在哪里？基于流程的编排的解耦和基于消息的解耦有什么区别？ 要有owner意识！！！自己负责的领域要讲好。业务流程要熟悉； 接口的设计要看下别人的，自己之前设计的接口有些是有问题的，特别是Pms中的；","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/接口的设计","date":"2021-08-05T09:25:04.202Z","updated":"2021-10-24T14:46:43.645Z","comments":true,"path":"2021/08/05/typora文件集合/技术/接口的设计/","link":"","permalink":"http://example.com/2021/08/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8E%A5%E5%8F%A3%E7%9A%84%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"为什么要进行接口的重新替换如何确定领域模型如何设计","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/面试/记录","date":"2021-08-04T23:43:24.535Z","updated":"2021-10-07T23:51:37.462Z","comments":true,"path":"2021/08/05/typora文件集合/产品/面试/记录/","link":"","permalink":"http://example.com/2021/08/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E9%9D%A2%E8%AF%95/%E8%AE%B0%E5%BD%95/","excerpt":"","text":"面试笔录： 积极性不够高，问什么答什么，没有扩展。 Java以及JVM还可以，主要的多线程、类加载、syncronized、以及JVM相关的都答上来了； redis答得不够好，没能说出redis的线程阻塞实现的原理机制，分布式锁的实现回答的也不是很好； mysql中索引的分类了解，但是底层的binlog、redolog的实现机制没有很清楚的答上来； 总结：java基础还可以，JUC没有用过，netty有实战经验，问的几个基础的都答上来了。但是好像处理 线上问题的经验很少。 郑敏杰面试记录： 沟通流畅，不过稍微有点紧张,回答会有一点扩展性 问了问java的基础，比如三大特性（没回答全）、类加载机制主要的答上来了，JDK的内存模型，说出了基本的区域划分。 mysql 锁、索引说出了有哪些，不知道底层的构造； redis知道常用的类型，问了其他的淘汰策略不致痘，也就没有向下问； 总结：我感觉不是很理想，沟通还可以，但是应该很多东西只是知道，没有深入理解。 时曙生面试总结： Java基础可以，拥有较多的redis使用经验和MQ使用经验。Mysql的索引结构能流畅表达出来。拥有一定的DDD建模能力。回答流畅，比较沉稳。 陈小波面试总结： 1、 问了mysql相关的索引、事务隔离级别的，能答上来；2、redis熟悉使用，redis单线程模型能简单讲下；3、AQS的原理基本知道，问深入一点，线程是怎么唤醒的没有答上来；4、 说是对MQ有比较深入的了解，问了下rocketMQ的架构图，只说出了大概的使用流程；5、 问了一个缓存和DB不一致的问题，没有答上来；东西用的挺多的，但是应该不是很清楚原理。沟通积极，表达流畅，遇到不会的就会说不知道。总体上应该达不到5年经验的水平。 邓冲杰面试： 介绍 项目 技术 印象 徐伟： 秒杀怎么做的？ 卡券库：设置对应的库存；绑定对应的商品； 多批次、 价格：自由商品、对吧商品；DDD ： 一个商品，一个规格：","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/DB/锁","date":"2021-08-04T23:22:06.409Z","updated":"2021-08-14T00:19:10.667Z","comments":true,"path":"2021/08/05/typora文件集合/技术/LandScape/DB/锁/","link":"","permalink":"http://example.com/2021/08/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/DB/%E9%94%81/","excerpt":"","text":"MySQL中的锁","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/DB/B+树","date":"2021-08-04T21:50:45.351Z","updated":"2021-10-03T22:33:28.782Z","comments":true,"path":"2021/08/05/typora文件集合/技术/LandScape/DB/B+树/","link":"","permalink":"http://example.com/2021/08/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/DB/B+%E6%A0%91/","excerpt":"","text":"B+树 Mysql中的索引的存储的数据结构： 数组、哈希表、搜索二叉树。 二叉树的特点是：父节点左子树所有节点的值小于父节点的值，右子树所有节点的值大于父节点的值。时间复杂度O(log(N))平衡二叉树： N叉树：每个父节点不止有有2个子节点。目的：减少磁盘的读取量，加快数据的访问。数据库索引结构一般采用N叉树。 InnoDB中的索引模型在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。 InnoDB存储引擎使用的是B+树索引模型，每一个索引对应一颗B+树。 索引分为主键索引和非主键索引。 主键索引（聚簇索引clustered index）的叶子节点存储的是整行的数据 非主键索引（二级索引secondary index）的叶子节点存储的是主键的值。 PS：在InnoDB中，索引和文件是不分开的，每一个数据文件同样也是索引文件，这一点和MyISAM是不同的。 对于MyIASM和InnoDB而言，即便同样都使用到了B+树，但是他们的实现机制也是有区分的。MyIASM的叶子节点存储的是实际的物理地址，而InnoDB存储的是索引文件的数据（主键索引而言）。所以我们说： MyIASM 不支持事务，不支持外键约束。索引文件和数据文件分开，可以在内存中存放更多的索引文件，支持大量查询的场景。 支持事务，走聚簇索引，强制要求有主键，支持外键约束，采用高并发、大数据量、高可用等相关的成熟的数据库架构，支持分库分表、读写分离、主备切换等功能。 索引的维护： B+树为了维护索引的有序性，在插入新值的时候需要做必要的维护。这个地方就会牵涉到页分裂和页合并？ 为什么必须要定义自增主键？自增主键会自动获取当前的ID最大值加1作为下一条记录的ID的值。这样的话，每次插入都是追加操作，不涉及到挪动其他记录，也不会触发叶子节点的分裂。这个是从性能方面，另外从存储方面来讲，用整型来做主键，只需要4个字节，长整形的话就是8个字节。主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 覆盖索引：（索引的叶子节点存储的正是我们查询的结果）覆盖索引可以减少树的搜索次数，显著提升查询性能，所以覆盖索引是一个常用的性能优化手段。 最左前缀原则最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。 索引下推5.6以后引入。可以在索引遍历的过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 无索引下推图 ​ 有索引下推图","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/Spring/Spring框架中使用到的设计模式以及举例","date":"2021-08-01T18:04:48.728Z","updated":"2021-08-01T18:05:34.007Z","comments":true,"path":"2021/08/02/typora文件集合/技术/LandScape/Spring/Spring框架中使用到的设计模式以及举例/","link":"","permalink":"http://example.com/2021/08/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/Spring/Spring%E6%A1%86%E6%9E%B6%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%A5%E5%8F%8A%E4%B8%BE%E4%BE%8B/","excerpt":"","text":"Spring对设计模式的实践","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/Spring/Spring中的常用的工具类","date":"2021-08-01T18:01:21.476Z","updated":"2021-08-01T18:21:09.880Z","comments":true,"path":"2021/08/02/typora文件集合/技术/LandScape/Spring/Spring中的常用的工具类/","link":"","permalink":"http://example.com/2021/08/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/Spring/Spring%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB/","excerpt":"","text":"工具类ClassUnit类相关的工具类； NamedThreadLocalThreadLocal的子类，可以给ThreadLocal指定个名字，可以使用toString()方法获取这个名字;","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/Spring/Spring中的事务","date":"2021-08-01T16:49:51.227Z","updated":"2021-08-01T18:43:32.596Z","comments":true,"path":"2021/08/02/typora文件集合/技术/LandScape/Spring/Spring中的事务/","link":"","permalink":"http://example.com/2021/08/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/Spring/Spring%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"Spring中的事务传播机制Spring中事务实现的技术依据：IOC+动态代理 PROPAGATION_REQUIRED如果当前没有事务，就会创建一个新事务；如果当前存在事务，就加入该事务，改设置是最常用的设置。 PROPAGATION_SUPPORTS支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务的方式执行； PROPAGATION_MANDATORY支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常； PROPAGATION_REQUIRES_NEW创建新事务，无论当前存不存在事务，都会创建事务； PROPAGATION_NOT_SUPPORTED以非事务方式执行操作，如果当前存在事务，就把当前事务挂起； PROPAGATION_NEVER以非事务方式执行，如果当前存在事务，则会抛出异常； PROPAGATION_NESTED如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按照REQUIRED属性执行 Spring中的事务中的挂起可以参考这个博文：https://wiyi.org/how-does-transaction-suspension-in-spring.html","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/LandScape/DB/MySql中的事务与锁机制","date":"2021-08-01T16:33:20.603Z","updated":"2021-08-01T16:33:20.607Z","comments":true,"path":"2021/08/02/typora文件集合/技术/LandScape/DB/MySql中的事务与锁机制/","link":"","permalink":"http://example.com/2021/08/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/LandScape/DB/MySql%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81%E6%9C%BA%E5%88%B6/","excerpt":"","text":"MySql中的事务与锁机制事务及其特性简单来说，事务是指作为单个逻辑工作单元执行的一系列操作，这些操作要么全做，要么全不做，是一个不可分割的工作单元。一个逻辑工作单元要成为事务，在关系型数据库管理系统中，必须满足 4 个特性，即所谓的 ACID：原子性、一致性、隔离性和持久性。一致性：事务开始之前和事务结束之后，数据库的完整性限制未被破坏。原子性：事务的所有操作，要么全部完成，要么全部不完成，不会结束在某个中间环节。持久性：事务完成之后，事务所做的修改进行持久化保存，不会丢失。隔离性：当多个事务并发访问数据库中的同一数据时，所表现出来的相互关系。ACID 及它们之间的关系如下图所示，比如 4 个特性中有 3 个与 WAL 有关系，都需要通过 Redo、Undo 日志来保证等。一致性首先来看一致性，一致性其实包括两部分内容，分别是约束一致性和数据一致性。 约束一致性：大家应该很容易想到数据库中创建表结构时所指定的外键、Check、唯一索引等约束。可惜在 MySQL 中，是不支持 Check 的，只支持另外两种，所以约束一致性就非常容易理解了。 数据一致性：是一个综合性的规定，或者说是一个把握全局的规定。因为它是由原子性、持久性、隔离性共同保证的结果，而不是单单依赖于某一种技术。原子性原子性就是前面提到的两个要么，即要么改了，要么没改。也就是说用户感受不到一个正在改的状态。Mysql是通过WAL（Write Ahead Log）技术来实现这个效果的。可能你想问，原子性和WAL到底有什么关系呢？其实关系非常的大。举例来说，如果事务提交了，那改了的数据就生效了，如果此时Buffer Pool的脏页没有刷盘，如何来保证改了的数据生效呢？就需要使用Redo日志恢复出来的数据。而如果事务没有提交，且Buffer Pool的脏页被刷盘了，那这个本不应该存在的数据如何消失呢？就需要使用Undo来实现了，Undo又是通过Redo来保证的，所以最终原子性的保证还是靠Redo的WAL机制实现的。持久性再来看持久性。所谓持久性，就是指一个事务一旦提交，他对数据库中的数据的改变就是应该是永久性的，接下来的操作或者故障不应该对其有任何的影响。前面已经讲到，事务的原子性可以保证一个事务要么全部执行，要么全部不执行的特性，这个可以从逻辑上保证用户看不到中间的状态。但是 持久性是如何保证的呢？一旦事务提交，通过原子性，即便是遇到宕机，也可以从逻辑上讲数据找回来后再次写入物理存储空间，这样就从逻辑和物理两个方面保证了数据不会丢失，即保证了数据库的持久性。隔离性最后看下隔离性。所谓隔离性，指的是一个事务的执行不能被其他的事务干扰，即一个事务内部的操作及使用的数据对其他的并发的事务是隔离的。锁和多版本控制就符合隔离性。并发事务控制单版本控制-锁先来看锁，锁用独占的方式来保证在只有一个版本的情况下事务之间相互隔离，所以锁可以理解为单版本控制。在Mysql事务中，锁的实现与隔离级别有关，在RR（Repeated Read） 隔离级别下，Mysql为了解决幻读的问题，以牺牲并行度为代价，通过Gap锁（间隙锁）来防止数据的写入，而这种锁，因为并行度不够，冲突很多，经常会引起死锁。现在流行的Row模式可以避免很多冲突甚至死锁，所以推行使用Row+RC（Read Commit）模式的隔离级别，可以很大程度上提高数据库的读写并行度。多版本控制-MVCC多版本控制也叫做MVCC，是指在数据库中，为了实现高并发的数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本。那多版本是如何生成的呢？每一次对数据库的修改，都会在Undo日志中记录当前修改记录的事务号及修改前数据状态的存储地址（即ROLL_PTR），以便在必要的时候可以回滚到老的数据版本。例如，一个读事务查询到当前记录，而最新的事务还未提交，根据原子性，读事务看不到最新的数据，但可以去回滚段中找到老本的数据，这样就生成了多个版本。多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据的吞吐量及读写性能。特性背后的技术原理先来看看原子性，每一个写事务，都会修改Buffer Pool，从而产生相应的Redo日志，这些日志信息会被记录到lib_logfile文件中。因为Redo日志遵循WAL的方式写入的，所以事务是顺序被记录的。在MYSQL 中，任何Buffer Pool中的页被刷到磁盘之前，都会先写入到日志文件中，这样做有两方面的保证。如果Buffer Pool中的这个页没有刷盘成功，此时的数据库挂了，那在数据库再次启动之后，可以通过Redo日志将其恢复出来，以保证脏页写下去的数据不会丢失，所以必须保证Redo先写。因为Buffer Pool的空间是有限的，要载入新页时，需要从LRU链表中淘汰一些页，而这些页必须要刷盘之后，才可以重新使用，那这时的刷盘，就需要保证对应的LSN的日志也要提前写到lib_logfiles中，如果没有写的话，恰巧这个事务又没有提交，数据库挂了，在数据库启动之后，这个事务就没法回滚了。所以如果不写日志的话，这些数据对应的回滚日志可能就不存在，导致未提交的事务回滚不了，从而不能保证原子性，所以原子性就是通过WAL来保证的。持久性背后的技术一个提交动作触发的操作有：binlog落地、发送binlog、存储引擎提交、flush_logs、check_point、事务提交标记等。这些都是数据库保证数据完整性、持久性的手段。那这些操作如何做到持久性的呢？前面讲过，通过原子性可以保证逻辑上的持久性，通过存储引擎的数据刷盘可以保证物理上的持久性。这个过程与前面提到的Redo日志、事务状态、数据库恢复、参数innodb_flush_log_at_trx_commit有关，还与binlog有关。另外，在数据库恢复时，如果发现某事务的状态为Prepare，则会在binlog中找到对应的事务并将其在数据库中重新执行一遍，来保证数据库的持久性。隔离性背后的技术接下来来看隔离性，InnoDB支持的隔离性有4种，隔离性从低到高分别为：读未提交、读提交、可重复读、可串行化。读未提交（RU，Read UnCommitted）。他能读到一个事务的中间过程，违背了ACID特性，存在脏读的问题，所以基本不会用到，可以忽略。读提交（RC，Read Committed）。他表示如果其他事务已经提交，那么我们可以看到，这也是一种最普遍适用的级别，但由于一些历史原因，可能RC在生产环境使用的并不多。可重复读（RR， Repeatable Read）,是目前被使用的最多的一种级别。其特点是有Gap锁，目前还是默认的级别，在这种级别下经常会发生死锁、低并发等问题。可串行化，这种实现方式，其实已经并不是多版本了，又回到了单版本的状态，因为它所有的实现都是通过锁来实现的。 具体说到隔离性的实现方式，我们通常用Read View 标示一个事务的可见性。目前讲到RC级别的事务可见性并不高，他可以看到已提交的事务的所有修改。而RR级别的事务，则没有这个功能，一个读事务中，不管其他事务对这些数据做了什么修改，以及是否提交，只要自己不提交，查询的数据结果就不会改变。这时如何做到的呢？随着时间的推移，读提交每一条读操作语句都会获取一次Read View，每次更新之后，都会获取数据库中最新的事务提交状态，也就是可以看到最新提交的事务了，即每条语句执行都会更新其可见性视图。而反观下面的可重复读，这个可见性视图，只有在自己当前事务提交之后，才会更新，所以与其他事务是没有关系的。这里需要提醒大家的是：在RR级别下，长时间未提交的事务会影响数据的PURGE操作，从而影响数据库的性能，所以可以对这样的事务天假一个监控。最后我们来讲下可串行化的隔离级别，前面已经提到了，可串行化是通过锁来实现的，所以实际上并不是通过多版本控制，他的特点也很明显：读锁、单版本控制、并发低。一致性背后的技术接下来是一致性。一致性可以归纳为数据的完整性。根据前文可知，数据的完整性是通过其他三个特性来保证的，包括原子性、隔离性、持久性，而这三个特性，又是通过Redo/Rndo来保证的，正所谓：合久必分，分久必合，三足鼎立，三分归晋。数据库也是，为了保证数据的完整性，提出来三个特性，这三个特性又是由同一个技术实现的，所以理解Redo/Undo才能理解数据库的本质。如上图所示，逻辑上的一致性，包括唯一索引、外键约束、check约束，这属于业务逻辑范畴。MVCC 实现原理Mysql InnoDB存储引擎，实现的是基于多版本的并发控制协议-MVCC，而不是基于锁的并发控制。MVCC 最大的好处是读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突时非常重要的，极大的提高了系统的并发性能，这也是为什么现阶段几乎所有的RDMS 都支持MVCC的原因。快照读与当前读在MVCC并发控制中，读操作可以分为两类：快照读（Snapshot Read）与当前读（ Current Read）。快照读：读取的是记录的可见版本（有可能是历史版本），不用加锁。 2. 当前读：读取的是记录的最新版本，并且当前读返回的记录，都会加锁，保证其他事务不会再并发修改这条记录。 注意：MVCC 只在RC 与RR这两种隔离级别下工作。如何区分快照读和当前读呢？ 可以简单的理解为：快照读：简单的select操作，属于快照读，不需要加锁；当前读： 特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。MVCC 多版本的实现为了让大家更直观的理解MVCC 的实现原理，这里举一个“事务对某行记录更新的过程”的案例来讲解MVCC中多版本的实现。 假设F1～F6是表中字段的名字，1～6是其对应的数据。后面三个隐含的字段分别对应该行的隐含的ID、事务号和回滚指针，如下图所示：隐含ID（DB_ROW_ID）,6个字节，当由InnoDB自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值；事务号（DB_TRX_ID），6个字节，标记了最新更新这行记录的Transaction ID，每处理一个事务，其值自动+1；回滚指针（DB_ROLL_PT），7个字节，指向当前记录的Rollback Segment 的Undo log记录，通过这个指针才能找到之前的版本数据。首先，假如这条数据是刚insert的，可以理解为ID是1，其余两个字段是空。然后，当事务1更改该行的数据时，会进行如下操作，如下图所示：用排他锁锁定该行，记录Redo log；把该行修改之前的值复制到Undo log，即图中下面的行；修改当前行的值，填写事务编号，使回滚指针指向 Undo log中修改前的行。接下来，与事务1相同，此时Undo log中有两行记录，并且通过回滚指针连在一起。因此，如果Undo log一直不删除，则会通过当前记录的回滚指针回溯到该行创建时的初始内容，所幸的是在InnoDB中存在purge线程，他会查询哪些比现在最老的活动事务还早的Undo log，并删除它们，从而保证Undo log文件不会无限增长，如下图所示： 并发事务问题及解决方案上文讲述了MVCC 的原理及实现。那么随着数据库并发事务处理能力的大大增强，数据库资源的利用率也会大大提高，从而提高了数据库系统的事务吞吐量，可以支持更多的用户并发访问。但是并发事务处理也会带来一些问题，如：脏读、不可重复读、幻读等。脏读一个事务在对一条记录修改，这个事务完成之前并提交，这条记录的数据就处于不一致的状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些脏数据，并据此做了进一步的处理，就会产生未提交的数据以来关系。这种现象叫做脏读。不可重复读一个事务在读取某些数据后的某个时间，再次读取以前读取过的数据，却发现其读出的数据已尽发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。幻读一个事务按相同的条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就叫做“幻读”。解决方案产生的这些问题，Mysql数据库是通过事务隔离级别来解决的，上文已经详细讲解过了。Mysql中锁的分类前面提到了锁，下面详细讲解Mysql中的锁。在Mysql中有三种级别的锁：页级锁、表级锁、行级锁表级锁：开销小，加锁快；不会出现死锁；锁粒度大，发生锁冲突的概率最高，并发度最低。会发生在：MyISAM、memory、InnoDB、DBD等存储引擎中。 行级锁：开销大，加锁慢；会出现死锁；锁粒度最小，发生锁冲突的概率最低，并发度最高。会发生在：InnoDB存储引擎。页级锁：开销和加锁时间介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁 和行锁之间，并发度一般。会发生在BDB存储引擎。三种级别的锁分别对应存储引擎关系如下图所示：注意：Mysql中表锁包括读锁和写锁。只需记住这个表锁模式兼容矩阵即可。InnoDB中的锁在Mysql InnoDB存储引擎中，锁分为行锁和表锁。其中行锁包括两种锁：共享锁（S）： 多个事务可以一起读，共享锁之间不互斥，共享锁会阻塞拍他锁；排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他锁。另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁搜事表锁。表锁分为三种。意向共享锁（IS）：事务计划给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得改表的IS锁；意向排他锁（IX）：事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得改表的IX锁。自增锁（AUTO-INC Lock）：特殊表锁，自增长计数器通过该“锁”来获得自增长计数器最大的计数值。在加行锁之前必须先获得表级意向锁，否则等待innodb_lock_wait_timeout 超时后根据innodb_rollback_on_timeout 决定是否回滚事务。InnoDB 自增锁在Mysql InnoDB存储引擎中，我们在设计表结构的时候，通常会建议添加一列作为自增主键。这里就会涉及一特殊的锁：自增锁（AUTO-INC Lock）,它属于表锁的一种，在insert结束之后立即释放。保持默认值就行。如下图所示：InnoDB 锁关系矩阵如下图所示，其中：+ 表示兼容，- 表示不兼容。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/Pulsar MQ相关知识点","date":"2021-07-25T18:08:05.420Z","updated":"2021-07-25T18:10:16.351Z","comments":true,"path":"2021/07/26/typora文件集合/技术/技术笔记/Pulsar MQ相关知识点/","link":"","permalink":"http://example.com/2021/07/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Pulsar%20MQ%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"Apache Pulsar 新一代云原生消息中间件 Pulsar 消息异常之后重新投递的机制消息消费异常之后，重新投递到信息队列里面之后，是在队列的头部，还是尾部？","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/Maven相关技术文件/Maven下的插件机制","date":"2021-07-25T17:20:10.510Z","updated":"2021-08-18T08:24:59.338Z","comments":true,"path":"2021/07/26/typora文件集合/技术/Maven相关技术文件/Maven下的插件机制/","link":"","permalink":"http://example.com/2021/07/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/Maven%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E6%96%87%E4%BB%B6/Maven%E4%B8%8B%E7%9A%84%E6%8F%92%E4%BB%B6%E6%9C%BA%E5%88%B6/","excerpt":"","text":"maven下的插件机制","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/Maven相关技术文件/Maven常用命令","date":"2021-07-25T17:09:50.715Z","updated":"2021-07-25T17:19:15.944Z","comments":true,"path":"2021/07/26/typora文件集合/技术/Maven相关技术文件/Maven常用命令/","link":"","permalink":"http://example.com/2021/07/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/Maven%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E6%96%87%E4%BB%B6/Maven%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Maven常用命令 编号 命令 用途释疑 1 mvn dependency:tree maven依赖树 2 mvn clean -Dmaven.tes.skip=true -U -e maven缺少依赖包，强制更新依赖，-e详细异常信息，-U 强制更新 3","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/Java字节码技术","date":"2021-07-25T16:31:10.494Z","updated":"2022-03-16T15:36:47.166Z","comments":true,"path":"2021/07/26/typora文件集合/技术/技术笔记/Java字节码技术/","link":"","permalink":"http://example.com/2021/07/26/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Java%E5%AD%97%E8%8A%82%E7%A0%81%E6%8A%80%E6%9C%AF/","excerpt":"","text":"什么Java 字节码？Java字节码技术有什么用处？Java的一些常用命令： javap是jdk自带的一个工具，可以对代码反编译，也可以查看java编译器生成的字节码。 12345678910111213141516171819-help 帮助-l 输出行和变量的表-public 只输出public方法和域-protected 只输出public和protected类和成员-package 只输出包，public和protected类和成员，这是默认的-p -private 输出所有类和成员-s 输出内部类型签名-c 输出分解后的代码，例如，类中每一个方法内，包含java字节码的指令，-verbose 输出栈大小，方法参数的个数-constants 输出静态final常量 比较常用的是==javap -c==。 JAD命令。 是一个用于反编译的执行的工具。常用的参数： 123456789101112131415161718192021222324252627282930313233343536 -a - 用JVM字节格式来注解输出 -af - 同 -a,但是注解的时候用全名称 -clear - 清除所有的前缀 -b - 输出多于的括号 (e.g., if(a) &#123; b(); &#125;, default: no) -d &lt;dir&gt; - 指定输出文件的文件目录 -dead -试图反编译代码的dead 部分(default: no) -disass - 不用用字节码的方式反编译 (no JAVA source generated) -f - 输出整个的名字,无论是类还是方法 -ff -输出类的成员在方法之前 (default: after methods) -i - 输出所有的变量的缺省的最初值 -l&lt;num&gt; - 将strings分割成指定数目的块的字符 (default: no) -lnc - 将输出文件用行号来注解 (default: no) -nl - 分割strings用新行字符 newline character (default: no) -nodos -不要去检查class文件是否以dos方式写 (CR before NL, default: check) -nocast - 不要生成辅助文件 -nocode -不要生成方法的源代码 -noconv - 不要转换java的定义符 (default: do) -noctor - 不允许空的构造器存在 -noinner -关掉对内部类的支持 (default: turn on) -nolvt - 忽略局部变量的表信息 -nonlb - 不要输出一个新行在打开一个括号之前 (default: do) -o - 无需确认直接覆盖输出 (default: no) -p - 发送反编译代码到标准输出 STDOUT (e.g., for piping) 其次.常用命令jad -o -r -sjava -dsrc test.classtree目录下的所有*.class文件 jad -o -r -sjava -dsrc tree/**/*.class unix可以表示为：jad -o -r -sjava -dsrc &#x27;tree/**/*.class&#x27;指定输出文件的名字的话，用以下的转移命令jad -p example1.class &gt; myexm1.java PS：但是，由于JAD已经很久不更新了，在对Java7生成的字节码进行反编译时，偶尔会出现不支持的问题，在对Java 8的lambda表达式反编译时就彻底失败。所以不推荐使用！ cfr","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/Java 8中新功能特性一览","date":"2021-07-25T06:56:24.837Z","updated":"2021-07-25T07:01:05.893Z","comments":true,"path":"2021/07/25/typora文件集合/技术/技术笔记/Java 8中新功能特性一览/","link":"","permalink":"http://example.com/2021/07/25/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Java%208%E4%B8%AD%E6%96%B0%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7%E4%B8%80%E8%A7%88/","excerpt":"","text":"Java 8java 8中的default方法详解Java 8中新增了default方法，它可以在接口添加新功能特性，而且还不影响接口的实现类。简单说就是：通过在接口定义的方法的访问修饰符前加上关键字default，那么实现类就无需提供改方法的实现了。这个特性也直接导致了接口中也可以写方法的实现了！！","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/PowerJob","date":"2021-07-25T06:47:24.930Z","updated":"2021-07-25T06:48:17.596Z","comments":true,"path":"2021/07/25/typora文件集合/技术/技术笔记/PowerJob/","link":"","permalink":"http://example.com/2021/07/25/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/PowerJob/","excerpt":"","text":"新一代任务框架–PowerJobMapReduce","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/架构的思考","date":"2021-07-21T16:14:42.805Z","updated":"2021-07-25T17:45:32.986Z","comments":true,"path":"2021/07/22/typora文件集合/技术/架构的思考/","link":"","permalink":"http://example.com/2021/07/22/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"","text":"架构业务架构业务架构不是演进的，业务架构是不断拆分的。 避免盲目的技术崇拜，对于任意的技术，我们要知道它适合的场景，一个技术再牛逼，如果场景不适合，也不能采用。这个场景有很多种：业务、使用人员等等。 基础架构","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/Redis中的序列化器","date":"2021-07-20T14:20:48.558Z","updated":"2021-07-20T14:21:17.448Z","comments":true,"path":"2021/07/20/typora文件集合/技术/Redis中的序列化器/","link":"","permalink":"http://example.com/2021/07/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/Redis%E4%B8%AD%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8/","excerpt":"","text":"Redis中的序列化器的使用","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/商品/业务id的使用","date":"2021-07-20T02:58:45.287Z","updated":"2021-07-20T14:20:07.844Z","comments":true,"path":"2021/07/20/typora文件集合/产品/商品/业务id的使用/","link":"","permalink":"http://example.com/2021/07/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%95%86%E5%93%81/%E4%B8%9A%E5%8A%A1id%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"engine发送地点商品的消息变动的扩展字段的业务含义： ![image-20210720105847566](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210720105847566.png)","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/告警配置","date":"2021-07-18T16:42:20.268Z","updated":"2021-07-18T17:12:50.735Z","comments":true,"path":"2021/07/19/typora文件集合/经验/告警配置/","link":"","permalink":"http://example.com/2021/07/19/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/%E5%91%8A%E8%AD%A6%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Redis配置![image-20210719004426694](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210719004426694.png) 只要需要配置的有： CPU使用率 连接数使用率 内存使用率 QPS使用率 流入带宽使用率 流出带宽使用率 平均相应时间 配置项可以参考阿里云相关的文档建议： ![image-20210719005603367](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210719005603367.png) MysqlECSESPulsar","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/系统数据迁移导致的主键Id的重复","date":"2021-07-14T05:43:24.340Z","updated":"2021-07-15T15:32:25.333Z","comments":true,"path":"2021/07/14/typora文件集合/经验/系统数据迁移导致的主键Id的重复/","link":"","permalink":"http://example.com/2021/07/14/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%BB%E9%94%AEId%E7%9A%84%E9%87%8D%E5%A4%8D/","excerpt":"","text":"系统的数据迁移导致的数据的互相依赖 原因id的生成依赖公共的法号服务，而这部分代码并没有上生产。线上的数据库的主键id采用的是自增的形式，线上和预发代码并不一致。 方案： B库中需要依赖A库中对应表的主键ID，这个时候就会有一个问题，假如一个人先在预发操作，把A库中的id1写入到了B库中去，B库中的id线上是自增的，这个时候有人在线上操作了新增操作，自增操作的id就是id+1，那么这个时候，当有一个B库中的id再同步过来的时候，就有可能同步过来的id也是id+1（因为B库、A库是两个完全独立的数据库）。这种情况就需要让A库的线上环境的id也采用和预发相同的机制。一个比较好的做法是：让A库的id采用发号服务生成，同时B库的id也采用相同的发号服务生成，并且A库的id和B库的id需要使用同一个发号服务的key。这样的话，在A库中生成的id就会使用掉发号服务对应的一个id，那么B库的线上操作在获取的发号id就不会一样了，这样就可以避免主键id冲突的问题。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/系统之间接口的依赖","date":"2021-07-13T10:59:25.245Z","updated":"2021-07-17T08:19:50.031Z","comments":true,"path":"2021/07/13/typora文件集合/事故/系统之间接口的依赖/","link":"","permalink":"http://example.com/2021/07/13/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%BE%9D%E8%B5%96/","excerpt":"","text":"接口的依赖 数据的依赖","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/如何解决多系统的耦合与依赖","date":"2021-07-13T08:15:01.760Z","updated":"2022-02-07T02:10:09.474Z","comments":true,"path":"2021/07/13/typora文件集合/技术/如何解决多系统的耦合与依赖/","link":"","permalink":"http://example.com/2021/07/13/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%A4%9A%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%80%A6%E5%90%88%E4%B8%8E%E4%BE%9D%E8%B5%96/","excerpt":"","text":"什么是系统直接的耦合与依赖？实际的业务开发中，有时候会出现A系统依赖B系统的某个接口，而B系统又可能会调用A系统的另一个接口的情况，这种情况会出现循环依赖的情况。造成系统之间的相互耦合！！ 常用的解决方案以及优缺点？ 消息中间件MQ消息中间件虽然可以解决系统与接口之间的依赖，也能起到销峰填谷的作用。但是MQ其实也有要不好的一方面：MQ增加了系统的复杂性，由于引入了MQ这个中间件，如果中间件出现服务宕机或者是丢失消息的情况，那么就会影响系统的稳定性。 系统的拆分相比较MQ，另一个思路就是进行系统的拆分。一个系统提供某一个模块的功能，不同的系统之间通过RPC接口进行调用。这样，只要每个服务保证自己RPC接口的稳定性以及性能，那么就可以解决系统之间的业务耦合。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/日志技术/MDC","date":"2021-07-11T16:12:30.733Z","updated":"2021-07-11T17:34:40.855Z","comments":true,"path":"2021/07/12/typora文件集合/技术/日志技术/MDC/","link":"","permalink":"http://example.com/2021/07/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%97%A5%E5%BF%97%E6%8A%80%E6%9C%AF/MDC/","excerpt":"","text":"MDCMapped Diagnostic Context MDC是slf4j中定义的一个日志接口规范。 通过org.slf4j.MDC的源码，可以看出MDC是通过MDCAdapter来完成put、get、remove等操作的","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/SPI","date":"2021-07-11T16:07:39.202Z","updated":"2021-09-20T08:13:00.667Z","comments":true,"path":"2021/07/12/typora文件集合/技术/技术笔记/SPI/","link":"","permalink":"http://example.com/2021/07/12/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/SPI/","excerpt":"","text":"[TOC] Java 中的SPI机制优点使用SPI机制的优势是实现解耦，使得第三方服务模块的装配控制的逻辑与调用者的业务代码分离，而不是耦合在一起。应用程序可以根据实际业务情况启用框架扩展替换框架组件。相比实用提供接口jar包，供第三方服务模块实现接口的方式，SPI的方式使得开源框架不必关心接口的实现类的路径，可以通过下面的方式获取接口的实现类： 代码硬编码import导入实现类； 指定类全路径反射获取，比如JDBC获取数据库驱动类： 1Class.forName(&quot;com.mysql.jdbc.Driver&quot;) 第三方服务模块把接口实现类实例注册到指定地方，源框架从该处访问实例 缺点 虽然ServiceLoader也算是使用的延迟加载，但是基本上只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果不想使用某些实现类，它也被加载并实例化了，这就造成了浪费。获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 多线程并发使用ServiceLoader类的实例并不安全。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/源码/TransmittableThreadLocal详解","date":"2021-07-10T17:10:49.151Z","updated":"2021-07-11T08:24:39.020Z","comments":true,"path":"2021/07/11/typora文件集合/技术/技术笔记/源码/TransmittableThreadLocal详解/","link":"","permalink":"http://example.com/2021/07/11/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%BA%90%E7%A0%81/TransmittableThreadLocal%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"何为 TransmittableThreadLocal?TransmittableThreadLocal是Alibaba开源的、用于解决“在使用线程池等会缓存线程的组件情况下传递ThreadLocal“问题的InheritableThreadLocal的扩展。这一点从TransmittableThreadLocal的源码中可以看出。![image-20210711011408606](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210711011408606.png) 使用场景 分布式跟踪系统； 应用容器或上层框架跨应用代码给下层SDK传递信息 日志收集记录系统上下文 参考博文： https://www.jianshu.com/p/e0774f965aa3 https://github.com/alibaba/transmittable-thread-local 相关的延伸InheritableThreadLocal详解https://www.jianshu.com/p/94ba4a918ff5","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/脚本处理/脚本处理经验","date":"2021-07-08T09:22:37.403Z","updated":"2021-07-10T17:08:13.882Z","comments":true,"path":"2021/07/08/typora文件集合/技术/脚本处理/脚本处理经验/","link":"","permalink":"http://example.com/2021/07/08/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E8%84%9A%E6%9C%AC%E5%A4%84%E7%90%86/%E8%84%9A%E6%9C%AC%E5%A4%84%E7%90%86%E7%BB%8F%E9%AA%8C/","excerpt":"","text":"背景商品系统重构，设计到新老系统的数据的清洗同步，同步的方式是解析excel，然后忘新的系统中插入数据。 excel样式：![image-20210709154442433](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210709154442433.png) 脚本的编写最开始是采用了组里面TL编写的一个脚本框架：ypsx-script-spring-boot-starter 这个starter的大致工作原理就是：解析excel中的每行数据，然后每一行数据起一个线程去进行具体的业务的处理； 但是这个框架有一个缺点，就是里面用到了自定义的端口，没有使用tomcat中的端口8080，因为他是加上是做了一些其他的工作： 采用自定义的端口的原因： 现在的Grpc有些平台化的场景满足不了 脚本统一调度执行的时候，对于暴露的grpc服务，没法做定向实例的调用。服务注册能支持按照group来分实例调用就好了。 但是在实际的使用中，发现架构组的同学不允许随便暴露自定义服务端口，需要使用统一的组件，即后续的power job。powerjob连接：https://github.com/PowerJob/PowerJob该组件可以解决上面的问题：脚本执行基于任务调度，任务调度是可以指定实例的，同时，新的PowerJob也是支持APi调度的。 涉及到的技术点 多线程执行，以及线程变量 ThreadLocal 任务调度。power job 任务拆分 ，对应于MapReduce 反射 基于注解的思想，解决一些问题 避免使用直接使用if else这样的判断，使用Guava库，最大化的优雅的开发业务流的判断； 声明式事务，可以自定义的把一些 操作包括在一个数据库事务中，满足个性化的业务需求 每个技术为什么这样取舍以前的时候，脚本的执行都是写一个controller，然后里面写一大堆的业务逻辑。这里面有一个问题，就是controller的执行是特别的针对非常具体的业务逻辑的，不同的脚本之间没有共享任何的信息，比如我要实现多线程处理，可以在里面使用多线程的工具，比如ForkJoin，这个是一个业务对应的controller，换了一个controller之后，这个里面的多线程的任务的拆分又需要重新做了。那如果有一个框架，可以帮我们做这个任务的拆分就好了，我们只需要关心具体的业务代码的实现，就不需要关心具体的子任务的拆分，线程的调用与维护了。脚本的执行很多的时候都是一次性的，不是一个正式的工具，是没有具体的页面的，所以很多的校验就需要做的很仔细。 针对每个技术点自己的思考多线程ThreadLocalMap 主要使用到了Alibaba开源的TransmittableThreadLocal组件。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/集合","date":"2021-07-01T08:01:57.808Z","updated":"2022-01-21T03:39:46.962Z","comments":true,"path":"2021/07/01/typora文件集合/技术/技术笔记/集合/","link":"","permalink":"http://example.com/2021/07/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E9%9B%86%E5%90%88/","excerpt":"","text":"Listlist 基本操作addList接口的add操作是会抛出UnsupportedOperationException异常，Arrays的内部类ArrayList和java.util.ArrayList都是继承AbstractList，remove、add等方法在AbstractList中是默认throw UnsupportedOperationException而且不作任何操作。java.util.ArrayList是不会抛出这个异常的。 DequeueDequeue中提供的相关方法，可以看出，对于插入、弹出（并移除）、获取这三个操作，有两大类：失败抛出异常和返回默认值两种。 1Deques can also be used as LIFO (Last-In-First-Out) stacks. This interface should be used in preference to the legacy &#123;@link Stack&#125; class. When a deque is used as a stack, elements are pushed and popped from the beginning of the deque. Stack methods are precisely equivalent to &#123;@code Deque&#125; methods as indicated in the table below 从JDK官方的文档中，我们可以看到，Dequeue可以被当作栈来使用（原因是Dequeue提供了相关的FIFO的操作）。Dequeue中的D是Double的意思，就是双端队列的意思。 Dequeue的一个常用的实现类是LinkedList。 有了Dequeue，我们看下其的父接口Queue，JDK的注释中提及这个接口涉及的常用的操作： Queue通常被当作一个FIFO的形式进行元素的存储，但其实现类有可能采用不同的规则。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/思维/分享","date":"2021-06-22T01:50:50.607Z","updated":"2022-03-12T08:24:26.998Z","comments":true,"path":"2021/06/22/typora文件集合/思维/分享/","link":"","permalink":"http://example.com/2021/06/22/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%80%9D%E7%BB%B4/%E5%88%86%E4%BA%AB/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/大促期间前后机器性能对比","date":"2021-06-17T15:45:00.296Z","updated":"2021-06-17T16:31:28.294Z","comments":true,"path":"2021/06/17/typora文件集合/技术/大促期间前后机器性能对比/","link":"","permalink":"http://example.com/2021/06/17/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E4%BF%83%E6%9C%9F%E9%97%B4%E5%89%8D%E5%90%8E%E6%9C%BA%E5%99%A8%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/","excerpt":"","text":"内存GC![image-20210618001436684](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618001436684.png) 线程数![image-20210618001550493](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618001550493.png) 总体情况![image-20210618001926436](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618001926436.png) 业务高峰期的情况![image-20210618001731752](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618001731752.png) QPS总体QPS趋势![image-20210617234825762](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210617234825762.png) Pms客户端调用QPS趋势![image-20210617234944948](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210617234944948.png) qps调用量最大是store（到家）![image-20210617235031087](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210617235031087.png) 服务rt响应![image-20210617235516811](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210617235516811.png) 应对中台pms请求的接口rt响应![image-20210617235537972](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210617235537972.png) 可以看到，item对pms的接口响应时间一半都很高。 ps：请求包大小的一个大致的了解 ![image-20210618000004976](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618000004976.png) 两个qps最大的接口的调用情况： ![image-20210618000551374](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618000551374.png) ![image-20210618000645633](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618000645633.png) Load 负载单个POD的情况![image-20210618003101477](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210618003101477.png)","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/谊批宝大事务导致的数据库和消息不一致的问题","date":"2021-06-17T15:33:38.755Z","updated":"2021-07-17T08:20:05.543Z","comments":true,"path":"2021/06/17/typora文件集合/事故/谊批宝大事务导致的数据库和消息不一致的问题/","link":"","permalink":"http://example.com/2021/06/17/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/%E8%B0%8A%E6%89%B9%E5%AE%9D%E5%A4%A7%E4%BA%8B%E5%8A%A1%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%80%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"现象原因总结","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/牛客网/哈希函数和哈希表","date":"2021-06-13T16:33:31.719Z","updated":"2021-06-14T00:35:39.725Z","comments":true,"path":"2021/06/14/typora文件集合/技术/牛客网/哈希函数和哈希表/","link":"","permalink":"http://example.com/2021/06/14/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E7%89%9B%E5%AE%A2%E7%BD%91/%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%E5%92%8C%E5%93%88%E5%B8%8C%E8%A1%A8/","excerpt":"","text":"hash定义特征 输入域是个无穷大的，输出域是有限的 相同的输入会得到相同的输出，但是不同的输入也可能会得到相同的输出（hash碰撞） 离散型 算法布隆过滤器必备技巧","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/6月10号PMS调用商户超时问题（关于ForkJoin）","date":"2021-06-11T03:05:43.873Z","updated":"2021-09-20T08:11:46.524Z","comments":true,"path":"2021/06/11/typora文件集合/事故/6月10号PMS调用商户超时问题（关于ForkJoin）/","link":"","permalink":"http://example.com/2021/06/11/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/6%E6%9C%8810%E5%8F%B7PMS%E8%B0%83%E7%94%A8%E5%95%86%E6%88%B7%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98%EF%BC%88%E5%85%B3%E4%BA%8EForkJoin%EF%BC%89/","excerpt":"","text":"[TOC] 问题现象查询商户的接口，报超时。 接口信息 12345678910111213141516public List&lt;MerchantInfo&gt; getMerchantListByIds(List&lt;Long&gt; merchantIdList) &#123; if (CollectionUtils.isEmpty(merchantIdList)) &#123; return Lists.newArrayList(); &#125; MerchantIdsRequest merchantIdsRequest = MerchantIdsRequest.newBuilder().addAllIds(merchantIdList).build(); MerchantListResponse merchantListResponse = merchantServiceBlockingStub.getMerchantListByIds(merchantIdsRequest); if (!merchantListResponse.getIsSuccess() || CollectionUtils.isEmpty(merchantListResponse.getDataList())) &#123; log.warn(&quot;MerchantExternalService.getMerchantListByIds fail,request:&#123;&#125;&quot;, JsonUtil.toJson(merchantIdsRequest)); throw new PmsBizException(GET_MERCHANT_ERROR); &#125; List&lt;MerchantInfo&gt; merchantInfoList = Lists.newArrayList(); for (Merchant merchant : merchantListResponse.getDataList()) &#123; merchantInfoList.add(MerchantInfo.build(merchant)); &#125; return merchantInfoList;&#125; 问题排查过程商户提供新的接口，替换。 新的接口的信息： 1234567891011121314151617181920212223242526public List&lt;MerchantInfo&gt; queryMerchantsByIds(List&lt;Long&gt; merchantIdList) &#123; if (CollectionUtils.isEmpty(merchantIdList)) &#123; return Lists.newArrayList(); &#125; QueryMerchantsByIdsRequest request = QueryMerchantsByIdsRequest.newBuilder() .addAllIds(merchantIdList) .build(); QueryMerchantsByIdsResponse response = phoenixMerchantServiceBlockingStub.queryMerchantsByIds(request); if (!response.getSuccess() || CollectionUtils.isEmpty(response.getMerchantsList())) &#123; log.warn(&quot;phoenixMerchantServiceBlockingStub.queryMerchantsByIds fail,request:&#123;&#125;&quot;, JsonUtil.toJson(request)); throw new PmsBizException(GET_MERCHANT_ERROR); &#125; List&lt;MerchantInfo&gt; merchantInfoList = Lists.newArrayList(); for (MerchantOuterClass.Merchant merchant : response.getMerchantsList()) &#123; merchantInfoList.add(MerchantInfo.builder() .id(merchant.getId()) .merchantName(merchant.getMerchantName()) .subMerchantType(merchant.getSubMerchantType()) .organizationCode(merchant.getOrganizationCode()) .businessLine(MerchantBusinessLine.forNumber(merchant.getBusinessLine())) .build()); &#125; return merchantInfoList;&#125; 两个接口的区别在与之前的接口里面查询的东西非常的多，而且有些内容是走DB的。量大的时候就会出现超时。即便商品这边改为并行查询也是不行的。 后面把接口替换成了下面的那个接口，但是仍旧保留并行查询的方式，但是发现一个现象：预发环境的时候查询是没有问题的，可以在网关的超时时间以内进行返回，但是发到线上之后发现还是会出现超时。 通过链路发现，调用商户没有出现很长的rt，而是商品内部的时间比较的就，通过代码发现，多线程我们使用了CompletableFuture 这个工具类 12345678910int merchantIdbatchSize = apolloDataConfig.getMerchantIdbatchSize();List&lt;List&lt;Long&gt;&gt; partitionIdList = Lists.partition(merchantIdList, merchantIdbatchSize);LinkedList&lt;CompletableFuture&lt;Stream&lt;MerchantInfo&gt;&gt;&gt; futures = Lists.newLinkedList();for (List&lt;Long&gt; idList : partitionIdList) &#123; futures.add(CompletableFuture .supplyAsync(() -&gt; ofNullable(merchantExternalService.queryMerchantsByIds(idList)) .orElse(Lists.newArrayList()) .stream().filter(Objects::nonNull)));&#125;List&lt;MerchantInfo&gt; merchantListByIds = futures.stream().flatMap(CompletableFuture::join).collect(toList()); 这个CompletableFuture中多线程用到了ForkJoinPool线程池。而FrokJoinPool这个线程池是全局共用的。 ![image-20210612232645550](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210612232645550.png) ![image-20210612232734342](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210612232734342.png) 通过ForkJoinPool的源代码我们可以看到，ForkJoinPool的核心线程池数parallelism初始值是-1，然后会先从系统变量中获取，如果没有的话就是系统核数-1。另外如果配置的parallelism的值大于了MAX_CAP=32767，则重置parallelism的值是32767。也就是说ForkJoin的理论的最大值只能是32767。 12345678String pp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;);String fp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.threadFactory&quot;);String hp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.exceptionHandler&quot;);if (pp != null) parallelism = Integer.parseInt(pp); 总结通过这个线上的问题，可以看到即便不同的环境部署了同样的代码，接口的效果仍然可能是不一样的。这个也让我认识到，多线程工具类CompletableFuture是不可以随便使用的，因为他的底层使用了我们常用的ForkJoin框架，这个框架是JUC包下面的很多并行类使用到了。如果遇到了需要使用多线程的地方，我们最好是自己创建一个线程工具类，这样可以避开使用共用的线程池等。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/GIT命令","date":"2021-06-05T17:45:06.183Z","updated":"2022-02-07T02:04:57.598Z","comments":true,"path":"2021/06/06/typora文件集合/技术/GIT命令/","link":"","permalink":"http://example.com/2021/06/06/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/GIT%E5%91%BD%E4%BB%A4/","excerpt":"","text":"编号 命令 注释 1 git rm -r –cached . 把文件从暂存区域移除 2 git add . 3 git commit -m ‘update .gitignore’ git清除缓存 4 git merge –abort 终止merge操作 5 6 7 8 9","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/性能压测","date":"2021-06-05T13:14:08.967Z","updated":"2021-06-06T17:03:09.647Z","comments":true,"path":"2021/06/05/typora文件集合/经验/性能压测/","link":"","permalink":"http://example.com/2021/06/05/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/%E6%80%A7%E8%83%BD%E5%8E%8B%E6%B5%8B/","excerpt":"","text":"性能压测 @所有人营销618压测结果 一、活动维度（查询活动+库存+商品）3947/5126 TPS（平均/峰值） 100%/100% 成功率（请求/业务）61平均RT（ms）5824/6757 TPS（平均/峰值） 100%/100% 成功率（请求/业务）84平均RT（ms）9557/14681 TPS（平均/峰值） 100%/100% 成功率（请求/业务）109平均RT（ms） 二、商详页维度（查询单品价+可领券）9387/11813 TPS（平均/峰值）99.98%/99.94%成功率（请求/业务）270平均RT（ms）9417/13779 TPS（平均/峰值）100%/100%成功率（请求/业务） 268平均RT（ms）11119/14297 TPS（平均/峰值）99.99%/99.99%成功率（请求/业务）419平均RT（ms） 三、用户维度（限购+id查活动）2929/3777 TPS（平均/峰值）100%/100%成功率（请求/业务）113平均RT（ms）3886/6032 TPS（平均/峰值）100%/100%成功率（请求/业务）123平均RT（ms）5865/11326 TPS（平均/峰值）100%/100%成功率（请求/业务）147平均RT（ms） 四、查询商品可用券370/642 TPS（平均/峰值）99.75%/99.75%成功率（请求/业务）686平均RT（ms）364/624 TPS（平均/峰值）99.58%/99.58%成功率（请求/业务）688平均RT（ms） 总结：营销本次压测，达到618的预期目标。 action:1、周一进行性能优化会议2、两条慢sql需优化3、mysql性能优化 性能的瓶颈点 DB Redis 超时的接口怎么优化？","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/技术笔记/ES相关/ES语法汇总","date":"2021-06-03T05:24:26.338Z","updated":"2021-08-21T00:32:27.419Z","comments":true,"path":"2021/06/03/typora文件集合/技术/技术笔记/ES相关/ES语法汇总/","link":"","permalink":"http://example.com/2021/06/03/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ES%E7%9B%B8%E5%85%B3/ES%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB/","excerpt":"","text":"聚合查询查询merchant_item_sku索引中有多少个merchantId的数据以及每个merchantId的文档数 POST merchant_item_sku_docs/_search?filter_path=aggregations &#123; &quot;_source&quot;: &quot;merchantItemDoc.merchantId&quot;, &quot;aggs&quot;:&#123; &quot;result&quot;:&#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;merchantItemDoc.merchantId&quot;, &quot;size&quot;: 100 &#125; &#125; &#125; &#125; 更新mapping`PUT index_name/_mapping/_doc?pretty{ “properties”: {&quot;field_name&quot;: &#123; &quot;type&quot;: &quot;fieldType&quot; &#125; }}`","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/事故/06月2号数据库CPU100%","date":"2021-06-02T11:47:37.746Z","updated":"2021-09-20T08:11:56.722Z","comments":true,"path":"2021/06/02/typora文件集合/事故/06月2号数据库CPU100%/","link":"","permalink":"http://example.com/2021/06/02/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%8B%E6%95%85/06%E6%9C%882%E5%8F%B7%E6%95%B0%E6%8D%AE%E5%BA%93CPU100%/","excerpt":"","text":"[TOC] 时间起因：![image-20210602195009782](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602195009782.png) 下午5点03分，item依赖的数据库实例告警：CPU使用率超过90%。 原因分析通过查看DMS的数据库SQL洞察,发现下面这个sql，每秒钟执行了2971次。 UPDATE shop_item_sku SET status = ?, operator = ?, last_ver = last_ver + ? WHERE id = ? 另外就是下面这个sql的耗时比例也比较大，平均每个sql的执行时间为1s。 SELECT * FROM shop_item_sku WHERE shop_id = ? LIMIT ?, ? 如下图所示： ![image-20210602170926997](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602170926997.png) ![image-20210602200202643](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602200202643.png) 通过sql定位到这个是消费商户那边营业部下线消息中的处理逻辑调用的– 里面根据shopId分页查询了营业部商品信息，然后再一条一条调用mapper更新数据库中shopItemSku的状态。因为一个营业部中大概有2w个商品 ![image-20210602201633440](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602201633440.png) 然后通过查看日志，发现在17点到17点40分这段时间内，总共接受到商户612条这样的消息（后来分析有部分消息是因为没有ACK重新投递消费的原因），那么这样计算下来，商品这边总共会变更数据库1千万多次。 ![image-20210602201805577](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602201805577.png) 因为更新商品状态之后会再发送营业部变动的消息，通过在基础保障平台中的消息队列中查看消息的发送消费情况，可以看到shop-item Topic的消息在部分消费者中有2千多万的积压量。 处理方式 dba针对把正在进行的会话进程kill掉； 对数据库增加限流； 因为代码是接受到消息立马就去便利数据库进行更新了，所以只能重启ECS终止对应的进程，停止对应的查询更新； 后面发现重启任务之后，消息还在发，通过日志及代码判断，应该是消息的处理逻辑rt时间比较久，超过了消息的自动ACK超时时间（配置的是10s），导致消息重新投递重复消费。所以就临时关闭了对商户这个消息的消费。 12345678910111213141516171819if (null != msg &amp;&amp; null != msg.getData() &amp;&amp; msg.getData().length != 0) &#123; String message = msg.getValue(); log.info(&quot;MerchantSyncConsumer receive message:&#123;&#125;&quot;, message); try &#123; String[] split = message.split(&quot;\\u0001&quot;); MerchantScope scope = MerchantScope.fromCode(Integer.valueOf(split[1])); if (scope.equals(MerchantScope.DELIVERY_STATION)) &#123; Merchant shop = JSONObject.parseObject(split[2], Merchant.class); if (shop.getSubMerchantType().equals(SubMerchantType.DELIVERY_STATION) &amp;&amp; shop.getMerchantStatus().equals(MerchantStatus.PAUSE)) &#123; log.info(&quot;MerchantSyncConsumer 营业部停止营业，shopId:&#123;&#125;&quot;, shop.getId()); shopItemService.downShelfShopItemSku(shop.getId()); &#125; &#125; &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); throw new ItemBizException(SG_MERCHANT_SYNC_CONSUMER_ERROR.code, SG_MERCHANT_SYNC_CONSUMER_ERROR.desc); &#125;&#125; 123456789101112131415161718public void downShelfShopItemSku(long shopId) &#123; int page = 1; int pageSize = 50; List&lt;ShopItemSku&gt; shopItemSkuList = shopItemRepository .queryShopItemSkuByShopId(shopId, page, pageSize); while (CollectionUtils.isNotEmpty(shopItemSkuList)) &#123; for (ShopItemSku shopItemSku : shopItemSkuList) &#123; shopItemRepository.updateShopItemSkuStatus(shopItemSku.getShopItemSkuId(), SaleStatus.DOWN_SHELF_VALUE, &quot;system&quot;); try &#123; messageService.sendShopItemMessage(shopItemSku.getShopItemSkuId(), EventType.TYPE_CHANGE_SHOP_ITEM_STATUS); &#125; catch (Exception e) &#123; log.warn(&quot;messageService.sendShopItemMessage warn&quot;, e); &#125; &#125; page++; shopItemSkuList = shopItemRepository.queryShopItemSkuByShopId(shopId, page, pageSize); &#125;&#125; ![image-20210602203349538](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602203349538.png) 总结 接入消息，首先要考虑两个问题：一是幂等性、另一个就是消息的ACK是有超时时间的。所以对于订阅消息的逻辑，首先要保证这两块东西。今天发生的CPU打满100%，其中的一个元凶就是消息里面的处理逻辑rt很长，但是我们又不能先ACK在处理逻辑（想想问什么？）。这个时候怎么办呢？一个思路就是本地消息表，就把消息的内容持久化下来，然后起一个定时任务去扫描未处理的消息表记录，重新去处理；还有一个思路就是点火到引擎（本质还是一个支持重试的组件），由引擎再去调用原本属于消费者内部的处理逻辑，由于引擎支持重试，所以可以天然的保持最终一致性。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/慢Sql优化","date":"2021-06-01T06:51:33.079Z","updated":"2022-02-07T02:10:17.722Z","comments":true,"path":"2021/06/01/typora文件集合/技术/慢Sql优化/","link":"","permalink":"http://example.com/2021/06/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%85%A2Sql%E4%BC%98%E5%8C%96/","excerpt":"","text":"什么是慢SQL 增加索引 分批查询 索引优化","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/价格/价格接口列表","date":"2021-05-31T17:16:09.987Z","updated":"2021-11-12T07:30:55.535Z","comments":true,"path":"2021/06/01/typora文件集合/产品/价格/价格接口列表/","link":"","permalink":"http://example.com/2021/06/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E4%BB%B7%E6%A0%BC/%E4%BB%B7%E6%A0%BC%E6%8E%A5%E5%8F%A3%E5%88%97%E8%A1%A8/","excerpt":"","text":"1.查询售价 市场价 结算价PriceRealTimeQueryServiceBlockingStub queryItemPrice2.生成调价单AdjustOrderQueryServiceBlockingStub.queryAdjustOrderNo 批量工具调整后仅进价调整使用AdjustOrderQueryServiceBlockingStub.batchQueryAdjustOrderNo3.售价市场价调整AdjustOrderAPIServiceBlockingStub.createSellingAdjustOrderAPI 批量工具调整后弃用4.结算价&amp;售价&amp;市场价 调整接口AdjustOrderStreamAPIServiceStub.createSettlementSellingMarketPriceStreamAPI5.结算价调整AdjustOrderAPIServiceBlockingStub.createSettlementAdjustOrderAPI 批量工具调整后弃用6.查询货品进价PriceRealTimeQueryServiceBlockingStub.queryPointTimePurchasePrice7.进价调整AdjustOrderStreamAPIServiceStub.createPurchaseAdjustOrderStreamAPI8.查询价格趋势PriceRealTimeQueryServiceBlockingStub.queryTrendPrice","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/产品/培养产品思维","date":"2021-05-31T17:13:02.115Z","updated":"2021-08-26T05:37:22.558Z","comments":true,"path":"2021/06/01/typora文件集合/产品/培养产品思维/","link":"","permalink":"http://example.com/2021/06/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E4%BA%A7%E5%93%81/%E5%9F%B9%E5%85%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4/","excerpt":"","text":"培养产品思维","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/流程引擎的技术演进","date":"2021-05-31T17:10:04.720Z","updated":"2022-02-07T01:59:18.702Z","comments":true,"path":"2021/06/01/typora文件集合/技术/流程引擎的技术演进/","link":"","permalink":"http://example.com/2021/06/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E6%B5%81%E7%A8%8B%E5%BC%95%E6%93%8E%E7%9A%84%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B/","excerpt":"","text":"流程引擎的技术演进 为什么会有流程引擎市面上常用的流程引擎架构模式Activity 做贴合业务场景的最有用的流程引擎统一的任务调度框架","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/DMS使用心得","date":"2021-05-31T15:39:33.146Z","updated":"2021-06-02T09:09:31.158Z","comments":true,"path":"2021/05/31/typora文件集合/经验/DMS使用心得/","link":"","permalink":"http://example.com/2021/05/31/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/DMS%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97/","excerpt":"","text":"慢sql的优化：慢日志分析-&gt;点击优化-&gt;查看之心计划&amp;&amp;获取优化建议。 ![image-20210601002410694](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210601002410694.png) ![image-20210601002634898](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210601002634898.png) ![image-20210601002258985](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210601002258985.png) 性能洞察：获取sql的请求量的分布以及 ![image-20210601002805454](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210601002805454.png) 耗时比例![image-20210602170926997](/Users/xiazhenyu/Library/Application Support/typora-user-images/image-20210602170926997.png)","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/技术/调价单的心路历程","date":"2021-05-30T16:37:05.965Z","updated":"2021-08-12T05:49:40.392Z","comments":true,"path":"2021/05/31/typora文件集合/技术/调价单的心路历程/","link":"","permalink":"http://example.com/2021/05/31/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E6%8A%80%E6%9C%AF/%E8%B0%83%E4%BB%B7%E5%8D%95%E7%9A%84%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B/","excerpt":"","text":"第一版mq 主要实现逻辑： 技术要求是支持600个商品的excel导入调价，门店是30个。支持的城市是杭州。当时杭州只有很少的门店，采用的思路是一般的解析excel、进行校验，然后调用item的接口进行更新。杭州在实施的时候没有遇到太大的问题，但是在sit以及预发测试的时候，经常会有超时的现象发生。因为sit以及预发的机器的性能不好。 当然这个里面用到的MQ，excel中的数据解析完并且校验成功之后，是会一条一条发送到MQ中。然后再自发自收中进行处理。好处：削峰、提高并发量。 第二版task+mq 主要实现逻辑： 在北京、上海切ERP的时候，对你调价单提出了需要支持2000+的目标，门店也要支持50+。这个时候引入了task任务的模式，导入一个excel以后，会启动一个线程去执行当前的excel的解析和处理：先保存这个任务，然后返回任务的id给前端。前端再拿这个任务id轮训的调用任务执行结果的查看接口。这样即便用于关闭了当前的页面，当再次进入这个调价单详情页的时候，我么依然可以根据这个调价单的id找到对应的任务id，进而可以得到excel的执行结果。这个是导入excel的执行逻辑，同理，对于调价单的审核也是采用异步task的方式：点击审核之后，就会触发一个异步的task任务的保存，这个任务里面会进行列表数据的校验、生成校验失败的excel并保存。然后用户可以在调价单的详情中看到校验失败（也即是调价失败）的excel地址，可以下载查看。 这个逻辑后面在内部中又增加了多线程的处理、数据库索引的增加、代码接口的精简等。 缺点：项目重启的时候，任务会丢失数据。合肥切换的时候，由于单个Excel中数据过万，门店也是140+。部分调价没有执行成功！！原因暂未找到。 第三版engine+mq 主要实现逻辑： 这个版本的优化主要针对的就是合肥切ERP导致的数据莫名丢失的问题。核心思路就是借助引擎的重试的机制。首先，一个导入excel进行调价会有两个关联的任务：第一个是解析excel的任务，一个是excel多行数据并行处理的任务。先说第一个任务：用户导入一个excel之后，会点火引擎（提交任务资料）。引擎内部会根据系统资源异步调用这个任务配置的执行代码块（一个handler或着说是processor）：这个processor中去执行具体的excel的解析和校验，只有校验呢通过的数据，才会被分批发送到mq中，mq的作用就是削峰和分流。通过自发自收，把消息的数据点火到引擎中，由引擎确保每个业务数据都能被执行到。（这里没有在mq中进行具体的商品的调价主要还是公司的pulsar集群不够稳定，量大的时候容易造成broker失去连接）。引擎在收到消息点火中的报文数据之后，会异步的调用第二个任务对应的handler（或者说是processor），然后会在这个handler中进行具体的商品的调价（会调用item的接口）。介入引擎和消费消息一样，需要做好handler（或者说是processor）的幂等性。因为每个hanlder都是有业务超时时间限制的，一旦任务的执行时间超过这个限制，引擎就会任务这个任务是执行失败的，会进行重试，但其实任务很有可能已经执行成功了，只是没有在规定的时间内给引擎返回成功的标识。所以幂等的处理至关重要！！ 缺点：采用这个方案虽然可以保证每条excel中的数据不丢失，但是没有了回执的结果给用户，用户无法感知任务的执行进度（除非进入到engine的后台进行查看）。另外，引擎在量大的时候极易造成任务拥堵，大量的任务执行超时，重试。造成资源的浪费！ 解决措施：task+engine+mq task记录执行回执，生成excel，用以返回结果给用户；engine确保业务数据不丢失，保证分布式业务幂等；mq进行请求的削峰、填谷。 第四版to be continue… 依旧存在的问题： 接口设计的很不合理，其中，pms这边很多查询商品的接口可以合并，然后，接口的查询也没有使用criteria条件参数，而是直接添加了入参，这个是不合理的，如果接口的入参增加，就需要改变入参的个数。","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/经验/pulsar的迁移的思考","date":"2021-05-19T16:58:07.924Z","updated":"2021-09-20T08:12:38.782Z","comments":true,"path":"2021/05/20/typora文件集合/经验/pulsar的迁移的思考/","link":"","permalink":"http://example.com/2021/05/20/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E7%BB%8F%E9%AA%8C/pulsar%E7%9A%84%E8%BF%81%E7%A7%BB%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"","text":"[TOC] pulsar的新老集群切换的心得 目的&amp;原因：老集群的版本比较低，存在对业务造成致命影响的BUG，且治理功能 不完善，需要迁移到新集群。 商品的现有消息的问题 消息发送的地方有很多，虽然有统一的messageService，但是调用这个messageService是有非常多的，而且调用同一个msgService的消息，里面是有一个envetType的，用来区分同一个消息的不同的业务类型，刚开始的还好，但是一多的时候，就会容易混淆， 消息中放的东西很多，但是外域在接商品消息的时候，往往并不直接使用消息体中的内容，而是拿到主键id后再次调用了商品的接口，这个有点浪费了。 迁移中遇到的问题 幂等性保证 对于保存插入的消息，一般的是会先查询一边数据库，判断下是不是存在，不存在则插入。但是当消息同时过来两条一样的时候，这个利用数据库的查询的结果就会失效。那么这个时候就会两种思路：一个是不做这个判断，直接调用底层的仓储层进行保存，利用数据库的业务主键冲突来保证实际只会有一个成功，但是这个方案对于没有业务唯一主键的表就失效了！另一种就是我们引入Redis的分布式锁，具体的可以自己调用redis底层的api实现，也可以采用第三方的组件：Redisson update类型的消息如何避免掉老的消息把新的消息给覆盖掉这个地方尤其发生在接受新老的集群发送的消息，因为不在一个集群中，所以会导致同一个业务消息在两个集群上发生乱序。基础保障组可以保证在同一个集群，同一个Topic的消息在两个partition中保证顺序，但是不同的集群就是不能保证的。我的做法是引入一个全局的时间过滤器：GlobalTimeFilter：业务主键id为key，gmtModified为value，存储在redis中，并设置一个过期时间，防止redis的内存被打满，如果新的消息中的对应的gmtModifed早于或等于redis中的时间，就直接ACK， 12345678910public boolean checkMsgIsTheLastOne(String businessKey, long newGmtModified) &#123; String oldGmtModified = cacheService.getCache(PULSAR_MSG_BUSINESS_KEY.getCacheKey(businessKey)); if (StringUtils.isNotBlank(oldGmtModified) &amp;&amp; Long.valueOf(oldGmtModified) &gt; newGmtModified) &#123; return false; &#125; else &#123; cacheService.saveCacheExpired(PULSAR_MSG_BUSINESS_KEY, String.valueOf(newGmtModified), businessKey); return true; &#125;&#125;","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/商品重构","date":"2021-05-10T05:48:52.210Z","updated":"2021-09-29T07:42:15.963Z","comments":true,"path":"2021/05/10/typora文件集合/商品重构/","link":"","permalink":"http://example.com/2021/05/10/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E5%95%86%E5%93%81%E9%87%8D%E6%9E%84/","excerpt":"","text":"流程引擎","categories":[],"tags":[]},{"title":"","slug":"typora文件集合/工作心得","date":"2021-03-01T01:54:33.633Z","updated":"2021-09-20T08:11:21.241Z","comments":true,"path":"2021/03/01/typora文件集合/工作心得/","link":"","permalink":"http://example.com/2021/03/01/typora%E6%96%87%E4%BB%B6%E9%9B%86%E5%90%88/%E5%B7%A5%E4%BD%9C%E5%BF%83%E5%BE%97/","excerpt":"","text":"[TOC] 工作心得 操作要留有痕迹，最好有文档落地，后期可以查问题。代码方面，在关键的地方打日志，方便排查问题；线上的数据库修改，最好根据修改的条件查出来对应的表的id，并记录下，这样万一有问题，可以根据这些id定位影响了哪些行的数据，方便排查问题。 一个方法里面的代码的行数不要超过50行。切记！！ 对一个对象里面的字段进行取值的时候，应该首先判断这个对象是否为null； 项目发布上线的时候，需要检查配置文件、apollo等获取配置的地方该有的配置是否配置齐全了； 发布上线前，要仔细做好code review。平时因为环境问题注释的代码，最好加上todo，这样上线或提交代码的时候，可以直接搜todo看有哪些代码是未完成和有问题的，可以提前避免问题； 要多看服务器的日志，通过日志发现问题。 不能再循环中调用外部服务，需要调用批量的方法； 类包要明确好，不同的包放置不同功能的类； 遇到Optional，使用的时候要进行判断，这个容器里面的有可能是null； 开发功能之前要先设计好详细的技术方案，画好时序图、用例图，先定义好接口，沟通清楚再进行开发。 上线之前一定要让测试验证过，不能搭便车。两次的开发要放在两个分支上，避免带着隐患上线。 做业务开发也要懂得业务，要有自己的思考，不能只听产品经理的。最好自己平时对自己做的业务多了解些。 用好扩展字段 注意并发请求的好处，对于多个的参数而言，并发是相当于同时拿一批的id去查询，所以开启的并发请求越多，耗时也就越多。注意这个和for循环中调用rpc服务的不同之处，for循环中的调用都是串行的，时间是累加的。采用parallel的方式进行查询，时间是一个的。所以，采用parallel的查询会提升查询的效率。 123456789101112if (CollectionUtils.isNotEmpty(allChildMerchantInfoIdList)) &#123; allChildMerchantMap = Lists.partition(allChildMerchantInfoIdList, 10).stream() // 去除重复ID .distinct() .parallel() .map(ids -&gt; merchantExternalService.queryShopListByIds(ids, tenantId)) .reduce((left, right) -&gt; &#123; left.putAll(right); return left; &#125;) .orElseThrow(() -&gt; new RuntimeException(&quot;&quot;));&#125; 规范话的开发流程，前期做好产品需求调研，认真细致阅读prd文档。 用好业务异常与系统异常，业务异常一般是给调用方以及前端使用的，不属于系统异常的一部分。对于业务异常，一般不需要打印日志：如果打印了，对于已经结构错误日志监控的系统来说，这部分就会告警，让系统维护人员误以为系统发生了故障。 线上的配置修改要慎重，比如对于MQ消息集群的切换，就需要去调查下游业务的使用情况，确定没有使用的才能关闭老的生产者。 对于做中台项目而言，前台接口文档很重要。这样很方便与前端对接。","categories":[],"tags":[]}],"categories":[{"name":"技术","slug":"技术","permalink":"http://example.com/categories/%E6%8A%80%E6%9C%AF/"},{"name":"linux","slug":"linux","permalink":"http://example.com/categories/linux/"},{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"},{"name":"wholee","slug":"wholee","permalink":"http://example.com/categories/wholee/"},{"name":"技能","slug":"技能","permalink":"http://example.com/categories/%E6%8A%80%E8%83%BD/"},{"name":"工作","slug":"技能/工作","permalink":"http://example.com/categories/%E6%8A%80%E8%83%BD/%E5%B7%A5%E4%BD%9C/"},{"name":"DDD","slug":"DDD","permalink":"http://example.com/categories/DDD/"},{"name":"typora","slug":"typora","permalink":"http://example.com/categories/typora/"}],"tags":[{"name":"工作安排","slug":"工作安排","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E5%AE%89%E6%8E%92/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"},{"name":"wholee","slug":"wholee","permalink":"http://example.com/tags/wholee/"},{"name":"技能","slug":"技能","permalink":"http://example.com/tags/%E6%8A%80%E8%83%BD/"},{"name":"DDD","slug":"DDD","permalink":"http://example.com/tags/DDD/"}]}